{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9pFGuKTRuJG",
        "outputId": "7fb934a8-5641-4b5d-a23c-f9bd7a1a2813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/A2Summ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlA2OoDFRzqa",
        "outputId": "48890ab8-917a-4f28-9735-76635ac761e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/A2Summ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n",
        "!pip install rouge-score==0.1.2\n",
        "!pip install scipy ortools==9.5.2237 h5py pyyaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxgOuTKMTLFg",
        "outputId": "d57a6c06-822b-4d52-a0ac-0849c441010d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Collecting rouge-score==0.1.2\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score==0.1.2) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score==0.1.2) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score==0.1.2) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score==0.1.2) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score==0.1.2) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score==0.1.2) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score==0.1.2) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score==0.1.2) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=5858cbff94b87d3fd73fc3f77f9cff1d8115529748f877771c04fcce5fece82b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting ortools==9.5.2237\n",
            "  Downloading ortools-9.5.2237-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.12.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: absl-py>=0.13 in /usr/local/lib/python3.11/dist-packages (from ortools==9.5.2237) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from ortools==9.5.2237) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=4.21.5 in /usr/local/lib/python3.11/dist-packages (from ortools==9.5.2237) (4.25.6)\n",
            "Downloading ortools-9.5.2237-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ortools\n",
            "Successfully installed ortools-9.5.2237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset TVSum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsz6jo3NSKSc",
        "outputId": "b28e6a8d-1c78-4f31-f4f1-034f260e018a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-08 20:16:47.814312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741465007.834178    9540 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741465007.840648    9540 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-08 20:16:47.860971: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025/03/08 20:16:51] {'dataset': 'TVSum', 'data_root': 'data', 'device': 'cuda', 'seed': 666, 'max_epoch': 300, 'start_epoch': 0, 'batch_size': 4, 'num_workers': 4, 'model_dir': 'logs/TVSum', 'log_file': 'log.txt', 'lr': 0.001, 'weight_decay': 1e-05, 'nms_thresh': 0.4, 'print_freq': 5, 'eval_freq': 1, 'suffix': '', 'checkpoint': None, 'test': False, 'num_input_video': 1024, 'num_input_text': 768, 'num_feature': 512, 'num_hidden': 128, 'dropout_video': 0.1, 'dropout_text': 0.1, 'dropout_attn': 0.5, 'dropout_fc': 0.5, 'num_layers': 2, 'lambda_contrastive_inter': 0.1, 'lambda_contrastive_intra': 1.0, 'ratio': 16}\n",
            "logs/TVSum\n",
            "[2025/03/08 20:16:51] Start training on data/TVSum/splits.yml: split 0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[2025/03/08 20:16:53] \n",
            "Model_VideoSumm(\n",
            "  (proj_fc_video): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
            "    (1): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (proj_fc_text): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
            "    (1): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (multiway_list): ModuleList(\n",
            "    (0-1): 2 x MultiWayTransformer(\n",
            "      (norm1_fused): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn_fusion): MultiHeadAttention(q_dims=128, k_dims=128, v_dims=128, h_dims=128, o_dims=128, heads=8, p=0.5, bias=True)\n",
            "      (norm2_video): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ffn_video): FFN(\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.5, inplace=False)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (drop2): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "      (norm2_text): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ffn_text): FFN(\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.5, inplace=False)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (drop2): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm_video): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (norm_text): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (fc_video): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (fc_video_cls): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (fc_video_loc): Linear(in_features=128, out_features=2, bias=True)\n",
            "  (fc_video_ctr): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (fc_text): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (fc_text_cls): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (fc_text_loc): Linear(in_features=128, out_features=2, bias=True)\n",
            "  (fc_text_ctr): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n",
            "[2025/03/08 20:16:56] [Train] Epoch: 1/300 Iter: 5/10 Time: 0.775 Data: 0.200 Loss: 0.1639/5.4187/1.3086/0.1579/1.5567/8.6057\n",
            "[2025/03/08 20:16:57] [Train] Epoch: 1/300 Iter: 10/10 Time: 0.466 Data: 0.100 Loss: 0.1552/5.6529/1.2557/0.1541/1.4312/8.6490\n",
            "[2025/03/08 20:16:59] [Eval]  Epoch: 1/300 F-score: 0.5704/0.5704\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:00] [Train] Epoch: 2/300 Iter: 5/10 Time: 0.399 Data: 0.095 Loss: 0.1413/4.7388/1.1520/0.1538/1.2471/7.4330\n",
            "[2025/03/08 20:17:01] [Train] Epoch: 2/300 Iter: 10/10 Time: 0.338 Data: 0.072 Loss: 0.1411/5.2571/1.1453/0.1596/1.2103/7.9135\n",
            "[2025/03/08 20:17:02] [Eval]  Epoch: 2/300 F-score: 0.5820/0.5820\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:03] [Train] Epoch: 3/300 Iter: 5/10 Time: 0.321 Data: 0.079 Loss: 0.1437/4.9898/1.1056/0.1554/1.1586/7.5531\n",
            "[2025/03/08 20:17:04] [Train] Epoch: 3/300 Iter: 10/10 Time: 0.286 Data: 0.066 Loss: 0.1425/5.1400/1.1194/0.1529/1.1642/7.7191\n",
            "[2025/03/08 20:17:05] [Eval]  Epoch: 3/300 F-score: 0.5945/0.5945\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:06] [Train] Epoch: 4/300 Iter: 5/10 Time: 0.280 Data: 0.066 Loss: 0.1422/5.0036/1.0907/0.1585/1.0388/7.4339\n",
            "[2025/03/08 20:17:06] [Train] Epoch: 4/300 Iter: 10/10 Time: 0.259 Data: 0.057 Loss: 0.1413/5.1312/1.0949/0.1564/1.1205/7.6444\n",
            "[2025/03/08 20:17:07] [Eval]  Epoch: 4/300 F-score: 0.5651/0.5945\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:09] [Train] Epoch: 5/300 Iter: 5/10 Time: 0.259 Data: 0.059 Loss: 0.1404/4.5866/1.0990/0.1607/1.1447/7.1315\n",
            "[2025/03/08 20:17:09] [Train] Epoch: 5/300 Iter: 10/10 Time: 0.247 Data: 0.053 Loss: 0.1405/5.1248/1.0967/0.1599/1.1345/7.6563\n",
            "[2025/03/08 20:17:10] [Eval]  Epoch: 5/300 F-score: 0.5857/0.5945\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:12] [Train] Epoch: 6/300 Iter: 5/10 Time: 0.259 Data: 0.064 Loss: 0.1391/5.0296/1.1174/0.1357/1.0558/7.4777\n",
            "[2025/03/08 20:17:13] [Train] Epoch: 6/300 Iter: 10/10 Time: 0.247 Data: 0.058 Loss: 0.1401/5.1430/1.0988/0.1425/1.1203/7.6447\n",
            "[2025/03/08 20:17:14] [Eval]  Epoch: 6/300 F-score: 0.6037/0.6037\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:15] [Train] Epoch: 7/300 Iter: 5/10 Time: 0.250 Data: 0.059 Loss: 0.1414/4.7987/1.0790/0.1646/1.1922/7.3758\n",
            "[2025/03/08 20:17:16] [Train] Epoch: 7/300 Iter: 10/10 Time: 0.239 Data: 0.055 Loss: 0.1403/5.1387/1.1006/0.1602/1.1333/7.6730\n",
            "[2025/03/08 20:17:16] [Eval]  Epoch: 7/300 F-score: 0.6039/0.6039\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:18] [Train] Epoch: 8/300 Iter: 5/10 Time: 0.242 Data: 0.059 Loss: 0.1417/5.4819/1.0671/0.1462/1.1559/7.9928\n",
            "[2025/03/08 20:17:18] [Train] Epoch: 8/300 Iter: 10/10 Time: 0.233 Data: 0.055 Loss: 0.1410/5.1564/1.0982/0.1479/1.1291/7.6726\n",
            "[2025/03/08 20:17:19] [Eval]  Epoch: 8/300 F-score: 0.5991/0.6039\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:21] [Train] Epoch: 9/300 Iter: 5/10 Time: 0.235 Data: 0.057 Loss: 0.1416/5.2441/1.0972/0.1568/1.1231/7.7629\n",
            "[2025/03/08 20:17:21] [Train] Epoch: 9/300 Iter: 10/10 Time: 0.227 Data: 0.054 Loss: 0.1409/5.1470/1.0936/0.1517/1.0837/7.6170\n",
            "[2025/03/08 20:17:22] [Eval]  Epoch: 9/300 F-score: 0.5957/0.6039\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:23] [Train] Epoch: 10/300 Iter: 5/10 Time: 0.233 Data: 0.055 Loss: 0.1428/4.6056/1.0977/0.1586/1.0278/7.0326\n",
            "[2025/03/08 20:17:24] [Train] Epoch: 10/300 Iter: 10/10 Time: 0.227 Data: 0.053 Loss: 0.1412/5.1364/1.0930/0.1602/1.1510/7.6819\n",
            "[2025/03/08 20:17:25] [Eval]  Epoch: 10/300 F-score: 0.5986/0.6039\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:27] [Train] Epoch: 11/300 Iter: 5/10 Time: 0.231 Data: 0.056 Loss: 0.1396/5.0211/1.0794/0.1497/1.1100/7.4997\n",
            "[2025/03/08 20:17:27] [Train] Epoch: 11/300 Iter: 10/10 Time: 0.225 Data: 0.053 Loss: 0.1417/5.1472/1.0982/0.1500/1.0348/7.5719\n",
            "[2025/03/08 20:17:28] [Eval]  Epoch: 11/300 F-score: 0.4978/0.6039\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:29] [Train] Epoch: 12/300 Iter: 5/10 Time: 0.226 Data: 0.054 Loss: 0.1492/4.9115/1.1608/0.1513/0.7130/7.0858\n",
            "[2025/03/08 20:17:30] [Train] Epoch: 12/300 Iter: 10/10 Time: 0.221 Data: 0.052 Loss: 0.1462/5.2135/1.0976/0.1447/0.8124/7.4144\n",
            "[2025/03/08 20:17:31] [Eval]  Epoch: 12/300 F-score: 0.5878/0.6039\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:32] [Train] Epoch: 13/300 Iter: 5/10 Time: 0.223 Data: 0.053 Loss: 0.1411/5.2424/1.0645/0.1535/1.1491/7.7506\n",
            "[2025/03/08 20:17:33] [Train] Epoch: 13/300 Iter: 10/10 Time: 0.219 Data: 0.051 Loss: 0.1400/5.1224/1.0869/0.1507/1.1964/7.6963\n",
            "[2025/03/08 20:17:33] [Eval]  Epoch: 13/300 F-score: 0.5865/0.6039\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:35] [Train] Epoch: 14/300 Iter: 5/10 Time: 0.221 Data: 0.053 Loss: 0.1379/4.5111/1.1150/0.1473/1.2432/7.1546\n",
            "[2025/03/08 20:17:35] [Train] Epoch: 14/300 Iter: 10/10 Time: 0.216 Data: 0.051 Loss: 0.1380/5.1182/1.0913/0.1405/1.1961/7.6841\n",
            "[2025/03/08 20:17:36] [Eval]  Epoch: 14/300 F-score: 0.5908/0.6039\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:38] [Train] Epoch: 15/300 Iter: 5/10 Time: 0.221 Data: 0.053 Loss: 0.1362/4.6926/1.0754/0.1613/1.2560/7.3215\n",
            "[2025/03/08 20:17:39] [Train] Epoch: 15/300 Iter: 10/10 Time: 0.220 Data: 0.052 Loss: 0.1366/5.1135/1.0897/0.1555/1.2687/7.7639\n",
            "[2025/03/08 20:17:40] [Eval]  Epoch: 15/300 F-score: 0.6051/0.6051\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:41] [Train] Epoch: 16/300 Iter: 5/10 Time: 0.221 Data: 0.053 Loss: 0.1369/4.5614/1.1209/0.1398/1.2470/7.2061\n",
            "[2025/03/08 20:17:42] [Train] Epoch: 16/300 Iter: 10/10 Time: 0.218 Data: 0.051 Loss: 0.1364/5.1093/1.0974/0.1458/1.2432/7.7322\n",
            "[2025/03/08 20:17:43] [Eval]  Epoch: 16/300 F-score: 0.6090/0.6090\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:44] [Train] Epoch: 17/300 Iter: 5/10 Time: 0.219 Data: 0.053 Loss: 0.1359/5.3695/1.0999/0.1470/1.1257/7.8779\n",
            "[2025/03/08 20:17:45] [Train] Epoch: 17/300 Iter: 10/10 Time: 0.216 Data: 0.052 Loss: 0.1366/5.1153/1.0876/0.1509/1.1046/7.5951\n",
            "[2025/03/08 20:17:46] [Eval]  Epoch: 17/300 F-score: 0.5894/0.6090\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:47] [Train] Epoch: 18/300 Iter: 5/10 Time: 0.218 Data: 0.053 Loss: 0.1375/5.2195/1.1042/0.1480/0.9709/7.5801\n",
            "[2025/03/08 20:17:48] [Train] Epoch: 18/300 Iter: 10/10 Time: 0.215 Data: 0.051 Loss: 0.1378/5.1363/1.0880/0.1593/0.9540/7.4753\n",
            "[2025/03/08 20:17:48] [Eval]  Epoch: 18/300 F-score: 0.5829/0.6090\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:50] [Train] Epoch: 19/300 Iter: 5/10 Time: 0.217 Data: 0.053 Loss: 0.1395/5.4107/1.0762/0.1481/0.8253/7.5997\n",
            "[2025/03/08 20:17:50] [Train] Epoch: 19/300 Iter: 10/10 Time: 0.215 Data: 0.051 Loss: 0.1406/5.1394/1.0945/0.1609/0.7791/7.3145\n",
            "[2025/03/08 20:17:52] [Eval]  Epoch: 19/300 F-score: 0.5966/0.6090\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:53] [Train] Epoch: 20/300 Iter: 5/10 Time: 0.218 Data: 0.054 Loss: 0.1421/5.0154/1.1019/0.1573/0.7889/7.2055\n",
            "[2025/03/08 20:17:54] [Train] Epoch: 20/300 Iter: 10/10 Time: 0.216 Data: 0.052 Loss: 0.1407/5.1276/1.0922/0.1494/0.8831/7.3930\n",
            "[2025/03/08 20:17:55] [Eval]  Epoch: 20/300 F-score: 0.6021/0.6090\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:56] [Train] Epoch: 21/300 Iter: 5/10 Time: 0.217 Data: 0.053 Loss: 0.1432/4.9443/1.1070/0.1662/0.7223/7.0830\n",
            "[2025/03/08 20:17:57] [Train] Epoch: 21/300 Iter: 10/10 Time: 0.214 Data: 0.052 Loss: 0.1481/5.1385/1.0933/0.1538/0.6458/7.1794\n",
            "[2025/03/08 20:17:57] [Eval]  Epoch: 21/300 F-score: 0.6004/0.6090\n",
            "\n",
            "\n",
            "[2025/03/08 20:17:59] [Train] Epoch: 22/300 Iter: 5/10 Time: 0.216 Data: 0.053 Loss: 0.1386/5.5618/1.0811/0.1620/1.0263/7.9698\n",
            "[2025/03/08 20:17:59] [Train] Epoch: 22/300 Iter: 10/10 Time: 0.213 Data: 0.052 Loss: 0.1379/5.0995/1.0920/0.1585/1.1680/7.6559\n",
            "[2025/03/08 20:18:00] [Eval]  Epoch: 22/300 F-score: 0.6091/0.6091\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:02] [Train] Epoch: 23/300 Iter: 5/10 Time: 0.214 Data: 0.052 Loss: 0.1364/4.8133/1.0901/0.1334/1.2220/7.3952\n",
            "[2025/03/08 20:18:02] [Train] Epoch: 23/300 Iter: 10/10 Time: 0.212 Data: 0.051 Loss: 0.1362/5.0901/1.0832/0.1430/1.1337/7.5862\n",
            "[2025/03/08 20:18:03] [Eval]  Epoch: 23/300 F-score: 0.6010/0.6091\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:04] [Train] Epoch: 24/300 Iter: 5/10 Time: 0.214 Data: 0.052 Loss: 0.1374/5.4594/1.0688/0.1677/1.0299/7.8632\n",
            "[2025/03/08 20:18:05] [Train] Epoch: 24/300 Iter: 10/10 Time: 0.213 Data: 0.051 Loss: 0.1377/5.1204/1.0777/0.1599/1.1052/7.6009\n",
            "[2025/03/08 20:18:06] [Eval]  Epoch: 24/300 F-score: 0.6142/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:08] [Train] Epoch: 25/300 Iter: 5/10 Time: 0.214 Data: 0.052 Loss: 0.1394/4.6894/1.0906/0.1627/1.0397/7.1218\n",
            "[2025/03/08 20:18:08] [Train] Epoch: 25/300 Iter: 10/10 Time: 0.212 Data: 0.051 Loss: 0.1380/5.1223/1.0955/0.1572/1.0905/7.6034\n",
            "[2025/03/08 20:18:09] [Eval]  Epoch: 25/300 F-score: 0.6141/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:10] [Train] Epoch: 26/300 Iter: 5/10 Time: 0.213 Data: 0.052 Loss: 0.1383/5.4475/1.0997/0.1506/1.0634/7.8996\n",
            "[2025/03/08 20:18:11] [Train] Epoch: 26/300 Iter: 10/10 Time: 0.211 Data: 0.051 Loss: 0.1389/5.1060/1.0971/0.1524/0.9552/7.4496\n",
            "[2025/03/08 20:18:12] [Eval]  Epoch: 26/300 F-score: 0.5979/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:13] [Train] Epoch: 27/300 Iter: 5/10 Time: 0.212 Data: 0.051 Loss: 0.1394/4.6964/1.0808/0.1492/0.8818/6.9475\n",
            "[2025/03/08 20:18:14] [Train] Epoch: 27/300 Iter: 10/10 Time: 0.210 Data: 0.050 Loss: 0.1383/5.0914/1.0769/0.1555/0.9031/7.3652\n",
            "[2025/03/08 20:18:14] [Eval]  Epoch: 27/300 F-score: 0.6039/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:16] [Train] Epoch: 28/300 Iter: 5/10 Time: 0.210 Data: 0.051 Loss: 0.1384/5.0557/1.1035/0.1501/0.8553/7.3030\n",
            "[2025/03/08 20:18:16] [Train] Epoch: 28/300 Iter: 10/10 Time: 0.209 Data: 0.050 Loss: 0.1390/5.1041/1.0813/0.1483/0.8124/7.2851\n",
            "[2025/03/08 20:18:17] [Eval]  Epoch: 28/300 F-score: 0.6095/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:19] [Train] Epoch: 29/300 Iter: 5/10 Time: 0.211 Data: 0.051 Loss: 0.1392/5.3346/1.0801/0.1472/0.6904/7.3915\n",
            "[2025/03/08 20:18:20] [Train] Epoch: 29/300 Iter: 10/10 Time: 0.210 Data: 0.051 Loss: 0.1387/5.0982/1.0754/0.1494/0.7935/7.2552\n",
            "[2025/03/08 20:18:21] [Eval]  Epoch: 29/300 F-score: 0.6113/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:22] [Train] Epoch: 30/300 Iter: 5/10 Time: 0.211 Data: 0.051 Loss: 0.1391/5.1863/1.0331/0.1642/0.9214/7.4441\n",
            "[2025/03/08 20:18:22] [Train] Epoch: 30/300 Iter: 10/10 Time: 0.209 Data: 0.050 Loss: 0.1385/5.0978/1.0683/0.1600/1.0809/7.5455\n",
            "[2025/03/08 20:18:23] [Eval]  Epoch: 30/300 F-score: 0.6111/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:24] [Train] Epoch: 31/300 Iter: 5/10 Time: 0.210 Data: 0.051 Loss: 0.1386/4.9909/1.0266/0.1534/0.8504/7.1598\n",
            "[2025/03/08 20:18:25] [Train] Epoch: 31/300 Iter: 10/10 Time: 0.208 Data: 0.050 Loss: 0.1390/5.1002/1.0602/0.1453/0.7967/7.2414\n",
            "[2025/03/08 20:18:26] [Eval]  Epoch: 31/300 F-score: 0.5941/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:27] [Train] Epoch: 32/300 Iter: 5/10 Time: 0.209 Data: 0.050 Loss: 0.1377/5.1696/1.0558/0.1554/0.8243/7.3428\n",
            "[2025/03/08 20:18:28] [Train] Epoch: 32/300 Iter: 10/10 Time: 0.207 Data: 0.049 Loss: 0.1391/5.1162/1.0663/0.1569/0.8304/7.3090\n",
            "[2025/03/08 20:18:28] [Eval]  Epoch: 32/300 F-score: 0.6002/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:30] [Train] Epoch: 33/300 Iter: 5/10 Time: 0.208 Data: 0.050 Loss: 0.1404/5.3731/1.0642/0.1609/0.6871/7.4258\n",
            "[2025/03/08 20:18:30] [Train] Epoch: 33/300 Iter: 10/10 Time: 0.206 Data: 0.049 Loss: 0.1396/5.1217/1.0675/0.1528/0.8386/7.3203\n",
            "[2025/03/08 20:18:31] [Eval]  Epoch: 33/300 F-score: 0.5817/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:33] [Train] Epoch: 34/300 Iter: 5/10 Time: 0.208 Data: 0.050 Loss: 0.1396/5.3088/1.0588/0.1460/1.0202/7.6734\n",
            "[2025/03/08 20:18:34] [Train] Epoch: 34/300 Iter: 10/10 Time: 0.207 Data: 0.049 Loss: 0.1394/5.0898/1.0424/0.1495/0.9841/7.4052\n",
            "[2025/03/08 20:18:35] [Eval]  Epoch: 34/300 F-score: 0.5794/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:36] [Train] Epoch: 35/300 Iter: 5/10 Time: 0.208 Data: 0.050 Loss: 0.1399/4.7279/1.0232/0.1446/0.7434/6.7790\n",
            "[2025/03/08 20:18:36] [Train] Epoch: 35/300 Iter: 10/10 Time: 0.207 Data: 0.049 Loss: 0.1399/5.0829/1.0296/0.1444/0.7788/7.1756\n",
            "[2025/03/08 20:18:37] [Eval]  Epoch: 35/300 F-score: 0.5942/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:38] [Train] Epoch: 36/300 Iter: 5/10 Time: 0.207 Data: 0.050 Loss: 0.1392/5.5425/1.0291/0.1475/0.8254/7.6838\n",
            "[2025/03/08 20:18:39] [Train] Epoch: 36/300 Iter: 10/10 Time: 0.206 Data: 0.049 Loss: 0.1399/5.0960/1.0207/0.1416/0.8231/7.2214\n",
            "[2025/03/08 20:18:40] [Eval]  Epoch: 36/300 F-score: 0.5711/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:41] [Train] Epoch: 37/300 Iter: 5/10 Time: 0.207 Data: 0.049 Loss: 0.1386/5.4366/1.0354/0.1380/0.8065/7.5552\n",
            "[2025/03/08 20:18:42] [Train] Epoch: 37/300 Iter: 10/10 Time: 0.205 Data: 0.049 Loss: 0.1404/5.0777/1.0256/0.1480/0.8505/7.2422\n",
            "[2025/03/08 20:18:42] [Eval]  Epoch: 37/300 F-score: 0.5437/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:44] [Train] Epoch: 38/300 Iter: 5/10 Time: 0.206 Data: 0.049 Loss: 0.1418/4.9908/1.0136/0.1474/0.9594/7.2529\n",
            "[2025/03/08 20:18:44] [Train] Epoch: 38/300 Iter: 10/10 Time: 0.205 Data: 0.049 Loss: 0.1450/5.1129/1.0284/0.1537/0.8689/7.3088\n",
            "[2025/03/08 20:18:45] [Eval]  Epoch: 38/300 F-score: 0.4872/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:47] [Train] Epoch: 39/300 Iter: 5/10 Time: 0.207 Data: 0.050 Loss: 0.1532/5.0457/1.0268/0.1434/0.6147/6.9838\n",
            "[2025/03/08 20:18:48] [Train] Epoch: 39/300 Iter: 10/10 Time: 0.206 Data: 0.049 Loss: 0.1519/5.2283/1.0384/0.1382/0.5779/7.1348\n",
            "[2025/03/08 20:18:49] [Eval]  Epoch: 39/300 F-score: 0.5289/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:50] [Train] Epoch: 40/300 Iter: 5/10 Time: 0.206 Data: 0.049 Loss: 0.1428/5.7303/0.9782/0.1513/0.6975/7.7001\n",
            "[2025/03/08 20:18:50] [Train] Epoch: 40/300 Iter: 10/10 Time: 0.205 Data: 0.049 Loss: 0.1431/5.2001/1.0246/0.1429/0.7364/7.2472\n",
            "[2025/03/08 20:18:51] [Eval]  Epoch: 40/300 F-score: 0.5857/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:52] [Train] Epoch: 41/300 Iter: 5/10 Time: 0.206 Data: 0.049 Loss: 0.1408/4.9242/0.9625/0.1480/0.7937/6.9691\n",
            "[2025/03/08 20:18:53] [Train] Epoch: 41/300 Iter: 10/10 Time: 0.204 Data: 0.049 Loss: 0.1405/5.0756/0.9949/0.1461/0.7745/7.1317\n",
            "[2025/03/08 20:18:54] [Eval]  Epoch: 41/300 F-score: 0.5777/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:55] [Train] Epoch: 42/300 Iter: 5/10 Time: 0.205 Data: 0.049 Loss: 0.1402/5.7177/0.9554/0.1413/0.6902/7.6448\n",
            "[2025/03/08 20:18:56] [Train] Epoch: 42/300 Iter: 10/10 Time: 0.204 Data: 0.048 Loss: 0.1416/5.0732/0.9822/0.1437/0.6603/7.0010\n",
            "[2025/03/08 20:18:56] [Eval]  Epoch: 42/300 F-score: 0.5346/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:18:58] [Train] Epoch: 43/300 Iter: 5/10 Time: 0.204 Data: 0.049 Loss: 0.1415/4.9247/0.9600/0.1412/0.6308/6.7983\n",
            "[2025/03/08 20:18:58] [Train] Epoch: 43/300 Iter: 10/10 Time: 0.203 Data: 0.048 Loss: 0.1418/5.0885/0.9943/0.1454/0.8197/7.1897\n",
            "[2025/03/08 20:18:59] [Eval]  Epoch: 43/300 F-score: 0.5753/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:01] [Train] Epoch: 44/300 Iter: 5/10 Time: 0.205 Data: 0.049 Loss: 0.1455/5.4864/0.9166/0.1459/0.9982/7.6925\n",
            "[2025/03/08 20:19:02] [Train] Epoch: 44/300 Iter: 10/10 Time: 0.204 Data: 0.048 Loss: 0.1436/5.1204/0.9812/0.1466/0.8799/7.2717\n",
            "[2025/03/08 20:19:02] [Eval]  Epoch: 44/300 F-score: 0.5593/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:04] [Train] Epoch: 45/300 Iter: 5/10 Time: 0.204 Data: 0.049 Loss: 0.1417/4.6667/0.9755/0.1561/0.7284/6.6683\n",
            "[2025/03/08 20:19:04] [Train] Epoch: 45/300 Iter: 10/10 Time: 0.203 Data: 0.048 Loss: 0.1400/5.1229/0.9812/0.1478/0.7965/7.1884\n",
            "[2025/03/08 20:19:05] [Eval]  Epoch: 45/300 F-score: 0.5639/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:06] [Train] Epoch: 46/300 Iter: 5/10 Time: 0.204 Data: 0.049 Loss: 0.1380/5.2345/0.9981/0.1403/0.8849/7.3959\n",
            "[2025/03/08 20:19:07] [Train] Epoch: 46/300 Iter: 10/10 Time: 0.203 Data: 0.048 Loss: 0.1398/5.0694/0.9653/0.1483/0.9141/7.2368\n",
            "[2025/03/08 20:19:08] [Eval]  Epoch: 46/300 F-score: 0.5689/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:09] [Train] Epoch: 47/300 Iter: 5/10 Time: 0.203 Data: 0.049 Loss: 0.1396/5.6246/0.9738/0.1512/1.0711/7.9603\n",
            "[2025/03/08 20:19:09] [Train] Epoch: 47/300 Iter: 10/10 Time: 0.202 Data: 0.048 Loss: 0.1399/5.0707/0.9679/0.1506/0.9464/7.2755\n",
            "[2025/03/08 20:19:10] [Eval]  Epoch: 47/300 F-score: 0.5763/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:11] [Train] Epoch: 48/300 Iter: 5/10 Time: 0.203 Data: 0.049 Loss: 0.1395/4.5486/1.0226/0.1464/0.8802/6.7374\n",
            "[2025/03/08 20:19:12] [Train] Epoch: 48/300 Iter: 10/10 Time: 0.202 Data: 0.048 Loss: 0.1395/5.0723/0.9765/0.1471/0.8567/7.1922\n",
            "[2025/03/08 20:19:13] [Eval]  Epoch: 48/300 F-score: 0.5620/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:15] [Train] Epoch: 49/300 Iter: 5/10 Time: 0.203 Data: 0.049 Loss: 0.1403/4.4387/0.9590/0.1360/0.8436/6.5176\n",
            "[2025/03/08 20:19:15] [Train] Epoch: 49/300 Iter: 10/10 Time: 0.203 Data: 0.049 Loss: 0.1395/5.0546/0.9672/0.1398/0.9032/7.2042\n",
            "[2025/03/08 20:19:16] [Eval]  Epoch: 49/300 F-score: 0.5671/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:18] [Train] Epoch: 50/300 Iter: 5/10 Time: 0.203 Data: 0.049 Loss: 0.1392/4.9388/0.9659/0.1514/0.9216/7.1169\n",
            "[2025/03/08 20:19:18] [Train] Epoch: 50/300 Iter: 10/10 Time: 0.202 Data: 0.048 Loss: 0.1400/5.0532/0.9524/0.1465/0.8422/7.1343\n",
            "[2025/03/08 20:19:19] [Eval]  Epoch: 50/300 F-score: 0.5674/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:20] [Train] Epoch: 51/300 Iter: 5/10 Time: 0.203 Data: 0.049 Loss: 0.1396/5.0592/0.9527/0.1478/0.8463/7.1457\n",
            "[2025/03/08 20:19:21] [Train] Epoch: 51/300 Iter: 10/10 Time: 0.202 Data: 0.048 Loss: 0.1398/5.0629/0.9453/0.1510/0.7362/7.0353\n",
            "[2025/03/08 20:19:21] [Eval]  Epoch: 51/300 F-score: 0.5559/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:23] [Train] Epoch: 52/300 Iter: 5/10 Time: 0.202 Data: 0.048 Loss: 0.1394/4.5442/0.9379/0.1456/0.8800/6.6472\n",
            "[2025/03/08 20:19:23] [Train] Epoch: 52/300 Iter: 10/10 Time: 0.201 Data: 0.048 Loss: 0.1387/5.0585/0.9262/0.1407/0.9260/7.1901\n",
            "[2025/03/08 20:19:24] [Eval]  Epoch: 52/300 F-score: 0.5682/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:26] [Train] Epoch: 53/300 Iter: 5/10 Time: 0.202 Data: 0.048 Loss: 0.1381/4.7709/0.9288/0.1471/0.7928/6.7776\n",
            "[2025/03/08 20:19:26] [Train] Epoch: 53/300 Iter: 10/10 Time: 0.202 Data: 0.048 Loss: 0.1387/5.0410/0.9220/0.1472/0.8348/7.0837\n",
            "[2025/03/08 20:19:28] [Eval]  Epoch: 53/300 F-score: 0.5875/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:29] [Train] Epoch: 54/300 Iter: 5/10 Time: 0.203 Data: 0.049 Loss: 0.1404/4.7869/0.9238/0.1504/0.7811/6.7825\n",
            "[2025/03/08 20:19:29] [Train] Epoch: 54/300 Iter: 10/10 Time: 0.202 Data: 0.048 Loss: 0.1396/5.0625/0.9302/0.1429/0.8020/7.0772\n",
            "[2025/03/08 20:19:30] [Eval]  Epoch: 54/300 F-score: 0.5848/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:31] [Train] Epoch: 55/300 Iter: 5/10 Time: 0.202 Data: 0.048 Loss: 0.1406/5.0841/0.9080/0.1571/0.8235/7.1133\n",
            "[2025/03/08 20:19:32] [Train] Epoch: 55/300 Iter: 10/10 Time: 0.201 Data: 0.048 Loss: 0.1391/5.0609/0.9259/0.1542/0.8383/7.1183\n",
            "[2025/03/08 20:19:33] [Eval]  Epoch: 55/300 F-score: 0.5536/0.6142\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:34] [Train] Epoch: 56/300 Iter: 5/10 Time: 0.202 Data: 0.048 Loss: 0.1391/5.1530/0.9957/0.1487/0.8087/7.2452\n",
            "[2025/03/08 20:19:34] [Train] Epoch: 56/300 Iter: 10/10 Time: 0.201 Data: 0.048 Loss: 0.1390/5.0608/0.9556/0.1475/0.8220/7.1248\n",
            "[2025/03/08 20:19:35] [Eval]  Epoch: 56/300 F-score: 0.6178/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:37] [Train] Epoch: 57/300 Iter: 5/10 Time: 0.201 Data: 0.048 Loss: 0.1389/5.1132/0.8749/0.1526/0.9319/7.2115\n",
            "[2025/03/08 20:19:37] [Train] Epoch: 57/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1387/5.0350/0.9224/0.1489/0.8698/7.1148\n",
            "[2025/03/08 20:19:38] [Eval]  Epoch: 57/300 F-score: 0.6136/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:40] [Train] Epoch: 58/300 Iter: 5/10 Time: 0.202 Data: 0.049 Loss: 0.1373/5.1801/0.8741/0.1446/0.8763/7.2124\n",
            "[2025/03/08 20:19:40] [Train] Epoch: 58/300 Iter: 10/10 Time: 0.201 Data: 0.048 Loss: 0.1393/5.0448/0.9116/0.1464/0.8221/7.0642\n",
            "[2025/03/08 20:19:41] [Eval]  Epoch: 58/300 F-score: 0.5850/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:43] [Train] Epoch: 59/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1385/5.3884/0.9084/0.1366/0.8499/7.4218\n",
            "[2025/03/08 20:19:43] [Train] Epoch: 59/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1388/5.0600/0.9231/0.1413/0.7920/7.0552\n",
            "[2025/03/08 20:19:44] [Eval]  Epoch: 59/300 F-score: 0.5747/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:45] [Train] Epoch: 60/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1379/4.8950/0.9108/0.1432/0.8461/6.9330\n",
            "[2025/03/08 20:19:46] [Train] Epoch: 60/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1382/5.0210/0.9421/0.1427/0.8284/7.0723\n",
            "[2025/03/08 20:19:46] [Eval]  Epoch: 60/300 F-score: 0.5990/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:48] [Train] Epoch: 61/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1386/5.4315/0.8966/0.1429/0.7779/7.3875\n",
            "[2025/03/08 20:19:48] [Train] Epoch: 61/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1388/5.0233/0.9257/0.1429/0.7753/7.0060\n",
            "[2025/03/08 20:19:49] [Eval]  Epoch: 61/300 F-score: 0.6084/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:50] [Train] Epoch: 62/300 Iter: 5/10 Time: 0.200 Data: 0.048 Loss: 0.1395/4.8788/0.9100/0.1454/0.6915/6.7651\n",
            "[2025/03/08 20:19:51] [Train] Epoch: 62/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1384/5.0326/0.9170/0.1420/0.7090/6.9389\n",
            "[2025/03/08 20:19:52] [Eval]  Epoch: 62/300 F-score: 0.5876/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:54] [Train] Epoch: 63/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1367/5.5134/0.8819/0.1476/0.7468/7.4264\n",
            "[2025/03/08 20:19:55] [Train] Epoch: 63/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1378/5.0307/0.9036/0.1462/0.7376/6.9561\n",
            "[2025/03/08 20:19:56] [Eval]  Epoch: 63/300 F-score: 0.5706/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:57] [Train] Epoch: 64/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1374/4.6367/0.9319/0.1442/0.7343/6.5845\n",
            "[2025/03/08 20:19:57] [Train] Epoch: 64/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1377/5.0011/0.9158/0.1497/0.7004/6.9047\n",
            "[2025/03/08 20:19:58] [Eval]  Epoch: 64/300 F-score: 0.5978/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:19:59] [Train] Epoch: 65/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1377/5.4442/0.8748/0.1434/0.6735/7.2736\n",
            "[2025/03/08 20:20:00] [Train] Epoch: 65/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1380/4.9856/0.9001/0.1463/0.6809/6.8508\n",
            "[2025/03/08 20:20:01] [Eval]  Epoch: 65/300 F-score: 0.6121/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:02] [Train] Epoch: 66/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1376/5.2089/0.9420/0.1496/0.7593/7.1975\n",
            "[2025/03/08 20:20:03] [Train] Epoch: 66/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1382/4.9839/0.8992/0.1473/0.7003/6.8689\n",
            "[2025/03/08 20:20:03] [Eval]  Epoch: 66/300 F-score: 0.5793/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:05] [Train] Epoch: 67/300 Iter: 5/10 Time: 0.200 Data: 0.048 Loss: 0.1379/5.4104/0.8651/0.1476/0.7768/7.3377\n",
            "[2025/03/08 20:20:05] [Train] Epoch: 67/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1377/4.9732/0.8893/0.1456/0.7102/6.8559\n",
            "[2025/03/08 20:20:06] [Eval]  Epoch: 67/300 F-score: 0.5789/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:08] [Train] Epoch: 68/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1388/4.6308/0.9172/0.1446/0.6144/6.4457\n",
            "[2025/03/08 20:20:09] [Train] Epoch: 68/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1376/4.9637/0.8966/0.1412/0.6453/6.7843\n",
            "[2025/03/08 20:20:10] [Eval]  Epoch: 68/300 F-score: 0.6000/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:11] [Train] Epoch: 69/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1364/4.7516/0.9309/0.1541/0.6372/6.6102\n",
            "[2025/03/08 20:20:11] [Train] Epoch: 69/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1383/4.9676/0.8906/0.1498/0.6385/6.7848\n",
            "[2025/03/08 20:20:12] [Eval]  Epoch: 69/300 F-score: 0.5812/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:13] [Train] Epoch: 70/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1385/4.7764/0.8613/0.1432/0.5295/6.4489\n",
            "[2025/03/08 20:20:14] [Train] Epoch: 70/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1387/4.9919/0.8919/0.1434/0.5682/6.7342\n",
            "[2025/03/08 20:20:15] [Eval]  Epoch: 70/300 F-score: 0.5613/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:16] [Train] Epoch: 71/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1395/4.9683/0.9004/0.1489/0.5681/6.7253\n",
            "[2025/03/08 20:20:17] [Train] Epoch: 71/300 Iter: 10/10 Time: 0.199 Data: 0.048 Loss: 0.1395/5.0064/0.8963/0.1479/0.5665/6.7565\n",
            "[2025/03/08 20:20:17] [Eval]  Epoch: 71/300 F-score: 0.5953/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:19] [Train] Epoch: 72/300 Iter: 5/10 Time: 0.200 Data: 0.048 Loss: 0.1393/5.1581/0.8809/0.1480/0.6954/7.0217\n",
            "[2025/03/08 20:20:20] [Train] Epoch: 72/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1390/5.0052/0.8944/0.1465/0.6409/6.8261\n",
            "[2025/03/08 20:20:21] [Eval]  Epoch: 72/300 F-score: 0.5528/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:22] [Train] Epoch: 73/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.5260/0.9116/0.1511/0.9032/6.6309\n",
            "[2025/03/08 20:20:23] [Train] Epoch: 73/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1388/5.0215/0.8921/0.1560/0.8509/7.0592\n",
            "[2025/03/08 20:20:24] [Eval]  Epoch: 73/300 F-score: 0.5769/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:25] [Train] Epoch: 74/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1391/4.9905/0.9162/0.1558/0.7994/7.0009\n",
            "[2025/03/08 20:20:26] [Train] Epoch: 74/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1397/4.9881/0.9006/0.1516/0.8469/7.0270\n",
            "[2025/03/08 20:20:26] [Eval]  Epoch: 74/300 F-score: 0.5900/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:28] [Train] Epoch: 75/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1391/5.0619/0.8624/0.1426/0.8449/7.0510\n",
            "[2025/03/08 20:20:28] [Train] Epoch: 75/300 Iter: 10/10 Time: 0.199 Data: 0.048 Loss: 0.1396/4.9962/0.8804/0.1455/0.7694/6.9312\n",
            "[2025/03/08 20:20:29] [Eval]  Epoch: 75/300 F-score: 0.5704/0.6178\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:30] [Train] Epoch: 76/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.7153/0.9529/0.1517/0.7778/6.7365\n",
            "[2025/03/08 20:20:31] [Train] Epoch: 76/300 Iter: 10/10 Time: 0.199 Data: 0.048 Loss: 0.1401/5.0068/0.8968/0.1465/0.8221/7.0124\n",
            "[2025/03/08 20:20:32] [Eval]  Epoch: 76/300 F-score: 0.6259/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:34] [Train] Epoch: 77/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1403/5.2467/0.8837/0.1607/0.8247/7.2560\n",
            "[2025/03/08 20:20:34] [Train] Epoch: 77/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1390/4.9934/0.9045/0.1583/0.8521/7.0474\n",
            "[2025/03/08 20:20:35] [Eval]  Epoch: 77/300 F-score: 0.6029/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:37] [Train] Epoch: 78/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1391/5.1527/0.8948/0.1443/0.8379/7.1688\n",
            "[2025/03/08 20:20:37] [Train] Epoch: 78/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1380/4.9809/0.8926/0.1486/0.8127/6.9728\n",
            "[2025/03/08 20:20:38] [Eval]  Epoch: 78/300 F-score: 0.6104/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:39] [Train] Epoch: 79/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1398/5.0084/0.8872/0.1465/0.6785/6.8602\n",
            "[2025/03/08 20:20:40] [Train] Epoch: 79/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1388/4.9997/0.8941/0.1478/0.6601/6.8404\n",
            "[2025/03/08 20:20:41] [Eval]  Epoch: 79/300 F-score: 0.6061/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:42] [Train] Epoch: 80/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1393/4.4016/0.8773/0.1510/0.5976/6.1668\n",
            "[2025/03/08 20:20:43] [Train] Epoch: 80/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1379/4.9861/0.8806/0.1446/0.6232/6.7724\n",
            "[2025/03/08 20:20:44] [Eval]  Epoch: 80/300 F-score: 0.6256/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:45] [Train] Epoch: 81/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1375/5.2959/0.8829/0.1466/0.6654/7.1283\n",
            "[2025/03/08 20:20:46] [Train] Epoch: 81/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1389/4.9860/0.8825/0.1441/0.6520/6.8035\n",
            "[2025/03/08 20:20:47] [Eval]  Epoch: 81/300 F-score: 0.6172/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:49] [Train] Epoch: 82/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1392/5.8239/0.9212/0.1541/0.5969/7.6353\n",
            "[2025/03/08 20:20:50] [Train] Epoch: 82/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1384/5.0035/0.9260/0.1528/0.5739/6.7946\n",
            "[2025/03/08 20:20:50] [Eval]  Epoch: 82/300 F-score: 0.5938/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:52] [Train] Epoch: 83/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1391/5.6679/0.8923/0.1406/0.4644/7.3042\n",
            "[2025/03/08 20:20:52] [Train] Epoch: 83/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.9862/0.9209/0.1435/0.4708/6.6602\n",
            "[2025/03/08 20:20:53] [Eval]  Epoch: 83/300 F-score: 0.5933/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:55] [Train] Epoch: 84/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1389/5.7080/0.9210/0.1451/0.4836/7.3966\n",
            "[2025/03/08 20:20:55] [Train] Epoch: 84/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1394/4.9861/0.8954/0.1449/0.4518/6.6175\n",
            "[2025/03/08 20:20:56] [Eval]  Epoch: 84/300 F-score: 0.6031/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:20:57] [Train] Epoch: 85/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1396/4.6154/0.8990/0.1426/0.4408/6.2373\n",
            "[2025/03/08 20:20:58] [Train] Epoch: 85/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1390/4.9879/0.8947/0.1411/0.4868/6.6495\n",
            "[2025/03/08 20:20:59] [Eval]  Epoch: 85/300 F-score: 0.5773/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:00] [Train] Epoch: 86/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1407/5.0081/0.8739/0.1413/0.7082/6.8720\n",
            "[2025/03/08 20:21:01] [Train] Epoch: 86/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1395/4.9977/0.8821/0.1453/0.7785/6.9431\n",
            "[2025/03/08 20:21:02] [Eval]  Epoch: 86/300 F-score: 0.5854/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:04] [Train] Epoch: 87/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1394/5.2336/0.9131/0.1500/0.5752/7.0113\n",
            "[2025/03/08 20:21:04] [Train] Epoch: 87/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.9854/0.8883/0.1415/0.5997/6.7539\n",
            "[2025/03/08 20:21:05] [Eval]  Epoch: 87/300 F-score: 0.5892/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:06] [Train] Epoch: 88/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1405/5.6975/0.8240/0.1354/0.7800/7.5775\n",
            "[2025/03/08 20:21:07] [Train] Epoch: 88/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1396/4.9732/0.8873/0.1395/0.7480/6.8877\n",
            "[2025/03/08 20:21:08] [Eval]  Epoch: 88/300 F-score: 0.5792/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:09] [Train] Epoch: 89/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1394/5.3330/0.8831/0.1360/0.5424/7.0340\n",
            "[2025/03/08 20:21:10] [Train] Epoch: 89/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1393/4.9470/0.8774/0.1387/0.6014/6.7037\n",
            "[2025/03/08 20:21:10] [Eval]  Epoch: 89/300 F-score: 0.6048/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:12] [Train] Epoch: 90/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1400/4.3853/0.8888/0.1398/0.7026/6.2566\n",
            "[2025/03/08 20:21:12] [Train] Epoch: 90/300 Iter: 10/10 Time: 0.200 Data: 0.048 Loss: 0.1392/4.9527/0.8724/0.1414/0.7837/6.8893\n",
            "[2025/03/08 20:21:13] [Eval]  Epoch: 90/300 F-score: 0.6097/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:15] [Train] Epoch: 91/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1400/4.8755/0.9285/0.1518/0.9236/7.0194\n",
            "[2025/03/08 20:21:16] [Train] Epoch: 91/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1395/4.9785/0.8722/0.1486/0.8989/7.0377\n",
            "[2025/03/08 20:21:17] [Eval]  Epoch: 91/300 F-score: 0.5951/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:18] [Train] Epoch: 92/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1394/4.4497/0.8683/0.1505/0.8133/6.4213\n",
            "[2025/03/08 20:21:19] [Train] Epoch: 92/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1391/4.9237/0.8682/0.1494/0.7719/6.8523\n",
            "[2025/03/08 20:21:19] [Eval]  Epoch: 92/300 F-score: 0.6004/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:21] [Train] Epoch: 93/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1377/5.2079/0.9226/0.1404/0.7127/7.1213\n",
            "[2025/03/08 20:21:21] [Train] Epoch: 93/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1386/4.9565/0.8839/0.1445/0.6361/6.7596\n",
            "[2025/03/08 20:21:22] [Eval]  Epoch: 93/300 F-score: 0.5852/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:24] [Train] Epoch: 94/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1396/4.9123/0.8332/0.1444/0.5368/6.5663\n",
            "[2025/03/08 20:21:24] [Train] Epoch: 94/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1386/4.9250/0.8646/0.1413/0.5715/6.6411\n",
            "[2025/03/08 20:21:25] [Eval]  Epoch: 94/300 F-score: 0.5907/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:26] [Train] Epoch: 95/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1381/5.1191/0.8497/0.1503/0.6722/6.9294\n",
            "[2025/03/08 20:21:27] [Train] Epoch: 95/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1390/4.9218/0.8756/0.1484/0.5988/6.6836\n",
            "[2025/03/08 20:21:28] [Eval]  Epoch: 95/300 F-score: 0.5831/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:30] [Train] Epoch: 96/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1389/5.5583/0.8402/0.1511/0.6073/7.2959\n",
            "[2025/03/08 20:21:30] [Train] Epoch: 96/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1391/4.9070/0.8681/0.1507/0.5479/6.6129\n",
            "[2025/03/08 20:21:31] [Eval]  Epoch: 96/300 F-score: 0.6152/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:32] [Train] Epoch: 97/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1402/5.1179/0.8571/0.1556/0.5366/6.8074\n",
            "[2025/03/08 20:21:33] [Train] Epoch: 97/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.9210/0.8609/0.1469/0.6011/6.6689\n",
            "[2025/03/08 20:21:34] [Eval]  Epoch: 97/300 F-score: 0.5924/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:35] [Train] Epoch: 98/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1382/4.7694/0.8935/0.1506/0.5979/6.5497\n",
            "[2025/03/08 20:21:36] [Train] Epoch: 98/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1384/4.9070/0.8736/0.1481/0.5758/6.6430\n",
            "[2025/03/08 20:21:37] [Eval]  Epoch: 98/300 F-score: 0.6044/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:38] [Train] Epoch: 99/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1381/5.0019/0.8910/0.1456/0.5702/6.7469\n",
            "[2025/03/08 20:21:38] [Train] Epoch: 99/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1386/4.9562/0.8786/0.1460/0.5845/6.7040\n",
            "[2025/03/08 20:21:39] [Eval]  Epoch: 99/300 F-score: 0.6155/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:41] [Train] Epoch: 100/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1374/5.0576/0.8483/0.1419/0.6975/6.8827\n",
            "[2025/03/08 20:21:42] [Train] Epoch: 100/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1387/4.9227/0.8644/0.1433/0.6827/6.7517\n",
            "[2025/03/08 20:21:43] [Eval]  Epoch: 100/300 F-score: 0.5649/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:44] [Train] Epoch: 101/300 Iter: 5/10 Time: 0.201 Data: 0.049 Loss: 0.1395/4.9608/0.8743/0.1609/0.7338/6.8693\n",
            "[2025/03/08 20:21:45] [Train] Epoch: 101/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1396/4.9069/0.8695/0.1522/0.6494/6.7177\n",
            "[2025/03/08 20:21:46] [Eval]  Epoch: 101/300 F-score: 0.5992/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:47] [Train] Epoch: 102/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1385/4.9464/0.8538/0.1361/0.6015/6.6763\n",
            "[2025/03/08 20:21:48] [Train] Epoch: 102/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.9177/0.8475/0.1379/0.6050/6.6470\n",
            "[2025/03/08 20:21:48] [Eval]  Epoch: 102/300 F-score: 0.6251/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:50] [Train] Epoch: 103/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1385/4.5870/0.8563/0.1448/0.6040/6.3305\n",
            "[2025/03/08 20:21:50] [Train] Epoch: 103/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1390/4.8780/0.8579/0.1460/0.6384/6.6593\n",
            "[2025/03/08 20:21:51] [Eval]  Epoch: 103/300 F-score: 0.6241/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:52] [Train] Epoch: 104/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1399/4.5719/0.8746/0.1433/0.7542/6.4839\n",
            "[2025/03/08 20:21:53] [Train] Epoch: 104/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1394/4.8559/0.8571/0.1412/0.7277/6.7213\n",
            "[2025/03/08 20:21:54] [Eval]  Epoch: 104/300 F-score: 0.6210/0.6259\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:56] [Train] Epoch: 105/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1384/5.1173/0.8288/0.1346/0.6146/6.8337\n",
            "[2025/03/08 20:21:56] [Train] Epoch: 105/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1384/4.8634/0.8460/0.1394/0.7048/6.6922\n",
            "[2025/03/08 20:21:57] [Eval]  Epoch: 105/300 F-score: 0.6294/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:21:59] [Train] Epoch: 106/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1386/4.9545/0.8234/0.1448/0.6761/6.7374\n",
            "[2025/03/08 20:21:59] [Train] Epoch: 106/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1391/4.8618/0.8567/0.1467/0.6559/6.6602\n",
            "[2025/03/08 20:22:00] [Eval]  Epoch: 106/300 F-score: 0.6043/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:01] [Train] Epoch: 107/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1387/5.0939/0.8388/0.1473/0.6807/6.8993\n",
            "[2025/03/08 20:22:02] [Train] Epoch: 107/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1388/4.8738/0.8469/0.1464/0.6122/6.6182\n",
            "[2025/03/08 20:22:03] [Eval]  Epoch: 107/300 F-score: 0.6099/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:04] [Train] Epoch: 108/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1379/5.0334/0.8316/0.1456/0.6222/6.7707\n",
            "[2025/03/08 20:22:04] [Train] Epoch: 108/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1386/4.8598/0.8515/0.1405/0.6300/6.6203\n",
            "[2025/03/08 20:22:05] [Eval]  Epoch: 108/300 F-score: 0.6045/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:07] [Train] Epoch: 109/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1386/5.0193/0.8572/0.1411/0.6272/6.7835\n",
            "[2025/03/08 20:22:07] [Train] Epoch: 109/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1388/4.8458/0.8542/0.1416/0.6016/6.5819\n",
            "[2025/03/08 20:22:08] [Eval]  Epoch: 109/300 F-score: 0.5820/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:10] [Train] Epoch: 110/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1379/4.7609/0.8211/0.1394/0.6285/6.4879\n",
            "[2025/03/08 20:22:11] [Train] Epoch: 110/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1385/4.8252/0.8308/0.1462/0.6864/6.6271\n",
            "[2025/03/08 20:22:12] [Eval]  Epoch: 110/300 F-score: 0.5744/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:13] [Train] Epoch: 111/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1379/5.0352/0.8482/0.1493/0.6997/6.8703\n",
            "[2025/03/08 20:22:13] [Train] Epoch: 111/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1382/4.8410/0.8522/0.1419/0.6433/6.6166\n",
            "[2025/03/08 20:22:14] [Eval]  Epoch: 111/300 F-score: 0.5999/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:15] [Train] Epoch: 112/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1396/4.7189/0.8485/0.1408/0.6113/6.4591\n",
            "[2025/03/08 20:22:16] [Train] Epoch: 112/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1386/4.8242/0.8505/0.1435/0.7352/6.6920\n",
            "[2025/03/08 20:22:17] [Eval]  Epoch: 112/300 F-score: 0.5691/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:18] [Train] Epoch: 113/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.5742/0.8512/0.1374/0.7581/6.4597\n",
            "[2025/03/08 20:22:19] [Train] Epoch: 113/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1389/4.8415/0.8584/0.1418/0.7006/6.6813\n",
            "[2025/03/08 20:22:19] [Eval]  Epoch: 113/300 F-score: 0.5813/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:21] [Train] Epoch: 114/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1388/5.0205/0.9006/0.1408/0.6184/6.8191\n",
            "[2025/03/08 20:22:22] [Train] Epoch: 114/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.8310/0.8647/0.1429/0.6319/6.6094\n",
            "[2025/03/08 20:22:23] [Eval]  Epoch: 114/300 F-score: 0.5898/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:24] [Train] Epoch: 115/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1385/4.8960/0.8539/0.1474/0.6125/6.6482\n",
            "[2025/03/08 20:22:25] [Train] Epoch: 115/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.8415/0.8527/0.1429/0.6521/6.6282\n",
            "[2025/03/08 20:22:26] [Eval]  Epoch: 115/300 F-score: 0.5684/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:27] [Train] Epoch: 116/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1375/4.8151/0.8700/0.1463/0.6323/6.6013\n",
            "[2025/03/08 20:22:28] [Train] Epoch: 116/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1384/4.8106/0.8508/0.1418/0.6424/6.5841\n",
            "[2025/03/08 20:22:29] [Eval]  Epoch: 116/300 F-score: 0.5862/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:30] [Train] Epoch: 117/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1395/4.1218/0.8767/0.1420/0.5647/5.8447\n",
            "[2025/03/08 20:22:30] [Train] Epoch: 117/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1392/4.8139/0.8448/0.1418/0.6059/6.5456\n",
            "[2025/03/08 20:22:31] [Eval]  Epoch: 117/300 F-score: 0.5914/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:33] [Train] Epoch: 118/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1402/5.0962/0.7947/0.1457/0.6634/6.8401\n",
            "[2025/03/08 20:22:33] [Train] Epoch: 118/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1389/4.8276/0.8494/0.1455/0.6391/6.6004\n",
            "[2025/03/08 20:22:34] [Eval]  Epoch: 118/300 F-score: 0.5914/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:36] [Train] Epoch: 119/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1400/4.1241/0.8609/0.1417/0.6291/5.8958\n",
            "[2025/03/08 20:22:36] [Train] Epoch: 119/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1394/4.8093/0.8546/0.1380/0.5888/6.5301\n",
            "[2025/03/08 20:22:38] [Eval]  Epoch: 119/300 F-score: 0.5714/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:39] [Train] Epoch: 120/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1391/4.6847/0.7673/0.1331/0.6236/6.3477\n",
            "[2025/03/08 20:22:39] [Train] Epoch: 120/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1390/4.8264/0.8412/0.1379/0.6698/6.6144\n",
            "[2025/03/08 20:22:40] [Eval]  Epoch: 120/300 F-score: 0.5886/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:41] [Train] Epoch: 121/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1385/4.4253/0.8694/0.1433/0.5514/6.1280\n",
            "[2025/03/08 20:22:42] [Train] Epoch: 121/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1386/4.8469/0.8609/0.1447/0.5726/6.5636\n",
            "[2025/03/08 20:22:43] [Eval]  Epoch: 121/300 F-score: 0.6119/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:44] [Train] Epoch: 122/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1365/5.0457/0.8774/0.1481/0.8028/7.0105\n",
            "[2025/03/08 20:22:45] [Train] Epoch: 122/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1384/4.8224/0.8586/0.1479/0.7851/6.7524\n",
            "[2025/03/08 20:22:45] [Eval]  Epoch: 122/300 F-score: 0.6129/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:47] [Train] Epoch: 123/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1396/4.8222/0.8251/0.1411/0.8005/6.7287\n",
            "[2025/03/08 20:22:47] [Train] Epoch: 123/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1387/4.8153/0.8427/0.1428/0.7936/6.7331\n",
            "[2025/03/08 20:22:48] [Eval]  Epoch: 123/300 F-score: 0.6008/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:50] [Train] Epoch: 124/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1388/4.2553/0.9081/0.1285/0.7294/6.1601\n",
            "[2025/03/08 20:22:51] [Train] Epoch: 124/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1391/4.8325/0.8530/0.1354/0.6730/6.6330\n",
            "[2025/03/08 20:22:52] [Eval]  Epoch: 124/300 F-score: 0.5996/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:53] [Train] Epoch: 125/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1374/4.2265/0.8464/0.1415/0.6822/6.0339\n",
            "[2025/03/08 20:22:54] [Train] Epoch: 125/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1384/4.8507/0.8405/0.1418/0.6502/6.6215\n",
            "[2025/03/08 20:22:54] [Eval]  Epoch: 125/300 F-score: 0.6006/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:56] [Train] Epoch: 126/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1378/5.0210/0.8435/0.1456/0.6747/6.8226\n",
            "[2025/03/08 20:22:56] [Train] Epoch: 126/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1385/4.8225/0.8392/0.1418/0.6334/6.5753\n",
            "[2025/03/08 20:22:57] [Eval]  Epoch: 126/300 F-score: 0.6000/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:22:59] [Train] Epoch: 127/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1390/4.1367/0.8553/0.1501/0.5918/5.8729\n",
            "[2025/03/08 20:22:59] [Train] Epoch: 127/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1389/4.8002/0.8326/0.1485/0.5761/6.4964\n",
            "[2025/03/08 20:23:00] [Eval]  Epoch: 127/300 F-score: 0.5852/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:01] [Train] Epoch: 128/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1380/4.7334/0.8392/0.1394/0.5558/6.4058\n",
            "[2025/03/08 20:23:02] [Train] Epoch: 128/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1385/4.8165/0.8321/0.1415/0.5465/6.4751\n",
            "[2025/03/08 20:23:03] [Eval]  Epoch: 128/300 F-score: 0.6126/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:05] [Train] Epoch: 129/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.9152/0.8534/0.1399/0.5461/6.5934\n",
            "[2025/03/08 20:23:05] [Train] Epoch: 129/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1383/4.8035/0.8356/0.1391/0.5889/6.5055\n",
            "[2025/03/08 20:23:06] [Eval]  Epoch: 129/300 F-score: 0.5727/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:07] [Train] Epoch: 130/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.8350/0.8166/0.1390/0.5370/6.4665\n",
            "[2025/03/08 20:23:08] [Train] Epoch: 130/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1381/4.7775/0.8436/0.1446/0.6191/6.5229\n",
            "[2025/03/08 20:23:09] [Eval]  Epoch: 130/300 F-score: 0.5834/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:10] [Train] Epoch: 131/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1367/5.0911/0.8290/0.1462/0.6642/6.8673\n",
            "[2025/03/08 20:23:11] [Train] Epoch: 131/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1381/4.7626/0.8327/0.1454/0.6582/6.5371\n",
            "[2025/03/08 20:23:11] [Eval]  Epoch: 131/300 F-score: 0.5996/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:13] [Train] Epoch: 132/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1388/4.9309/0.7614/0.1434/0.5630/6.5375\n",
            "[2025/03/08 20:23:13] [Train] Epoch: 132/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1386/4.7548/0.8166/0.1398/0.5982/6.4480\n",
            "[2025/03/08 20:23:14] [Eval]  Epoch: 132/300 F-score: 0.5857/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:16] [Train] Epoch: 133/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1389/4.3008/0.8493/0.1379/0.5451/5.9721\n",
            "[2025/03/08 20:23:16] [Train] Epoch: 133/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1385/4.7522/0.8353/0.1396/0.5752/6.4407\n",
            "[2025/03/08 20:23:18] [Eval]  Epoch: 133/300 F-score: 0.5887/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:19] [Train] Epoch: 134/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1398/4.7982/0.8105/0.1363/0.5174/6.4021\n",
            "[2025/03/08 20:23:20] [Train] Epoch: 134/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1392/4.7481/0.8269/0.1448/0.5561/6.4150\n",
            "[2025/03/08 20:23:20] [Eval]  Epoch: 134/300 F-score: 0.6035/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:22] [Train] Epoch: 135/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1382/4.1728/0.8188/0.1430/0.6045/5.8774\n",
            "[2025/03/08 20:23:22] [Train] Epoch: 135/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1383/4.7569/0.8179/0.1385/0.5876/6.4391\n",
            "[2025/03/08 20:23:23] [Eval]  Epoch: 135/300 F-score: 0.5966/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:24] [Train] Epoch: 136/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1383/4.5533/0.7942/0.1424/0.5692/6.1975\n",
            "[2025/03/08 20:23:25] [Train] Epoch: 136/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1386/4.7580/0.8269/0.1487/0.5784/6.4506\n",
            "[2025/03/08 20:23:26] [Eval]  Epoch: 136/300 F-score: 0.5905/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:27] [Train] Epoch: 137/300 Iter: 5/10 Time: 0.199 Data: 0.049 Loss: 0.1382/4.7153/0.8398/0.1400/0.5293/6.3625\n",
            "[2025/03/08 20:23:28] [Train] Epoch: 137/300 Iter: 10/10 Time: 0.199 Data: 0.049 Loss: 0.1382/4.7292/0.8366/0.1415/0.5950/6.4406\n",
            "[2025/03/08 20:23:29] [Eval]  Epoch: 137/300 F-score: 0.6093/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:30] [Train] Epoch: 138/300 Iter: 5/10 Time: 0.200 Data: 0.049 Loss: 0.1381/5.0279/0.8407/0.1502/0.5582/6.7151\n",
            "[2025/03/08 20:23:31] [Train] Epoch: 138/300 Iter: 10/10 Time: 0.200 Data: 0.049 Loss: 0.1379/4.7322/0.8388/0.1439/0.5584/6.4111\n",
            "[2025/03/08 20:23:32] [Eval]  Epoch: 138/300 F-score: 0.5695/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:35] [Train] Epoch: 139/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1370/4.6877/0.8365/0.1371/0.6083/6.4066\n",
            "[2025/03/08 20:23:35] [Train] Epoch: 139/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1380/4.6856/0.8327/0.1431/0.6516/6.4510\n",
            "[2025/03/08 20:23:36] [Eval]  Epoch: 139/300 F-score: 0.5883/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:38] [Train] Epoch: 140/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1393/4.2283/0.7960/0.1467/0.7261/6.0363\n",
            "[2025/03/08 20:23:38] [Train] Epoch: 140/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1380/4.6830/0.8207/0.1444/0.7404/6.5264\n",
            "[2025/03/08 20:23:39] [Eval]  Epoch: 140/300 F-score: 0.5885/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:40] [Train] Epoch: 141/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1377/4.8049/0.8104/0.1435/0.6675/6.5640\n",
            "[2025/03/08 20:23:41] [Train] Epoch: 141/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1381/4.6858/0.8120/0.1453/0.6309/6.4122\n",
            "[2025/03/08 20:23:42] [Eval]  Epoch: 141/300 F-score: 0.5710/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:44] [Train] Epoch: 142/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1384/4.8472/0.8021/0.1441/0.5554/6.4872\n",
            "[2025/03/08 20:23:44] [Train] Epoch: 142/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1385/4.6868/0.8193/0.1414/0.6116/6.3976\n",
            "[2025/03/08 20:23:45] [Eval]  Epoch: 142/300 F-score: 0.5976/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:47] [Train] Epoch: 143/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1379/4.5046/0.8025/0.1378/0.6265/6.2092\n",
            "[2025/03/08 20:23:47] [Train] Epoch: 143/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1384/4.6642/0.8158/0.1377/0.6373/6.3934\n",
            "[2025/03/08 20:23:48] [Eval]  Epoch: 143/300 F-score: 0.5910/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:49] [Train] Epoch: 144/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1383/4.5688/0.8349/0.1414/0.6398/6.3233\n",
            "[2025/03/08 20:23:50] [Train] Epoch: 144/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1385/4.6673/0.8121/0.1372/0.6172/6.3722\n",
            "[2025/03/08 20:23:51] [Eval]  Epoch: 144/300 F-score: 0.6088/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:52] [Train] Epoch: 145/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1370/4.7028/0.8316/0.1496/0.6260/6.4470\n",
            "[2025/03/08 20:23:53] [Train] Epoch: 145/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1380/4.6723/0.8129/0.1446/0.6339/6.4018\n",
            "[2025/03/08 20:23:53] [Eval]  Epoch: 145/300 F-score: 0.6011/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:55] [Train] Epoch: 146/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1386/4.1700/0.8609/0.1403/0.5584/5.8681\n",
            "[2025/03/08 20:23:55] [Train] Epoch: 146/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1383/4.6408/0.8039/0.1409/0.5679/6.2918\n",
            "[2025/03/08 20:23:56] [Eval]  Epoch: 146/300 F-score: 0.5980/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:23:58] [Train] Epoch: 147/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1374/4.2995/0.8147/0.1329/0.5584/5.9429\n",
            "[2025/03/08 20:23:59] [Train] Epoch: 147/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1377/4.6529/0.8048/0.1326/0.5336/6.2615\n",
            "[2025/03/08 20:24:00] [Eval]  Epoch: 147/300 F-score: 0.5936/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:01] [Train] Epoch: 148/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1383/5.0279/0.8190/0.1360/0.5343/6.6555\n",
            "[2025/03/08 20:24:02] [Train] Epoch: 148/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1385/4.6471/0.8079/0.1439/0.5271/6.2645\n",
            "[2025/03/08 20:24:02] [Eval]  Epoch: 148/300 F-score: 0.5800/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:04] [Train] Epoch: 149/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1377/4.4398/0.8282/0.1482/0.5557/6.1095\n",
            "[2025/03/08 20:24:04] [Train] Epoch: 149/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1382/4.6624/0.8069/0.1480/0.5473/6.3028\n",
            "[2025/03/08 20:24:05] [Eval]  Epoch: 149/300 F-score: 0.6095/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:06] [Train] Epoch: 150/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1387/4.5997/0.8015/0.1419/0.5119/6.1937\n",
            "[2025/03/08 20:24:07] [Train] Epoch: 150/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1374/4.6592/0.8306/0.1387/0.5174/6.2834\n",
            "[2025/03/08 20:24:08] [Eval]  Epoch: 150/300 F-score: 0.6168/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:09] [Train] Epoch: 151/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1361/4.5569/0.8391/0.1559/0.5024/6.1903\n",
            "[2025/03/08 20:24:10] [Train] Epoch: 151/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1376/4.6818/0.8084/0.1536/0.4829/6.2643\n",
            "[2025/03/08 20:24:11] [Eval]  Epoch: 151/300 F-score: 0.6023/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:13] [Train] Epoch: 152/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1369/4.3571/0.8292/0.1488/0.5182/5.9901\n",
            "[2025/03/08 20:24:13] [Train] Epoch: 152/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1374/4.6369/0.7981/0.1458/0.4883/6.2065\n",
            "[2025/03/08 20:24:14] [Eval]  Epoch: 152/300 F-score: 0.6242/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:15] [Train] Epoch: 153/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1360/5.0757/0.8290/0.1374/0.5213/6.6996\n",
            "[2025/03/08 20:24:16] [Train] Epoch: 153/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1369/4.6280/0.8060/0.1402/0.4935/6.2046\n",
            "[2025/03/08 20:24:17] [Eval]  Epoch: 153/300 F-score: 0.6054/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:18] [Train] Epoch: 154/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1389/5.4059/0.7435/0.1370/0.5268/6.9521\n",
            "[2025/03/08 20:24:19] [Train] Epoch: 154/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1378/4.6162/0.7938/0.1405/0.5032/6.1916\n",
            "[2025/03/08 20:24:19] [Eval]  Epoch: 154/300 F-score: 0.5930/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:21] [Train] Epoch: 155/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1387/4.1243/0.7887/0.1384/0.5355/5.7256\n",
            "[2025/03/08 20:24:21] [Train] Epoch: 155/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1373/4.5831/0.7995/0.1421/0.5244/6.1864\n",
            "[2025/03/08 20:24:22] [Eval]  Epoch: 155/300 F-score: 0.5873/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:24] [Train] Epoch: 156/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1383/4.6017/0.8237/0.1421/0.5516/6.2574\n",
            "[2025/03/08 20:24:25] [Train] Epoch: 156/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1376/4.5861/0.8073/0.1466/0.5367/6.2143\n",
            "[2025/03/08 20:24:26] [Eval]  Epoch: 156/300 F-score: 0.6066/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:27] [Train] Epoch: 157/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1363/4.7901/0.8453/0.1449/0.6072/6.5239\n",
            "[2025/03/08 20:24:28] [Train] Epoch: 157/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1370/4.5824/0.8029/0.1389/0.6255/6.2867\n",
            "[2025/03/08 20:24:29] [Eval]  Epoch: 157/300 F-score: 0.6050/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:30] [Train] Epoch: 158/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1367/4.4645/0.8299/0.1450/0.6740/6.2500\n",
            "[2025/03/08 20:24:30] [Train] Epoch: 158/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1374/4.5911/0.8133/0.1442/0.7067/6.3927\n",
            "[2025/03/08 20:24:31] [Eval]  Epoch: 158/300 F-score: 0.5974/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:33] [Train] Epoch: 159/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1385/4.7682/0.8094/0.1464/0.7612/6.6238\n",
            "[2025/03/08 20:24:33] [Train] Epoch: 159/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1370/4.6056/0.8112/0.1416/0.7273/6.4226\n",
            "[2025/03/08 20:24:34] [Eval]  Epoch: 159/300 F-score: 0.5999/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:36] [Train] Epoch: 160/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1387/4.7693/0.7819/0.1441/0.6448/6.4787\n",
            "[2025/03/08 20:24:36] [Train] Epoch: 160/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1378/4.6356/0.8153/0.1459/0.6201/6.3546\n",
            "[2025/03/08 20:24:37] [Eval]  Epoch: 160/300 F-score: 0.6110/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:39] [Train] Epoch: 161/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1365/4.1253/0.8493/0.1388/0.5990/5.8489\n",
            "[2025/03/08 20:24:40] [Train] Epoch: 161/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1374/4.6054/0.8272/0.1395/0.6133/6.3227\n",
            "[2025/03/08 20:24:41] [Eval]  Epoch: 161/300 F-score: 0.5953/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:42] [Train] Epoch: 162/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1369/4.4580/0.8098/0.1413/0.5773/6.1235\n",
            "[2025/03/08 20:24:42] [Train] Epoch: 162/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1368/4.6142/0.8071/0.1462/0.5651/6.2695\n",
            "[2025/03/08 20:24:43] [Eval]  Epoch: 162/300 F-score: 0.6042/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:44] [Train] Epoch: 163/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1364/4.7356/0.7970/0.1482/0.5050/6.3221\n",
            "[2025/03/08 20:24:45] [Train] Epoch: 163/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1369/4.6274/0.7996/0.1470/0.5076/6.2185\n",
            "[2025/03/08 20:24:46] [Eval]  Epoch: 163/300 F-score: 0.5962/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:47] [Train] Epoch: 164/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1392/4.7045/0.7874/0.1363/0.5211/6.2885\n",
            "[2025/03/08 20:24:48] [Train] Epoch: 164/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1383/4.6143/0.7987/0.1392/0.4981/6.1886\n",
            "[2025/03/08 20:24:48] [Eval]  Epoch: 164/300 F-score: 0.6063/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:50] [Train] Epoch: 165/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1382/3.9457/0.7987/0.1439/0.4470/5.4736\n",
            "[2025/03/08 20:24:51] [Train] Epoch: 165/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1375/4.5867/0.8147/0.1466/0.4865/6.1721\n",
            "[2025/03/08 20:24:52] [Eval]  Epoch: 165/300 F-score: 0.6201/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:53] [Train] Epoch: 166/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1351/4.4958/0.7879/0.1408/0.5117/6.0713\n",
            "[2025/03/08 20:24:54] [Train] Epoch: 166/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1360/4.5822/0.7903/0.1431/0.5245/6.1762\n",
            "[2025/03/08 20:24:55] [Eval]  Epoch: 166/300 F-score: 0.6070/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:56] [Train] Epoch: 167/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1374/4.2589/0.8214/0.1427/0.5256/5.8860\n",
            "[2025/03/08 20:24:57] [Train] Epoch: 167/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1366/4.5711/0.7972/0.1453/0.5048/6.1549\n",
            "[2025/03/08 20:24:57] [Eval]  Epoch: 167/300 F-score: 0.6157/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:24:59] [Train] Epoch: 168/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1362/4.5741/0.8276/0.1485/0.5605/6.2468\n",
            "[2025/03/08 20:24:59] [Train] Epoch: 168/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1370/4.5748/0.7992/0.1455/0.5280/6.1845\n",
            "[2025/03/08 20:25:00] [Eval]  Epoch: 168/300 F-score: 0.5972/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:01] [Train] Epoch: 169/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1361/4.6305/0.7828/0.1381/0.5300/6.2175\n",
            "[2025/03/08 20:25:02] [Train] Epoch: 169/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1359/4.5406/0.8015/0.1370/0.5037/6.1187\n",
            "[2025/03/08 20:25:03] [Eval]  Epoch: 169/300 F-score: 0.6146/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:05] [Train] Epoch: 170/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1363/5.1576/0.7805/0.1391/0.5077/6.7212\n",
            "[2025/03/08 20:25:06] [Train] Epoch: 170/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1357/4.5737/0.8120/0.1411/0.5264/6.1889\n",
            "[2025/03/08 20:25:07] [Eval]  Epoch: 170/300 F-score: 0.5916/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:08] [Train] Epoch: 171/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1357/4.5687/0.7865/0.1411/0.5615/6.1934\n",
            "[2025/03/08 20:25:08] [Train] Epoch: 171/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1358/4.5607/0.8005/0.1456/0.5985/6.2411\n",
            "[2025/03/08 20:25:09] [Eval]  Epoch: 171/300 F-score: 0.5995/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:11] [Train] Epoch: 172/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1356/4.3088/0.8203/0.1478/0.5304/5.9429\n",
            "[2025/03/08 20:25:11] [Train] Epoch: 172/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1367/4.5573/0.8027/0.1466/0.5162/6.1595\n",
            "[2025/03/08 20:25:12] [Eval]  Epoch: 172/300 F-score: 0.6041/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:13] [Train] Epoch: 173/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1354/4.4731/0.7713/0.1386/0.5371/6.0555\n",
            "[2025/03/08 20:25:14] [Train] Epoch: 173/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1354/4.5463/0.7925/0.1426/0.5751/6.1919\n",
            "[2025/03/08 20:25:15] [Eval]  Epoch: 173/300 F-score: 0.6086/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:16] [Train] Epoch: 174/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1351/4.2868/0.7668/0.1336/0.5592/5.8816\n",
            "[2025/03/08 20:25:17] [Train] Epoch: 174/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1351/4.5520/0.8019/0.1358/0.5718/6.1966\n",
            "[2025/03/08 20:25:18] [Eval]  Epoch: 174/300 F-score: 0.6032/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:20] [Train] Epoch: 175/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1357/4.6013/0.8139/0.1478/0.5195/6.2183\n",
            "[2025/03/08 20:25:20] [Train] Epoch: 175/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1345/4.5573/0.8017/0.1450/0.5236/6.1622\n",
            "[2025/03/08 20:25:21] [Eval]  Epoch: 175/300 F-score: 0.6052/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:22] [Train] Epoch: 176/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1350/3.8553/0.8058/0.1330/0.4885/5.4176\n",
            "[2025/03/08 20:25:23] [Train] Epoch: 176/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1346/4.5302/0.7936/0.1396/0.4996/6.0976\n",
            "[2025/03/08 20:25:24] [Eval]  Epoch: 176/300 F-score: 0.6010/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:25] [Train] Epoch: 177/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1365/4.4977/0.7999/0.1409/0.5131/6.0880\n",
            "[2025/03/08 20:25:26] [Train] Epoch: 177/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1356/4.5246/0.7867/0.1443/0.5632/6.1545\n",
            "[2025/03/08 20:25:26] [Eval]  Epoch: 177/300 F-score: 0.5818/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:28] [Train] Epoch: 178/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1358/4.4251/0.7468/0.1364/0.6123/6.0564\n",
            "[2025/03/08 20:25:28] [Train] Epoch: 178/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1349/4.5295/0.7956/0.1365/0.5883/6.1849\n",
            "[2025/03/08 20:25:29] [Eval]  Epoch: 178/300 F-score: 0.5934/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:31] [Train] Epoch: 179/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1346/4.8809/0.7721/0.1473/0.5809/6.5158\n",
            "[2025/03/08 20:25:31] [Train] Epoch: 179/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1350/4.5225/0.7885/0.1409/0.5882/6.1752\n",
            "[2025/03/08 20:25:33] [Eval]  Epoch: 179/300 F-score: 0.5948/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:34] [Train] Epoch: 180/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1350/4.7968/0.7664/0.1419/0.5804/6.4205\n",
            "[2025/03/08 20:25:35] [Train] Epoch: 180/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1341/4.5463/0.7881/0.1408/0.5673/6.1765\n",
            "[2025/03/08 20:25:35] [Eval]  Epoch: 180/300 F-score: 0.5990/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:37] [Train] Epoch: 181/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1349/4.3652/0.8144/0.1482/0.5260/5.9887\n",
            "[2025/03/08 20:25:37] [Train] Epoch: 181/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1350/4.5069/0.7979/0.1489/0.5367/6.1255\n",
            "[2025/03/08 20:25:38] [Eval]  Epoch: 181/300 F-score: 0.6100/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:40] [Train] Epoch: 182/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1343/3.7980/0.8101/0.1350/0.5220/5.3993\n",
            "[2025/03/08 20:25:40] [Train] Epoch: 182/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1330/4.5030/0.7933/0.1412/0.5333/6.1038\n",
            "[2025/03/08 20:25:41] [Eval]  Epoch: 182/300 F-score: 0.5852/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:42] [Train] Epoch: 183/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1330/4.0888/0.7668/0.1411/0.4839/5.6136\n",
            "[2025/03/08 20:25:43] [Train] Epoch: 183/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1335/4.5030/0.7810/0.1404/0.4596/6.0175\n",
            "[2025/03/08 20:25:44] [Eval]  Epoch: 183/300 F-score: 0.5894/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:46] [Train] Epoch: 184/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1337/4.4410/0.8186/0.1399/0.4812/6.0145\n",
            "[2025/03/08 20:25:47] [Train] Epoch: 184/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1334/4.5239/0.8018/0.1435/0.4641/6.0667\n",
            "[2025/03/08 20:25:48] [Eval]  Epoch: 184/300 F-score: 0.5834/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:49] [Train] Epoch: 185/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1327/4.9527/0.7512/0.1420/0.4524/6.4309\n",
            "[2025/03/08 20:25:50] [Train] Epoch: 185/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1334/4.5274/0.7823/0.1447/0.4672/6.0549\n",
            "[2025/03/08 20:25:50] [Eval]  Epoch: 185/300 F-score: 0.6022/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:52] [Train] Epoch: 186/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1341/3.7626/0.8550/0.1367/0.4928/5.3811\n",
            "[2025/03/08 20:25:52] [Train] Epoch: 186/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1339/4.5313/0.8076/0.1393/0.5084/6.1205\n",
            "[2025/03/08 20:25:53] [Eval]  Epoch: 186/300 F-score: 0.6159/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:55] [Train] Epoch: 187/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1306/4.1573/0.7595/0.1431/0.5018/5.6923\n",
            "[2025/03/08 20:25:55] [Train] Epoch: 187/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1321/4.5135/0.7883/0.1397/0.5096/6.0832\n",
            "[2025/03/08 20:25:56] [Eval]  Epoch: 187/300 F-score: 0.5910/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:25:58] [Train] Epoch: 188/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1338/4.2362/0.8007/0.1410/0.5032/5.8148\n",
            "[2025/03/08 20:25:59] [Train] Epoch: 188/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1336/4.4937/0.7843/0.1418/0.5095/6.0628\n",
            "[2025/03/08 20:26:00] [Eval]  Epoch: 188/300 F-score: 0.6023/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:01] [Train] Epoch: 189/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1324/4.3036/0.7850/0.1346/0.4980/5.8537\n",
            "[2025/03/08 20:26:02] [Train] Epoch: 189/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1319/4.4844/0.7877/0.1323/0.5170/6.0531\n",
            "[2025/03/08 20:26:03] [Eval]  Epoch: 189/300 F-score: 0.6154/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:04] [Train] Epoch: 190/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1325/4.4807/0.7991/0.1418/0.5338/6.0879\n",
            "[2025/03/08 20:26:04] [Train] Epoch: 190/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1322/4.4879/0.7950/0.1423/0.5351/6.0924\n",
            "[2025/03/08 20:26:05] [Eval]  Epoch: 190/300 F-score: 0.6131/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:07] [Train] Epoch: 191/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1303/5.2799/0.7628/0.1486/0.5318/6.8534\n",
            "[2025/03/08 20:26:07] [Train] Epoch: 191/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1316/4.4852/0.7848/0.1443/0.4593/6.0053\n",
            "[2025/03/08 20:26:08] [Eval]  Epoch: 191/300 F-score: 0.6076/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:09] [Train] Epoch: 192/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1329/4.4079/0.8005/0.1370/0.5502/6.0285\n",
            "[2025/03/08 20:26:10] [Train] Epoch: 192/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1330/4.5079/0.7819/0.1385/0.5388/6.1001\n",
            "[2025/03/08 20:26:11] [Eval]  Epoch: 192/300 F-score: 0.5880/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:13] [Train] Epoch: 193/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1348/4.5437/0.7800/0.1432/0.5097/6.1114\n",
            "[2025/03/08 20:26:13] [Train] Epoch: 193/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1323/4.4992/0.7887/0.1369/0.5253/6.0824\n",
            "[2025/03/08 20:26:14] [Eval]  Epoch: 193/300 F-score: 0.5785/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:16] [Train] Epoch: 194/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1305/4.7547/0.7992/0.1381/0.5574/6.3799\n",
            "[2025/03/08 20:26:16] [Train] Epoch: 194/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1312/4.4773/0.7929/0.1406/0.5278/6.0698\n",
            "[2025/03/08 20:26:17] [Eval]  Epoch: 194/300 F-score: 0.6040/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:18] [Train] Epoch: 195/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1310/4.3247/0.7773/0.1406/0.4703/5.8438\n",
            "[2025/03/08 20:26:19] [Train] Epoch: 195/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1321/4.4622/0.7818/0.1394/0.4871/6.0026\n",
            "[2025/03/08 20:26:19] [Eval]  Epoch: 195/300 F-score: 0.5891/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:21] [Train] Epoch: 196/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1300/4.3593/0.7824/0.1416/0.4551/5.8684\n",
            "[2025/03/08 20:26:21] [Train] Epoch: 196/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1314/4.4686/0.7800/0.1377/0.4905/6.0082\n",
            "[2025/03/08 20:26:22] [Eval]  Epoch: 196/300 F-score: 0.5816/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:24] [Train] Epoch: 197/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1308/4.4023/0.7768/0.1399/0.4998/5.9495\n",
            "[2025/03/08 20:26:24] [Train] Epoch: 197/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1316/4.4711/0.7861/0.1405/0.4931/6.0224\n",
            "[2025/03/08 20:26:26] [Eval]  Epoch: 197/300 F-score: 0.6002/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:27] [Train] Epoch: 198/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1309/3.8313/0.8093/0.1391/0.5230/5.4336\n",
            "[2025/03/08 20:26:28] [Train] Epoch: 198/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1315/4.4662/0.7860/0.1408/0.5143/6.0387\n",
            "[2025/03/08 20:26:29] [Eval]  Epoch: 198/300 F-score: 0.5747/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:30] [Train] Epoch: 199/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1311/4.0089/0.7419/0.1432/0.4918/5.5169\n",
            "[2025/03/08 20:26:31] [Train] Epoch: 199/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1308/4.4422/0.7808/0.1396/0.4715/5.9649\n",
            "[2025/03/08 20:26:31] [Eval]  Epoch: 199/300 F-score: 0.5803/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:33] [Train] Epoch: 200/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1286/4.6954/0.7548/0.1387/0.4974/6.2148\n",
            "[2025/03/08 20:26:33] [Train] Epoch: 200/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1302/4.4407/0.7784/0.1383/0.4807/5.9682\n",
            "[2025/03/08 20:26:34] [Eval]  Epoch: 200/300 F-score: 0.5831/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:36] [Train] Epoch: 201/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1270/4.7307/0.8065/0.1364/0.4656/6.2662\n",
            "[2025/03/08 20:26:36] [Train] Epoch: 201/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1310/4.4552/0.7867/0.1390/0.3898/5.9016\n",
            "[2025/03/08 20:26:37] [Eval]  Epoch: 201/300 F-score: 0.5870/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:39] [Train] Epoch: 202/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1311/4.6392/0.7822/0.1302/0.4498/6.1326\n",
            "[2025/03/08 20:26:39] [Train] Epoch: 202/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1313/4.4598/0.7838/0.1326/0.4623/5.9698\n",
            "[2025/03/08 20:26:40] [Eval]  Epoch: 202/300 F-score: 0.5729/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:42] [Train] Epoch: 203/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1324/4.0753/0.7971/0.1347/0.4529/5.5925\n",
            "[2025/03/08 20:26:42] [Train] Epoch: 203/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1317/4.4511/0.7792/0.1345/0.4879/5.9843\n",
            "[2025/03/08 20:26:43] [Eval]  Epoch: 203/300 F-score: 0.5828/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:45] [Train] Epoch: 204/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1308/5.6170/0.7546/0.1402/0.5038/7.1465\n",
            "[2025/03/08 20:26:45] [Train] Epoch: 204/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1308/4.4436/0.7819/0.1375/0.5145/6.0083\n",
            "[2025/03/08 20:26:46] [Eval]  Epoch: 204/300 F-score: 0.5842/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:47] [Train] Epoch: 205/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1309/4.5645/0.7741/0.1364/0.4876/6.0935\n",
            "[2025/03/08 20:26:48] [Train] Epoch: 205/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1308/4.4542/0.7865/0.1392/0.4796/5.9904\n",
            "[2025/03/08 20:26:49] [Eval]  Epoch: 205/300 F-score: 0.5869/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:50] [Train] Epoch: 206/300 Iter: 5/10 Time: 0.200 Data: 0.050 Loss: 0.1314/4.5411/0.7287/0.1377/0.4620/6.0009\n",
            "[2025/03/08 20:26:50] [Train] Epoch: 206/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1291/4.4384/0.7853/0.1326/0.4833/5.9686\n",
            "[2025/03/08 20:26:52] [Eval]  Epoch: 206/300 F-score: 0.5812/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:53] [Train] Epoch: 207/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1308/4.2177/0.8009/0.1377/0.4257/5.7129\n",
            "[2025/03/08 20:26:54] [Train] Epoch: 207/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1292/4.4512/0.7799/0.1353/0.4579/5.9535\n",
            "[2025/03/08 20:26:55] [Eval]  Epoch: 207/300 F-score: 0.5975/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:56] [Train] Epoch: 208/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1295/4.7738/0.7747/0.1325/0.4613/6.2718\n",
            "[2025/03/08 20:26:57] [Train] Epoch: 208/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1320/4.4670/0.7849/0.1294/0.4405/5.9539\n",
            "[2025/03/08 20:26:58] [Eval]  Epoch: 208/300 F-score: 0.6052/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:26:59] [Train] Epoch: 209/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1306/4.1769/0.8225/0.1278/0.4980/5.7557\n",
            "[2025/03/08 20:27:00] [Train] Epoch: 209/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1301/4.4487/0.7970/0.1323/0.4769/5.9850\n",
            "[2025/03/08 20:27:01] [Eval]  Epoch: 209/300 F-score: 0.5918/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:02] [Train] Epoch: 210/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1308/4.2548/0.7843/0.1304/0.5022/5.8025\n",
            "[2025/03/08 20:27:03] [Train] Epoch: 210/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1304/4.4425/0.7862/0.1313/0.4916/5.9820\n",
            "[2025/03/08 20:27:03] [Eval]  Epoch: 210/300 F-score: 0.5978/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:05] [Train] Epoch: 211/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1280/4.8263/0.7583/0.1310/0.4508/6.2944\n",
            "[2025/03/08 20:27:06] [Train] Epoch: 211/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1279/4.4539/0.7913/0.1343/0.4618/5.9691\n",
            "[2025/03/08 20:27:07] [Eval]  Epoch: 211/300 F-score: 0.6138/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:08] [Train] Epoch: 212/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1284/5.1171/0.7910/0.1416/0.4382/6.6163\n",
            "[2025/03/08 20:27:09] [Train] Epoch: 212/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1314/4.4405/0.7825/0.1361/0.4341/5.9245\n",
            "[2025/03/08 20:27:10] [Eval]  Epoch: 212/300 F-score: 0.5931/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:11] [Train] Epoch: 213/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1299/4.1008/0.8097/0.1418/0.4214/5.6037\n",
            "[2025/03/08 20:27:12] [Train] Epoch: 213/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1302/4.4246/0.7940/0.1372/0.4067/5.8928\n",
            "[2025/03/08 20:27:12] [Eval]  Epoch: 213/300 F-score: 0.6226/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:14] [Train] Epoch: 214/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1287/4.2568/0.7511/0.1320/0.4266/5.6950\n",
            "[2025/03/08 20:27:14] [Train] Epoch: 214/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1294/4.4255/0.7873/0.1305/0.4277/5.9004\n",
            "[2025/03/08 20:27:15] [Eval]  Epoch: 214/300 F-score: 0.5818/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:17] [Train] Epoch: 215/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1290/3.9037/0.7815/0.1269/0.4311/5.3723\n",
            "[2025/03/08 20:27:17] [Train] Epoch: 215/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1284/4.4164/0.7764/0.1297/0.4237/5.8747\n",
            "[2025/03/08 20:27:18] [Eval]  Epoch: 215/300 F-score: 0.6096/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:20] [Train] Epoch: 216/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1284/4.1184/0.8037/0.1455/0.4391/5.6350\n",
            "[2025/03/08 20:27:21] [Train] Epoch: 216/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1274/4.4324/0.7789/0.1410/0.4170/5.8968\n",
            "[2025/03/08 20:27:22] [Eval]  Epoch: 216/300 F-score: 0.5860/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:23] [Train] Epoch: 217/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1297/4.5491/0.7627/0.1400/0.4539/6.0354\n",
            "[2025/03/08 20:27:23] [Train] Epoch: 217/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1262/4.4168/0.7738/0.1392/0.4456/5.9016\n",
            "[2025/03/08 20:27:24] [Eval]  Epoch: 217/300 F-score: 0.6181/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:25] [Train] Epoch: 218/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1263/4.0052/0.7779/0.1428/0.4416/5.4937\n",
            "[2025/03/08 20:27:26] [Train] Epoch: 218/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1273/4.4094/0.7788/0.1358/0.4414/5.8928\n",
            "[2025/03/08 20:27:27] [Eval]  Epoch: 218/300 F-score: 0.5902/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:28] [Train] Epoch: 219/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1296/4.0094/0.7680/0.1358/0.3987/5.4415\n",
            "[2025/03/08 20:27:29] [Train] Epoch: 219/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1272/4.4218/0.7731/0.1317/0.4086/5.8624\n",
            "[2025/03/08 20:27:29] [Eval]  Epoch: 219/300 F-score: 0.6013/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:31] [Train] Epoch: 220/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1289/4.4989/0.7965/0.1268/0.4277/5.9788\n",
            "[2025/03/08 20:27:31] [Train] Epoch: 220/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1264/4.4199/0.7769/0.1309/0.4108/5.8649\n",
            "[2025/03/08 20:27:33] [Eval]  Epoch: 220/300 F-score: 0.5963/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:34] [Train] Epoch: 221/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1269/4.8503/0.7380/0.1370/0.4082/6.2605\n",
            "[2025/03/08 20:27:35] [Train] Epoch: 221/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1266/4.4078/0.7821/0.1311/0.3972/5.8448\n",
            "[2025/03/08 20:27:36] [Eval]  Epoch: 221/300 F-score: 0.5876/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:37] [Train] Epoch: 222/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1271/4.4087/0.8118/0.1359/0.3710/5.8545\n",
            "[2025/03/08 20:27:38] [Train] Epoch: 222/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1276/4.3925/0.7834/0.1356/0.4049/5.8439\n",
            "[2025/03/08 20:27:38] [Eval]  Epoch: 222/300 F-score: 0.5853/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:40] [Train] Epoch: 223/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1277/4.6359/0.7705/0.1133/0.4002/6.0476\n",
            "[2025/03/08 20:27:40] [Train] Epoch: 223/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1288/4.4052/0.7824/0.1240/0.4161/5.8565\n",
            "[2025/03/08 20:27:41] [Eval]  Epoch: 223/300 F-score: 0.6247/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:42] [Train] Epoch: 224/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1245/3.6060/0.7480/0.1385/0.4004/5.0174\n",
            "[2025/03/08 20:27:43] [Train] Epoch: 224/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1258/4.4186/0.7843/0.1280/0.4316/5.8882\n",
            "[2025/03/08 20:27:44] [Eval]  Epoch: 224/300 F-score: 0.5990/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:45] [Train] Epoch: 225/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1304/4.6410/0.7381/0.1287/0.3623/6.0005\n",
            "[2025/03/08 20:27:46] [Train] Epoch: 225/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1280/4.3920/0.7758/0.1283/0.4054/5.8294\n",
            "[2025/03/08 20:27:47] [Eval]  Epoch: 225/300 F-score: 0.5929/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:49] [Train] Epoch: 226/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1242/4.2794/0.7988/0.1144/0.3923/5.7090\n",
            "[2025/03/08 20:27:49] [Train] Epoch: 226/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1260/4.4097/0.7772/0.1276/0.4274/5.8680\n",
            "[2025/03/08 20:27:50] [Eval]  Epoch: 226/300 F-score: 0.6046/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:52] [Train] Epoch: 227/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1250/4.4198/0.7582/0.1208/0.4214/5.8452\n",
            "[2025/03/08 20:27:52] [Train] Epoch: 227/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1269/4.3933/0.7922/0.1182/0.4166/5.8472\n",
            "[2025/03/08 20:27:53] [Eval]  Epoch: 227/300 F-score: 0.6025/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:54] [Train] Epoch: 228/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1270/4.8038/0.7321/0.1293/0.3924/6.1844\n",
            "[2025/03/08 20:27:55] [Train] Epoch: 228/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1274/4.4055/0.7772/0.1308/0.4191/5.8600\n",
            "[2025/03/08 20:27:56] [Eval]  Epoch: 228/300 F-score: 0.5933/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:27:57] [Train] Epoch: 229/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1314/5.0023/0.8092/0.1132/0.4354/6.4915\n",
            "[2025/03/08 20:27:58] [Train] Epoch: 229/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1282/4.4177/0.7816/0.1168/0.4532/5.8975\n",
            "[2025/03/08 20:27:59] [Eval]  Epoch: 229/300 F-score: 0.5907/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:00] [Train] Epoch: 230/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1274/4.7384/0.7812/0.1141/0.4758/6.2368\n",
            "[2025/03/08 20:28:01] [Train] Epoch: 230/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1268/4.4240/0.7763/0.1206/0.4534/5.9011\n",
            "[2025/03/08 20:28:02] [Eval]  Epoch: 230/300 F-score: 0.5944/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:03] [Train] Epoch: 231/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1247/4.7133/0.7780/0.1117/0.3990/6.1268\n",
            "[2025/03/08 20:28:04] [Train] Epoch: 231/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1267/4.4272/0.7818/0.1218/0.4129/5.8705\n",
            "[2025/03/08 20:28:05] [Eval]  Epoch: 231/300 F-score: 0.6170/0.6294\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:06] [Train] Epoch: 232/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1239/4.8104/0.7698/0.1323/0.4164/6.2528\n",
            "[2025/03/08 20:28:07] [Train] Epoch: 232/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1255/4.4172/0.7797/0.1310/0.4499/5.9032\n",
            "[2025/03/08 20:28:08] [Eval]  Epoch: 232/300 F-score: 0.6316/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:09] [Train] Epoch: 233/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1225/4.1515/0.7407/0.1061/0.5007/5.6215\n",
            "[2025/03/08 20:28:09] [Train] Epoch: 233/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1257/4.4019/0.7748/0.1136/0.4530/5.8690\n",
            "[2025/03/08 20:28:10] [Eval]  Epoch: 233/300 F-score: 0.5968/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:12] [Train] Epoch: 234/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1244/4.3310/0.7832/0.1096/0.4503/5.7984\n",
            "[2025/03/08 20:28:12] [Train] Epoch: 234/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1249/4.3843/0.7793/0.1108/0.4547/5.8541\n",
            "[2025/03/08 20:28:13] [Eval]  Epoch: 234/300 F-score: 0.6101/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:15] [Train] Epoch: 235/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1228/4.9511/0.7749/0.1088/0.3996/6.3572\n",
            "[2025/03/08 20:28:16] [Train] Epoch: 235/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1244/4.3966/0.7719/0.1117/0.4132/5.8178\n",
            "[2025/03/08 20:28:17] [Eval]  Epoch: 235/300 F-score: 0.6011/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:18] [Train] Epoch: 236/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1222/3.6202/0.8012/0.1156/0.4704/5.1296\n",
            "[2025/03/08 20:28:19] [Train] Epoch: 236/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1252/4.3931/0.7774/0.1185/0.4712/5.8853\n",
            "[2025/03/08 20:28:19] [Eval]  Epoch: 236/300 F-score: 0.6141/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:21] [Train] Epoch: 237/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1232/4.4771/0.7870/0.1325/0.5085/6.0283\n",
            "[2025/03/08 20:28:21] [Train] Epoch: 237/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1251/4.4055/0.7836/0.1324/0.4483/5.8949\n",
            "[2025/03/08 20:28:22] [Eval]  Epoch: 237/300 F-score: 0.6042/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:24] [Train] Epoch: 238/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1245/4.8646/0.7740/0.1306/0.4671/6.3609\n",
            "[2025/03/08 20:28:24] [Train] Epoch: 238/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1247/4.3844/0.7771/0.1327/0.4430/5.8618\n",
            "[2025/03/08 20:28:25] [Eval]  Epoch: 238/300 F-score: 0.6056/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:26] [Train] Epoch: 239/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1267/4.6372/0.7744/0.1198/0.4243/6.0824\n",
            "[2025/03/08 20:28:27] [Train] Epoch: 239/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1261/4.4330/0.7775/0.1283/0.4212/5.8860\n",
            "[2025/03/08 20:28:28] [Eval]  Epoch: 239/300 F-score: 0.5987/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:30] [Train] Epoch: 240/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1226/4.2638/0.7696/0.1098/0.4011/5.6668\n",
            "[2025/03/08 20:28:30] [Train] Epoch: 240/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1243/4.3988/0.7678/0.1154/0.4019/5.8082\n",
            "[2025/03/08 20:28:31] [Eval]  Epoch: 240/300 F-score: 0.5939/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:33] [Train] Epoch: 241/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1258/4.0895/0.7691/0.1155/0.4468/5.5467\n",
            "[2025/03/08 20:28:33] [Train] Epoch: 241/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1251/4.4063/0.7789/0.1174/0.4043/5.8321\n",
            "[2025/03/08 20:28:34] [Eval]  Epoch: 241/300 F-score: 0.6159/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:35] [Train] Epoch: 242/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1249/4.3483/0.7760/0.1090/0.3564/5.7147\n",
            "[2025/03/08 20:28:36] [Train] Epoch: 242/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1253/4.3912/0.7699/0.1139/0.3846/5.7849\n",
            "[2025/03/08 20:28:37] [Eval]  Epoch: 242/300 F-score: 0.5931/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:38] [Train] Epoch: 243/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1211/4.0898/0.7834/0.1071/0.4003/5.5017\n",
            "[2025/03/08 20:28:39] [Train] Epoch: 243/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1255/4.3837/0.7738/0.1017/0.3708/5.7556\n",
            "[2025/03/08 20:28:40] [Eval]  Epoch: 243/300 F-score: 0.6030/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:41] [Train] Epoch: 244/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1197/3.7220/0.7873/0.1225/0.4118/5.1633\n",
            "[2025/03/08 20:28:42] [Train] Epoch: 244/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1227/4.3749/0.7765/0.1119/0.4097/5.7957\n",
            "[2025/03/08 20:28:43] [Eval]  Epoch: 244/300 F-score: 0.6023/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:45] [Train] Epoch: 245/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1238/4.7336/0.7560/0.1049/0.4058/6.1240\n",
            "[2025/03/08 20:28:45] [Train] Epoch: 245/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1246/4.3761/0.7752/0.1018/0.3776/5.7553\n",
            "[2025/03/08 20:28:46] [Eval]  Epoch: 245/300 F-score: 0.6203/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:47] [Train] Epoch: 246/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1208/4.2332/0.7864/0.1163/0.3903/5.6470\n",
            "[2025/03/08 20:28:48] [Train] Epoch: 246/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1205/4.3619/0.7710/0.1085/0.3977/5.7596\n",
            "[2025/03/08 20:28:49] [Eval]  Epoch: 246/300 F-score: 0.6199/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:50] [Train] Epoch: 247/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1207/4.9312/0.7825/0.1119/0.4113/6.3576\n",
            "[2025/03/08 20:28:50] [Train] Epoch: 247/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1219/4.3687/0.7848/0.1068/0.3830/5.7653\n",
            "[2025/03/08 20:28:51] [Eval]  Epoch: 247/300 F-score: 0.6119/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:53] [Train] Epoch: 248/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1226/4.6053/0.7637/0.1247/0.3476/5.9638\n",
            "[2025/03/08 20:28:53] [Train] Epoch: 248/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1210/4.3696/0.7718/0.1251/0.3544/5.7419\n",
            "[2025/03/08 20:28:54] [Eval]  Epoch: 248/300 F-score: 0.6088/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:56] [Train] Epoch: 249/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1222/3.9716/0.7756/0.0934/0.4208/5.3836\n",
            "[2025/03/08 20:28:57] [Train] Epoch: 249/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1227/4.3672/0.7730/0.1055/0.3997/5.7681\n",
            "[2025/03/08 20:28:58] [Eval]  Epoch: 249/300 F-score: 0.6075/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:28:59] [Train] Epoch: 250/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1213/4.8509/0.7903/0.1060/0.3668/6.2354\n",
            "[2025/03/08 20:29:00] [Train] Epoch: 250/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1212/4.3650/0.7752/0.1070/0.3790/5.7475\n",
            "[2025/03/08 20:29:00] [Eval]  Epoch: 250/300 F-score: 0.6022/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:02] [Train] Epoch: 251/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1234/4.4834/0.7823/0.1005/0.3861/5.8756\n",
            "[2025/03/08 20:29:02] [Train] Epoch: 251/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1230/4.3667/0.7763/0.1002/0.3845/5.7507\n",
            "[2025/03/08 20:29:03] [Eval]  Epoch: 251/300 F-score: 0.5990/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:04] [Train] Epoch: 252/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1199/3.5906/0.8331/0.0999/0.3595/5.0031\n",
            "[2025/03/08 20:29:05] [Train] Epoch: 252/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1230/4.3680/0.7740/0.1017/0.3764/5.7432\n",
            "[2025/03/08 20:29:06] [Eval]  Epoch: 252/300 F-score: 0.6080/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:07] [Train] Epoch: 253/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1212/4.0928/0.7861/0.0910/0.3660/5.4571\n",
            "[2025/03/08 20:29:08] [Train] Epoch: 253/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1210/4.3580/0.7669/0.1033/0.3593/5.7084\n",
            "[2025/03/08 20:29:09] [Eval]  Epoch: 253/300 F-score: 0.6159/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:11] [Train] Epoch: 254/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1272/4.2589/0.7303/0.0943/0.3922/5.6027\n",
            "[2025/03/08 20:29:11] [Train] Epoch: 254/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1236/4.3869/0.7724/0.0948/0.3794/5.7570\n",
            "[2025/03/08 20:29:12] [Eval]  Epoch: 254/300 F-score: 0.6008/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:13] [Train] Epoch: 255/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1260/4.3217/0.7758/0.1070/0.3768/5.7073\n",
            "[2025/03/08 20:29:14] [Train] Epoch: 255/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1226/4.3621/0.7748/0.1070/0.3624/5.7289\n",
            "[2025/03/08 20:29:15] [Eval]  Epoch: 255/300 F-score: 0.6059/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:16] [Train] Epoch: 256/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1230/4.3226/0.7705/0.0995/0.3896/5.7051\n",
            "[2025/03/08 20:29:17] [Train] Epoch: 256/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1245/4.3756/0.7721/0.1071/0.3795/5.7587\n",
            "[2025/03/08 20:29:18] [Eval]  Epoch: 256/300 F-score: 0.6047/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:19] [Train] Epoch: 257/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1212/4.6373/0.7692/0.0908/0.3529/5.9714\n",
            "[2025/03/08 20:29:19] [Train] Epoch: 257/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1232/4.3691/0.7706/0.1034/0.3581/5.7243\n",
            "[2025/03/08 20:29:21] [Eval]  Epoch: 257/300 F-score: 0.6171/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:22] [Train] Epoch: 258/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1213/3.9272/0.8159/0.1123/0.4052/5.3818\n",
            "[2025/03/08 20:29:23] [Train] Epoch: 258/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1241/4.3649/0.7732/0.1086/0.3804/5.7511\n",
            "[2025/03/08 20:29:24] [Eval]  Epoch: 258/300 F-score: 0.5997/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:25] [Train] Epoch: 259/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1259/4.4182/0.7721/0.0989/0.4367/5.8518\n",
            "[2025/03/08 20:29:26] [Train] Epoch: 259/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1251/4.3583/0.7787/0.1017/0.4014/5.7652\n",
            "[2025/03/08 20:29:27] [Eval]  Epoch: 259/300 F-score: 0.6092/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:28] [Train] Epoch: 260/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1208/4.2952/0.7464/0.1132/0.3996/5.6752\n",
            "[2025/03/08 20:29:29] [Train] Epoch: 260/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1210/4.3542/0.7735/0.1172/0.3503/5.7161\n",
            "[2025/03/08 20:29:30] [Eval]  Epoch: 260/300 F-score: 0.6239/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:31] [Train] Epoch: 261/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1190/4.2178/0.7754/0.1226/0.3155/5.5503\n",
            "[2025/03/08 20:29:31] [Train] Epoch: 261/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1195/4.3599/0.7717/0.1131/0.3402/5.7043\n",
            "[2025/03/08 20:29:32] [Eval]  Epoch: 261/300 F-score: 0.5906/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:34] [Train] Epoch: 262/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1208/4.5956/0.7725/0.1093/0.3340/5.9322\n",
            "[2025/03/08 20:29:34] [Train] Epoch: 262/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1211/4.3639/0.7755/0.1167/0.3561/5.7332\n",
            "[2025/03/08 20:29:36] [Eval]  Epoch: 262/300 F-score: 0.6074/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:37] [Train] Epoch: 263/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1187/4.6226/0.7840/0.0917/0.3725/5.9896\n",
            "[2025/03/08 20:29:38] [Train] Epoch: 263/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1210/4.3539/0.7753/0.0974/0.3591/5.7067\n",
            "[2025/03/08 20:29:39] [Eval]  Epoch: 263/300 F-score: 0.6051/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:40] [Train] Epoch: 264/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1239/4.2634/0.7598/0.1195/0.3651/5.6316\n",
            "[2025/03/08 20:29:41] [Train] Epoch: 264/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1221/4.3421/0.7696/0.1126/0.3549/5.7013\n",
            "[2025/03/08 20:29:41] [Eval]  Epoch: 264/300 F-score: 0.6243/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:43] [Train] Epoch: 265/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1252/4.2857/0.7690/0.1101/0.3774/5.6674\n",
            "[2025/03/08 20:29:43] [Train] Epoch: 265/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1187/4.3481/0.7682/0.1103/0.3749/5.7202\n",
            "[2025/03/08 20:29:44] [Eval]  Epoch: 265/300 F-score: 0.6065/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:45] [Train] Epoch: 266/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1232/4.4631/0.7557/0.1013/0.3437/5.7870\n",
            "[2025/03/08 20:29:46] [Train] Epoch: 266/300 Iter: 10/10 Time: 0.200 Data: 0.050 Loss: 0.1215/4.3370/0.7771/0.1078/0.3465/5.6899\n",
            "[2025/03/08 20:29:47] [Eval]  Epoch: 266/300 F-score: 0.6232/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:49] [Train] Epoch: 267/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1191/4.3437/0.7742/0.0788/0.3577/5.6735\n",
            "[2025/03/08 20:29:50] [Train] Epoch: 267/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1200/4.3513/0.7686/0.0823/0.3550/5.6772\n",
            "[2025/03/08 20:29:51] [Eval]  Epoch: 267/300 F-score: 0.5995/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:52] [Train] Epoch: 268/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1245/4.2982/0.7620/0.0951/0.3717/5.6515\n",
            "[2025/03/08 20:29:53] [Train] Epoch: 268/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1199/4.3302/0.7660/0.1037/0.3732/5.6931\n",
            "[2025/03/08 20:29:53] [Eval]  Epoch: 268/300 F-score: 0.6270/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:55] [Train] Epoch: 269/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1202/4.9928/0.7403/0.1111/0.3222/6.2866\n",
            "[2025/03/08 20:29:55] [Train] Epoch: 269/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1170/4.3466/0.7661/0.0977/0.3317/5.6592\n",
            "[2025/03/08 20:29:56] [Eval]  Epoch: 269/300 F-score: 0.6278/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:29:57] [Train] Epoch: 270/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1161/4.3884/0.7882/0.1071/0.3183/5.7181\n",
            "[2025/03/08 20:29:58] [Train] Epoch: 270/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1186/4.3412/0.7733/0.0980/0.3430/5.6741\n",
            "[2025/03/08 20:29:59] [Eval]  Epoch: 270/300 F-score: 0.6153/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:00] [Train] Epoch: 271/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1186/4.5081/0.7688/0.0846/0.3577/5.8377\n",
            "[2025/03/08 20:30:01] [Train] Epoch: 271/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1186/4.3321/0.7722/0.0924/0.3549/5.6704\n",
            "[2025/03/08 20:30:02] [Eval]  Epoch: 271/300 F-score: 0.6105/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:04] [Train] Epoch: 272/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1206/3.9155/0.7684/0.0828/0.3219/5.2093\n",
            "[2025/03/08 20:30:05] [Train] Epoch: 272/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1185/4.3407/0.7708/0.0876/0.3359/5.6536\n",
            "[2025/03/08 20:30:05] [Eval]  Epoch: 272/300 F-score: 0.6289/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:07] [Train] Epoch: 273/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1187/4.1348/0.8020/0.0841/0.3672/5.5068\n",
            "[2025/03/08 20:30:07] [Train] Epoch: 273/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1192/4.3397/0.7693/0.0895/0.3479/5.6655\n",
            "[2025/03/08 20:30:08] [Eval]  Epoch: 273/300 F-score: 0.6162/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:10] [Train] Epoch: 274/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1147/4.9017/0.7386/0.0933/0.3402/6.1886\n",
            "[2025/03/08 20:30:10] [Train] Epoch: 274/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1183/4.3397/0.7657/0.1004/0.3210/5.6451\n",
            "[2025/03/08 20:30:11] [Eval]  Epoch: 274/300 F-score: 0.6099/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:12] [Train] Epoch: 275/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1168/3.9965/0.8003/0.1245/0.3402/5.3783\n",
            "[2025/03/08 20:30:13] [Train] Epoch: 275/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1175/4.3380/0.7788/0.1086/0.3292/5.6721\n",
            "[2025/03/08 20:30:14] [Eval]  Epoch: 275/300 F-score: 0.6114/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:15] [Train] Epoch: 276/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1164/4.8102/0.7870/0.0892/0.3486/6.1514\n",
            "[2025/03/08 20:30:16] [Train] Epoch: 276/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1152/4.3391/0.7711/0.0825/0.3483/5.6562\n",
            "[2025/03/08 20:30:17] [Eval]  Epoch: 276/300 F-score: 0.6106/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:18] [Train] Epoch: 277/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1202/4.2385/0.7438/0.1039/0.3252/5.5316\n",
            "[2025/03/08 20:30:19] [Train] Epoch: 277/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1176/4.3351/0.7755/0.0959/0.3173/5.6414\n",
            "[2025/03/08 20:30:20] [Eval]  Epoch: 277/300 F-score: 0.6285/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:21] [Train] Epoch: 278/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1219/4.5486/0.7613/0.1022/0.3073/5.8413\n",
            "[2025/03/08 20:30:22] [Train] Epoch: 278/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1201/4.3455/0.7686/0.0948/0.3204/5.6494\n",
            "[2025/03/08 20:30:22] [Eval]  Epoch: 278/300 F-score: 0.6274/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:24] [Train] Epoch: 279/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1213/4.4289/0.7704/0.0901/0.3274/5.7380\n",
            "[2025/03/08 20:30:24] [Train] Epoch: 279/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1207/4.3364/0.7767/0.0869/0.3162/5.6370\n",
            "[2025/03/08 20:30:25] [Eval]  Epoch: 279/300 F-score: 0.6249/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:26] [Train] Epoch: 280/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1204/3.7921/0.8003/0.0760/0.2621/5.0509\n",
            "[2025/03/08 20:30:27] [Train] Epoch: 280/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1202/4.3317/0.7761/0.0889/0.2911/5.6080\n",
            "[2025/03/08 20:30:28] [Eval]  Epoch: 280/300 F-score: 0.6270/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:30] [Train] Epoch: 281/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1170/3.9780/0.7566/0.0712/0.3142/5.2372\n",
            "[2025/03/08 20:30:31] [Train] Epoch: 281/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1158/4.3416/0.7743/0.0713/0.3011/5.6041\n",
            "[2025/03/08 20:30:32] [Eval]  Epoch: 281/300 F-score: 0.6036/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:33] [Train] Epoch: 282/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1138/4.4137/0.7979/0.0927/0.3379/5.7560\n",
            "[2025/03/08 20:30:34] [Train] Epoch: 282/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1155/4.3191/0.7657/0.0921/0.3100/5.6025\n",
            "[2025/03/08 20:30:35] [Eval]  Epoch: 282/300 F-score: 0.6064/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:36] [Train] Epoch: 283/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1118/4.2976/0.8008/0.0959/0.3181/5.6243\n",
            "[2025/03/08 20:30:36] [Train] Epoch: 283/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1148/4.3304/0.7638/0.0931/0.3084/5.6106\n",
            "[2025/03/08 20:30:37] [Eval]  Epoch: 283/300 F-score: 0.6073/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:39] [Train] Epoch: 284/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1216/4.4026/0.7919/0.0797/0.3043/5.7001\n",
            "[2025/03/08 20:30:39] [Train] Epoch: 284/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1163/4.3231/0.7672/0.0798/0.3067/5.5930\n",
            "[2025/03/08 20:30:40] [Eval]  Epoch: 284/300 F-score: 0.6215/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:41] [Train] Epoch: 285/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1136/4.0232/0.8000/0.1084/0.2894/5.3346\n",
            "[2025/03/08 20:30:42] [Train] Epoch: 285/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1146/4.3183/0.7764/0.1026/0.3093/5.6211\n",
            "[2025/03/08 20:30:43] [Eval]  Epoch: 285/300 F-score: 0.6100/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:45] [Train] Epoch: 286/300 Iter: 5/10 Time: 0.201 Data: 0.051 Loss: 0.1136/4.2814/0.7693/0.0913/0.3178/5.5733\n",
            "[2025/03/08 20:30:46] [Train] Epoch: 286/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1166/4.3142/0.7623/0.0901/0.3307/5.6139\n",
            "[2025/03/08 20:30:47] [Eval]  Epoch: 286/300 F-score: 0.6036/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:48] [Train] Epoch: 287/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1198/4.6641/0.7619/0.0942/0.3154/5.9554\n",
            "[2025/03/08 20:30:49] [Train] Epoch: 287/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1183/4.3082/0.7673/0.0934/0.3075/5.5947\n",
            "[2025/03/08 20:30:49] [Eval]  Epoch: 287/300 F-score: 0.5988/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:51] [Train] Epoch: 288/300 Iter: 5/10 Time: 0.201 Data: 0.051 Loss: 0.1134/3.7116/0.8118/0.0912/0.2737/5.0016\n",
            "[2025/03/08 20:30:51] [Train] Epoch: 288/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1163/4.3174/0.7594/0.0849/0.2922/5.5701\n",
            "[2025/03/08 20:30:52] [Eval]  Epoch: 288/300 F-score: 0.6243/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:53] [Train] Epoch: 289/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1168/4.0393/0.7544/0.0861/0.3034/5.3000\n",
            "[2025/03/08 20:30:54] [Train] Epoch: 289/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1155/4.3178/0.7634/0.0910/0.2897/5.5775\n",
            "[2025/03/08 20:30:55] [Eval]  Epoch: 289/300 F-score: 0.6111/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:30:57] [Train] Epoch: 290/300 Iter: 5/10 Time: 0.201 Data: 0.051 Loss: 0.1163/4.1383/0.7773/0.0954/0.2998/5.4271\n",
            "[2025/03/08 20:30:57] [Train] Epoch: 290/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1180/4.3139/0.7654/0.0869/0.2916/5.5757\n",
            "[2025/03/08 20:30:58] [Eval]  Epoch: 290/300 F-score: 0.5993/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:00] [Train] Epoch: 291/300 Iter: 5/10 Time: 0.201 Data: 0.051 Loss: 0.1142/4.3493/0.7194/0.0722/0.2682/5.5232\n",
            "[2025/03/08 20:31:00] [Train] Epoch: 291/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1145/4.2849/0.7602/0.0707/0.2807/5.5109\n",
            "[2025/03/08 20:31:01] [Eval]  Epoch: 291/300 F-score: 0.6163/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:02] [Train] Epoch: 292/300 Iter: 5/10 Time: 0.201 Data: 0.051 Loss: 0.1149/4.1856/0.7612/0.0745/0.2854/5.4216\n",
            "[2025/03/08 20:31:03] [Train] Epoch: 292/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1138/4.3106/0.7607/0.0752/0.3075/5.5678\n",
            "[2025/03/08 20:31:04] [Eval]  Epoch: 292/300 F-score: 0.5953/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:05] [Train] Epoch: 293/300 Iter: 5/10 Time: 0.201 Data: 0.051 Loss: 0.1151/4.2877/0.7455/0.0723/0.2915/5.5121\n",
            "[2025/03/08 20:31:06] [Train] Epoch: 293/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1149/4.3028/0.7593/0.0767/0.2866/5.5402\n",
            "[2025/03/08 20:31:07] [Eval]  Epoch: 293/300 F-score: 0.6271/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:08] [Train] Epoch: 294/300 Iter: 5/10 Time: 0.201 Data: 0.051 Loss: 0.1154/4.0331/0.7694/0.0775/0.2353/5.2307\n",
            "[2025/03/08 20:31:09] [Train] Epoch: 294/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1148/4.3148/0.7588/0.0815/0.2653/5.5352\n",
            "[2025/03/08 20:31:10] [Eval]  Epoch: 294/300 F-score: 0.6151/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:12] [Train] Epoch: 295/300 Iter: 5/10 Time: 0.201 Data: 0.051 Loss: 0.1168/3.7785/0.7572/0.0968/0.2661/5.0154\n",
            "[2025/03/08 20:31:12] [Train] Epoch: 295/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1161/4.3016/0.7612/0.0853/0.2783/5.5425\n",
            "[2025/03/08 20:31:13] [Eval]  Epoch: 295/300 F-score: 0.6029/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:15] [Train] Epoch: 296/300 Iter: 5/10 Time: 0.201 Data: 0.051 Loss: 0.1086/5.0402/0.7256/0.0778/0.2883/6.2405\n",
            "[2025/03/08 20:31:15] [Train] Epoch: 296/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1128/4.2922/0.7533/0.0775/0.2704/5.5062\n",
            "[2025/03/08 20:31:16] [Eval]  Epoch: 296/300 F-score: 0.6208/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:17] [Train] Epoch: 297/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1112/4.6930/0.7463/0.0729/0.2718/5.8952\n",
            "[2025/03/08 20:31:18] [Train] Epoch: 297/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1111/4.2887/0.7576/0.0793/0.2724/5.5092\n",
            "[2025/03/08 20:31:19] [Eval]  Epoch: 297/300 F-score: 0.6035/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:20] [Train] Epoch: 298/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1048/4.3132/0.7988/0.0754/0.2767/5.5688\n",
            "[2025/03/08 20:31:21] [Train] Epoch: 298/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1123/4.3044/0.7599/0.0725/0.2665/5.5156\n",
            "[2025/03/08 20:31:21] [Eval]  Epoch: 298/300 F-score: 0.5991/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:23] [Train] Epoch: 299/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1106/4.6053/0.7776/0.0571/0.2670/5.8176\n",
            "[2025/03/08 20:31:24] [Train] Epoch: 299/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1127/4.2998/0.7598/0.0663/0.2680/5.5065\n",
            "[2025/03/08 20:31:25] [Eval]  Epoch: 299/300 F-score: 0.5962/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:26] [Train] Epoch: 300/300 Iter: 5/10 Time: 0.201 Data: 0.050 Loss: 0.1141/4.1822/0.7305/0.0765/0.2937/5.3971\n",
            "[2025/03/08 20:31:27] [Train] Epoch: 300/300 Iter: 10/10 Time: 0.201 Data: 0.050 Loss: 0.1152/4.3101/0.7595/0.0839/0.2717/5.5406\n",
            "[2025/03/08 20:31:28] [Eval]  Epoch: 300/300 F-score: 0.5888/0.6316\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:28] Start training on data/TVSum/splits.yml: split 1\n",
            "[2025/03/08 20:31:28] \n",
            "Model_VideoSumm(\n",
            "  (proj_fc_video): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
            "    (1): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (proj_fc_text): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
            "    (1): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (multiway_list): ModuleList(\n",
            "    (0-1): 2 x MultiWayTransformer(\n",
            "      (norm1_fused): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn_fusion): MultiHeadAttention(q_dims=128, k_dims=128, v_dims=128, h_dims=128, o_dims=128, heads=8, p=0.5, bias=True)\n",
            "      (norm2_video): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ffn_video): FFN(\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.5, inplace=False)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (drop2): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "      (norm2_text): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ffn_text): FFN(\n",
            "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.5, inplace=False)\n",
            "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "        (drop2): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm_video): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (norm_text): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (fc_video): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (fc_video_cls): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (fc_video_loc): Linear(in_features=128, out_features=2, bias=True)\n",
            "  (fc_video_ctr): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (fc_text): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (fc_text_cls): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (fc_text_loc): Linear(in_features=128, out_features=2, bias=True)\n",
            "  (fc_text_ctr): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n",
            "[2025/03/08 20:31:29] [Train] Epoch: 1/300 Iter: 5/10 Time: 0.288 Data: 0.111 Loss: 0.1651/6.2772/1.2612/0.1717/1.6975/9.5728\n",
            "[2025/03/08 20:31:30] [Train] Epoch: 1/300 Iter: 10/10 Time: 0.198 Data: 0.056 Loss: 0.1551/5.6356/1.2152/0.1661/1.4649/8.6369\n",
            "[2025/03/08 20:31:31] [Eval]  Epoch: 1/300 F-score: 0.5311/0.5311\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:32] [Train] Epoch: 2/300 Iter: 5/10 Time: 0.228 Data: 0.062 Loss: 0.1418/5.0235/1.1365/0.1561/1.1742/7.6321\n",
            "[2025/03/08 20:31:33] [Train] Epoch: 2/300 Iter: 10/10 Time: 0.203 Data: 0.047 Loss: 0.1423/5.2520/1.1149/0.1602/1.1680/7.8373\n",
            "[2025/03/08 20:31:34] [Eval]  Epoch: 2/300 F-score: 0.5445/0.5445\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:35] [Train] Epoch: 3/300 Iter: 5/10 Time: 0.219 Data: 0.055 Loss: 0.1417/5.0124/1.0657/0.1587/1.2014/7.5799\n",
            "[2025/03/08 20:31:35] [Train] Epoch: 3/300 Iter: 10/10 Time: 0.200 Data: 0.046 Loss: 0.1403/5.1942/1.0938/0.1566/1.1354/7.7204\n",
            "[2025/03/08 20:31:36] [Eval]  Epoch: 3/300 F-score: 0.5141/0.5445\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:38] [Train] Epoch: 4/300 Iter: 5/10 Time: 0.225 Data: 0.054 Loss: 0.1413/4.6233/1.1213/0.1484/1.0758/7.1101\n",
            "[2025/03/08 20:31:39] [Train] Epoch: 4/300 Iter: 10/10 Time: 0.215 Data: 0.048 Loss: 0.1414/5.1649/1.0827/0.1545/1.1415/7.6849\n",
            "[2025/03/08 20:31:40] [Eval]  Epoch: 4/300 F-score: 0.5144/0.5445\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:41] [Train] Epoch: 5/300 Iter: 5/10 Time: 0.222 Data: 0.052 Loss: 0.1397/5.0180/1.0703/0.1627/1.2349/7.6256\n",
            "[2025/03/08 20:31:42] [Train] Epoch: 5/300 Iter: 10/10 Time: 0.212 Data: 0.047 Loss: 0.1410/5.1674/1.0841/0.1559/1.1827/7.7311\n",
            "[2025/03/08 20:31:42] [Eval]  Epoch: 5/300 F-score: 0.5426/0.5445\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:44] [Train] Epoch: 6/300 Iter: 5/10 Time: 0.217 Data: 0.049 Loss: 0.1418/5.5249/1.0777/0.1572/1.1373/8.0389\n",
            "[2025/03/08 20:31:44] [Train] Epoch: 6/300 Iter: 10/10 Time: 0.208 Data: 0.045 Loss: 0.1419/5.1696/1.0814/0.1562/1.0943/7.6434\n",
            "[2025/03/08 20:31:45] [Eval]  Epoch: 6/300 F-score: 0.5301/0.5445\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:46] [Train] Epoch: 7/300 Iter: 5/10 Time: 0.213 Data: 0.049 Loss: 0.1448/4.9570/1.0718/0.1377/0.9131/7.2244\n",
            "[2025/03/08 20:31:47] [Train] Epoch: 7/300 Iter: 10/10 Time: 0.206 Data: 0.045 Loss: 0.1459/5.2215/1.0841/0.1519/0.8181/7.4215\n",
            "[2025/03/08 20:31:48] [Eval]  Epoch: 7/300 F-score: 0.5648/0.5648\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:49] [Train] Epoch: 8/300 Iter: 5/10 Time: 0.213 Data: 0.048 Loss: 0.1462/4.9797/1.0851/0.1444/0.7785/7.1337\n",
            "[2025/03/08 20:31:50] [Train] Epoch: 8/300 Iter: 10/10 Time: 0.207 Data: 0.045 Loss: 0.1453/5.2157/1.0870/0.1423/0.7611/7.3515\n",
            "[2025/03/08 20:31:51] [Eval]  Epoch: 8/300 F-score: 0.5663/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:53] [Train] Epoch: 9/300 Iter: 5/10 Time: 0.219 Data: 0.052 Loss: 0.1441/5.0715/1.1020/0.1582/1.0614/7.5372\n",
            "[2025/03/08 20:31:53] [Train] Epoch: 9/300 Iter: 10/10 Time: 0.212 Data: 0.049 Loss: 0.1452/5.2271/1.0853/0.1486/0.8849/7.4911\n",
            "[2025/03/08 20:31:54] [Eval]  Epoch: 9/300 F-score: 0.5613/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:55] [Train] Epoch: 10/300 Iter: 5/10 Time: 0.216 Data: 0.050 Loss: 0.1355/5.9517/1.0379/0.1454/1.2953/8.5658\n",
            "[2025/03/08 20:31:56] [Train] Epoch: 10/300 Iter: 10/10 Time: 0.210 Data: 0.048 Loss: 0.1356/5.1869/1.0777/0.1580/1.2960/7.8543\n",
            "[2025/03/08 20:31:56] [Eval]  Epoch: 10/300 F-score: 0.5338/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:31:58] [Train] Epoch: 11/300 Iter: 5/10 Time: 0.214 Data: 0.050 Loss: 0.1334/5.2297/1.0961/0.1558/1.4231/8.0381\n",
            "[2025/03/08 20:31:58] [Train] Epoch: 11/300 Iter: 10/10 Time: 0.209 Data: 0.048 Loss: 0.1361/5.1513/1.0794/0.1537/1.3223/7.8428\n",
            "[2025/03/08 20:31:59] [Eval]  Epoch: 11/300 F-score: 0.5355/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:00] [Train] Epoch: 12/300 Iter: 5/10 Time: 0.211 Data: 0.049 Loss: 0.1373/4.8340/1.0589/0.1583/1.2046/7.3931\n",
            "[2025/03/08 20:32:01] [Train] Epoch: 12/300 Iter: 10/10 Time: 0.208 Data: 0.047 Loss: 0.1367/5.1583/1.0744/0.1578/1.2517/7.7788\n",
            "[2025/03/08 20:32:02] [Eval]  Epoch: 12/300 F-score: 0.5298/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:04] [Train] Epoch: 13/300 Iter: 5/10 Time: 0.214 Data: 0.050 Loss: 0.1373/4.9676/1.1060/0.1393/1.0686/7.4188\n",
            "[2025/03/08 20:32:04] [Train] Epoch: 13/300 Iter: 10/10 Time: 0.211 Data: 0.048 Loss: 0.1394/5.1848/1.0817/0.1472/0.9858/7.5389\n",
            "[2025/03/08 20:32:05] [Eval]  Epoch: 13/300 F-score: 0.5341/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:07] [Train] Epoch: 14/300 Iter: 5/10 Time: 0.213 Data: 0.050 Loss: 0.1411/4.9615/1.0835/0.1495/0.7091/7.0448\n",
            "[2025/03/08 20:32:07] [Train] Epoch: 14/300 Iter: 10/10 Time: 0.210 Data: 0.048 Loss: 0.1408/5.1958/1.0816/0.1481/0.7447/7.3110\n",
            "[2025/03/08 20:32:08] [Eval]  Epoch: 14/300 F-score: 0.5518/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:09] [Train] Epoch: 15/300 Iter: 5/10 Time: 0.213 Data: 0.049 Loss: 0.1416/4.5222/1.0776/0.1489/0.6860/6.5763\n",
            "[2025/03/08 20:32:10] [Train] Epoch: 15/300 Iter: 10/10 Time: 0.209 Data: 0.047 Loss: 0.1411/5.1997/1.0791/0.1560/0.7339/7.3098\n",
            "[2025/03/08 20:32:10] [Eval]  Epoch: 15/300 F-score: 0.5387/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:12] [Train] Epoch: 16/300 Iter: 5/10 Time: 0.212 Data: 0.049 Loss: 0.1415/5.2688/1.1151/0.1393/0.9826/7.6472\n",
            "[2025/03/08 20:32:12] [Train] Epoch: 16/300 Iter: 10/10 Time: 0.209 Data: 0.048 Loss: 0.1414/5.1811/1.0801/0.1450/0.8713/7.4189\n",
            "[2025/03/08 20:32:13] [Eval]  Epoch: 16/300 F-score: 0.4360/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:15] [Train] Epoch: 17/300 Iter: 5/10 Time: 0.211 Data: 0.049 Loss: 0.1465/5.1088/1.0743/0.1583/0.7934/7.2813\n",
            "[2025/03/08 20:32:15] [Train] Epoch: 17/300 Iter: 10/10 Time: 0.207 Data: 0.048 Loss: 0.1458/5.2381/1.0852/0.1591/0.7413/7.3695\n",
            "[2025/03/08 20:32:16] [Eval]  Epoch: 17/300 F-score: 0.5412/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:18] [Train] Epoch: 18/300 Iter: 5/10 Time: 0.214 Data: 0.052 Loss: 0.1364/5.1001/1.0767/0.1558/1.4285/7.8975\n",
            "[2025/03/08 20:32:19] [Train] Epoch: 18/300 Iter: 10/10 Time: 0.212 Data: 0.050 Loss: 0.1382/5.1847/1.0757/0.1581/1.2457/7.8024\n",
            "[2025/03/08 20:32:19] [Eval]  Epoch: 18/300 F-score: 0.5525/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:21] [Train] Epoch: 19/300 Iter: 5/10 Time: 0.213 Data: 0.052 Loss: 0.1372/5.5234/1.0641/0.1554/1.0866/7.9667\n",
            "[2025/03/08 20:32:21] [Train] Epoch: 19/300 Iter: 10/10 Time: 0.211 Data: 0.050 Loss: 0.1373/5.1494/1.0772/0.1521/1.1119/7.6280\n",
            "[2025/03/08 20:32:22] [Eval]  Epoch: 19/300 F-score: 0.5303/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:23] [Train] Epoch: 20/300 Iter: 5/10 Time: 0.213 Data: 0.051 Loss: 0.1398/5.8314/1.0738/0.1381/1.0774/8.2605\n",
            "[2025/03/08 20:32:24] [Train] Epoch: 20/300 Iter: 10/10 Time: 0.210 Data: 0.050 Loss: 0.1404/5.1902/1.0761/0.1453/1.0105/7.5627\n",
            "[2025/03/08 20:32:25] [Eval]  Epoch: 20/300 F-score: 0.5320/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:26] [Train] Epoch: 21/300 Iter: 5/10 Time: 0.211 Data: 0.051 Loss: 0.1432/5.5360/1.0630/0.1642/0.7570/7.6634\n",
            "[2025/03/08 20:32:27] [Train] Epoch: 21/300 Iter: 10/10 Time: 0.209 Data: 0.050 Loss: 0.1446/5.1987/1.0848/0.1540/0.8356/7.4178\n",
            "[2025/03/08 20:32:27] [Eval]  Epoch: 21/300 F-score: 0.4853/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:28] [Train] Epoch: 22/300 Iter: 5/10 Time: 0.210 Data: 0.051 Loss: 0.1481/5.0615/1.0425/0.1548/0.6395/7.0465\n",
            "[2025/03/08 20:32:29] [Train] Epoch: 22/300 Iter: 10/10 Time: 0.209 Data: 0.050 Loss: 0.1478/5.1626/1.0824/0.1577/0.8183/7.3688\n",
            "[2025/03/08 20:32:30] [Eval]  Epoch: 22/300 F-score: 0.4556/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:32] [Train] Epoch: 23/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1479/5.0030/1.0847/0.1460/0.8769/7.2585\n",
            "[2025/03/08 20:32:33] [Train] Epoch: 23/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1445/5.2160/1.0862/0.1536/1.1199/7.7203\n",
            "[2025/03/08 20:32:34] [Eval]  Epoch: 23/300 F-score: 0.5216/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:35] [Train] Epoch: 24/300 Iter: 5/10 Time: 0.213 Data: 0.052 Loss: 0.1386/5.2652/1.0665/0.1477/1.2726/7.8906\n",
            "[2025/03/08 20:32:36] [Train] Epoch: 24/300 Iter: 10/10 Time: 0.211 Data: 0.051 Loss: 0.1392/5.1595/1.0764/0.1447/1.1548/7.6745\n",
            "[2025/03/08 20:32:36] [Eval]  Epoch: 24/300 F-score: 0.5527/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:37] [Train] Epoch: 25/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1392/4.7457/1.0586/0.1366/0.9346/7.0148\n",
            "[2025/03/08 20:32:38] [Train] Epoch: 25/300 Iter: 10/10 Time: 0.210 Data: 0.051 Loss: 0.1388/5.1501/1.0768/0.1411/0.9658/7.4726\n",
            "[2025/03/08 20:32:39] [Eval]  Epoch: 25/300 F-score: 0.5457/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:40] [Train] Epoch: 26/300 Iter: 5/10 Time: 0.211 Data: 0.051 Loss: 0.1379/5.0892/1.1062/0.1475/0.9416/7.4224\n",
            "[2025/03/08 20:32:41] [Train] Epoch: 26/300 Iter: 10/10 Time: 0.209 Data: 0.050 Loss: 0.1388/5.1530/1.0723/0.1501/0.8510/7.3651\n",
            "[2025/03/08 20:32:41] [Eval]  Epoch: 26/300 F-score: 0.5460/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:43] [Train] Epoch: 27/300 Iter: 5/10 Time: 0.211 Data: 0.052 Loss: 0.1388/5.5372/1.0688/0.1537/0.7771/7.6755\n",
            "[2025/03/08 20:32:44] [Train] Epoch: 27/300 Iter: 10/10 Time: 0.210 Data: 0.051 Loss: 0.1396/5.1818/1.0817/0.1497/0.7650/7.3179\n",
            "[2025/03/08 20:32:45] [Eval]  Epoch: 27/300 F-score: 0.5536/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:46] [Train] Epoch: 28/300 Iter: 5/10 Time: 0.213 Data: 0.052 Loss: 0.1399/5.3822/1.0704/0.1568/0.7214/7.4707\n",
            "[2025/03/08 20:32:47] [Train] Epoch: 28/300 Iter: 10/10 Time: 0.211 Data: 0.051 Loss: 0.1401/5.1917/1.0760/0.1571/0.7668/7.3316\n",
            "[2025/03/08 20:32:48] [Eval]  Epoch: 28/300 F-score: 0.5504/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:49] [Train] Epoch: 29/300 Iter: 5/10 Time: 0.212 Data: 0.051 Loss: 0.1408/5.0421/1.0946/0.1441/0.7474/7.1689\n",
            "[2025/03/08 20:32:50] [Train] Epoch: 29/300 Iter: 10/10 Time: 0.210 Data: 0.051 Loss: 0.1407/5.1947/1.0776/0.1435/0.7716/7.3281\n",
            "[2025/03/08 20:32:50] [Eval]  Epoch: 29/300 F-score: 0.5521/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:52] [Train] Epoch: 30/300 Iter: 5/10 Time: 0.211 Data: 0.052 Loss: 0.1399/5.6148/1.0677/0.1444/0.7382/7.7049\n",
            "[2025/03/08 20:32:52] [Train] Epoch: 30/300 Iter: 10/10 Time: 0.210 Data: 0.051 Loss: 0.1410/5.1722/1.0809/0.1508/0.7849/7.3297\n",
            "[2025/03/08 20:32:53] [Eval]  Epoch: 30/300 F-score: 0.5297/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:54] [Train] Epoch: 31/300 Iter: 5/10 Time: 0.211 Data: 0.052 Loss: 0.1433/4.7675/1.1218/0.1420/0.8346/7.0093\n",
            "[2025/03/08 20:32:55] [Train] Epoch: 31/300 Iter: 10/10 Time: 0.209 Data: 0.051 Loss: 0.1415/5.1701/1.0817/0.1493/0.8677/7.4103\n",
            "[2025/03/08 20:32:55] [Eval]  Epoch: 31/300 F-score: 0.5269/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:32:57] [Train] Epoch: 32/300 Iter: 5/10 Time: 0.211 Data: 0.052 Loss: 0.1392/4.6803/1.1036/0.1554/0.9337/7.0123\n",
            "[2025/03/08 20:32:58] [Train] Epoch: 32/300 Iter: 10/10 Time: 0.210 Data: 0.051 Loss: 0.1394/5.1598/1.0796/0.1465/0.9076/7.4328\n",
            "[2025/03/08 20:32:59] [Eval]  Epoch: 32/300 F-score: 0.5413/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:00] [Train] Epoch: 33/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1395/5.6067/1.0533/0.1464/0.7417/7.6876\n",
            "[2025/03/08 20:33:01] [Train] Epoch: 33/300 Iter: 10/10 Time: 0.210 Data: 0.052 Loss: 0.1402/5.1546/1.0767/0.1464/0.7856/7.3036\n",
            "[2025/03/08 20:33:02] [Eval]  Epoch: 33/300 F-score: 0.5229/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:03] [Train] Epoch: 34/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1375/5.2403/1.0537/0.1439/0.8822/7.4577\n",
            "[2025/03/08 20:33:04] [Train] Epoch: 34/300 Iter: 10/10 Time: 0.210 Data: 0.052 Loss: 0.1391/5.1493/1.0678/0.1472/0.8561/7.3594\n",
            "[2025/03/08 20:33:04] [Eval]  Epoch: 34/300 F-score: 0.5468/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:06] [Train] Epoch: 35/300 Iter: 5/10 Time: 0.211 Data: 0.053 Loss: 0.1400/4.4463/1.1126/0.1527/0.7754/6.6270\n",
            "[2025/03/08 20:33:06] [Train] Epoch: 35/300 Iter: 10/10 Time: 0.210 Data: 0.052 Loss: 0.1395/5.1626/1.0742/0.1478/0.8572/7.3813\n",
            "[2025/03/08 20:33:07] [Eval]  Epoch: 35/300 F-score: 0.5533/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:08] [Train] Epoch: 36/300 Iter: 5/10 Time: 0.211 Data: 0.053 Loss: 0.1381/5.4894/1.0339/0.1455/0.8724/7.6792\n",
            "[2025/03/08 20:33:09] [Train] Epoch: 36/300 Iter: 10/10 Time: 0.210 Data: 0.052 Loss: 0.1386/5.1340/1.0709/0.1492/0.9591/7.4518\n",
            "[2025/03/08 20:33:10] [Eval]  Epoch: 36/300 F-score: 0.5466/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:12] [Train] Epoch: 37/300 Iter: 5/10 Time: 0.212 Data: 0.054 Loss: 0.1392/5.4098/1.0808/0.1381/1.0037/7.7715\n",
            "[2025/03/08 20:33:12] [Train] Epoch: 37/300 Iter: 10/10 Time: 0.211 Data: 0.053 Loss: 0.1386/5.1201/1.0616/0.1396/1.0245/7.4843\n",
            "[2025/03/08 20:33:13] [Eval]  Epoch: 37/300 F-score: 0.5550/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:15] [Train] Epoch: 38/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1367/5.5543/1.0785/0.1504/1.0570/7.9768\n",
            "[2025/03/08 20:33:15] [Train] Epoch: 38/300 Iter: 10/10 Time: 0.211 Data: 0.053 Loss: 0.1387/5.1115/1.0634/0.1431/0.9863/7.4430\n",
            "[2025/03/08 20:33:16] [Eval]  Epoch: 38/300 F-score: 0.5530/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:17] [Train] Epoch: 39/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1397/4.6108/1.0452/0.1452/0.9057/6.8465\n",
            "[2025/03/08 20:33:18] [Train] Epoch: 39/300 Iter: 10/10 Time: 0.211 Data: 0.053 Loss: 0.1383/5.1244/1.0521/0.1449/1.0174/7.4770\n",
            "[2025/03/08 20:33:19] [Eval]  Epoch: 39/300 F-score: 0.5528/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:20] [Train] Epoch: 40/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1383/5.5247/1.0286/0.1408/0.9549/7.7872\n",
            "[2025/03/08 20:33:21] [Train] Epoch: 40/300 Iter: 10/10 Time: 0.210 Data: 0.052 Loss: 0.1381/5.1229/1.0607/0.1422/0.9925/7.4564\n",
            "[2025/03/08 20:33:21] [Eval]  Epoch: 40/300 F-score: 0.5484/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:23] [Train] Epoch: 41/300 Iter: 5/10 Time: 0.211 Data: 0.053 Loss: 0.1366/5.0044/1.0856/0.1414/1.0588/7.4268\n",
            "[2025/03/08 20:33:23] [Train] Epoch: 41/300 Iter: 10/10 Time: 0.210 Data: 0.052 Loss: 0.1378/5.1204/1.0553/0.1465/0.9566/7.4166\n",
            "[2025/03/08 20:33:24] [Eval]  Epoch: 41/300 F-score: 0.5442/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:26] [Train] Epoch: 42/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1375/5.3123/1.0320/0.1422/0.9300/7.5540\n",
            "[2025/03/08 20:33:27] [Train] Epoch: 42/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1376/5.1332/1.0541/0.1465/0.9424/7.4137\n",
            "[2025/03/08 20:33:28] [Eval]  Epoch: 42/300 F-score: 0.5587/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:29] [Train] Epoch: 43/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1389/4.8714/1.0705/0.1535/1.0154/7.2496\n",
            "[2025/03/08 20:33:30] [Train] Epoch: 43/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1376/5.1238/1.0151/0.1477/0.9364/7.3607\n",
            "[2025/03/08 20:33:30] [Eval]  Epoch: 43/300 F-score: 0.5395/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:32] [Train] Epoch: 44/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1378/5.4825/1.0160/0.1407/0.9074/7.6845\n",
            "[2025/03/08 20:33:33] [Train] Epoch: 44/300 Iter: 10/10 Time: 0.211 Data: 0.053 Loss: 0.1381/5.1264/1.0156/0.1412/0.8406/7.2619\n",
            "[2025/03/08 20:33:33] [Eval]  Epoch: 44/300 F-score: 0.5314/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:35] [Train] Epoch: 45/300 Iter: 5/10 Time: 0.212 Data: 0.054 Loss: 0.1386/4.8133/1.0364/0.1356/0.7745/6.8985\n",
            "[2025/03/08 20:33:35] [Train] Epoch: 45/300 Iter: 10/10 Time: 0.211 Data: 0.053 Loss: 0.1382/5.1476/1.0164/0.1388/0.7554/7.1965\n",
            "[2025/03/08 20:33:36] [Eval]  Epoch: 45/300 F-score: 0.5508/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:38] [Train] Epoch: 46/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1390/5.3261/1.0165/0.1521/0.6732/7.3069\n",
            "[2025/03/08 20:33:38] [Train] Epoch: 46/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1397/5.1538/1.0268/0.1548/0.6561/7.1313\n",
            "[2025/03/08 20:33:39] [Eval]  Epoch: 46/300 F-score: 0.5655/0.5663\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:41] [Train] Epoch: 47/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1383/5.0658/1.0209/0.1499/0.6472/7.0221\n",
            "[2025/03/08 20:33:42] [Train] Epoch: 47/300 Iter: 10/10 Time: 0.212 Data: 0.054 Loss: 0.1377/5.1402/1.0081/0.1494/0.8048/7.2403\n",
            "[2025/03/08 20:33:42] [Eval]  Epoch: 47/300 F-score: 0.5665/0.5665\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:44] [Train] Epoch: 48/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1388/5.1785/0.9999/0.1546/1.0718/7.5435\n",
            "[2025/03/08 20:33:44] [Train] Epoch: 48/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1385/5.1268/1.0009/0.1508/1.0165/7.4336\n",
            "[2025/03/08 20:33:45] [Eval]  Epoch: 48/300 F-score: 0.5416/0.5665\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:46] [Train] Epoch: 49/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1396/5.2521/0.9310/0.1420/0.8715/7.3363\n",
            "[2025/03/08 20:33:47] [Train] Epoch: 49/300 Iter: 10/10 Time: 0.212 Data: 0.054 Loss: 0.1408/5.1274/0.9928/0.1455/0.8538/7.2603\n",
            "[2025/03/08 20:33:48] [Eval]  Epoch: 49/300 F-score: 0.5404/0.5665\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:49] [Train] Epoch: 50/300 Iter: 5/10 Time: 0.212 Data: 0.054 Loss: 0.1390/5.2781/0.9551/0.1549/0.7469/7.2740\n",
            "[2025/03/08 20:33:50] [Train] Epoch: 50/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1391/5.1216/0.9768/0.1497/0.9164/7.3035\n",
            "[2025/03/08 20:33:50] [Eval]  Epoch: 50/300 F-score: 0.5338/0.5665\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:52] [Train] Epoch: 51/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1395/5.0935/0.9696/0.1659/1.0482/7.4167\n",
            "[2025/03/08 20:33:53] [Train] Epoch: 51/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1412/5.1595/0.9891/0.1623/0.9594/7.4115\n",
            "[2025/03/08 20:33:54] [Eval]  Epoch: 51/300 F-score: 0.5451/0.5665\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:55] [Train] Epoch: 52/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1429/5.2841/1.0302/0.1481/0.6167/7.2219\n",
            "[2025/03/08 20:33:56] [Train] Epoch: 52/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1437/5.1766/1.0123/0.1518/0.5877/7.0721\n",
            "[2025/03/08 20:33:57] [Eval]  Epoch: 52/300 F-score: 0.5565/0.5665\n",
            "\n",
            "\n",
            "[2025/03/08 20:33:58] [Train] Epoch: 53/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1403/5.3972/1.0373/0.1608/0.8432/7.5787\n",
            "[2025/03/08 20:33:59] [Train] Epoch: 53/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1406/5.1513/1.0010/0.1488/0.9755/7.4172\n",
            "[2025/03/08 20:33:59] [Eval]  Epoch: 53/300 F-score: 0.5587/0.5665\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:00] [Train] Epoch: 54/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1389/4.7912/0.9770/0.1448/0.9149/6.9668\n",
            "[2025/03/08 20:34:01] [Train] Epoch: 54/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1390/5.1371/0.9712/0.1439/0.9225/7.3137\n",
            "[2025/03/08 20:34:02] [Eval]  Epoch: 54/300 F-score: 0.5597/0.5665\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:03] [Train] Epoch: 55/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1365/5.1314/0.9956/0.1372/0.9125/7.3131\n",
            "[2025/03/08 20:34:04] [Train] Epoch: 55/300 Iter: 10/10 Time: 0.211 Data: 0.053 Loss: 0.1376/5.1233/0.9714/0.1410/0.8011/7.1743\n",
            "[2025/03/08 20:34:05] [Eval]  Epoch: 55/300 F-score: 0.5187/0.5665\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:07] [Train] Epoch: 56/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1388/5.3002/0.9821/0.1498/0.7830/7.3539\n",
            "[2025/03/08 20:34:07] [Train] Epoch: 56/300 Iter: 10/10 Time: 0.213 Data: 0.054 Loss: 0.1392/5.1145/0.9664/0.1476/0.7301/7.0977\n",
            "[2025/03/08 20:34:08] [Eval]  Epoch: 56/300 F-score: 0.5407/0.5665\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:10] [Train] Epoch: 57/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1378/5.6738/0.8885/0.1541/0.7277/7.5820\n",
            "[2025/03/08 20:34:10] [Train] Epoch: 57/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1394/5.1199/0.9519/0.1524/0.7584/7.1221\n",
            "[2025/03/08 20:34:11] [Eval]  Epoch: 57/300 F-score: 0.5797/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:12] [Train] Epoch: 58/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1397/5.4503/0.9457/0.1428/0.8810/7.5596\n",
            "[2025/03/08 20:34:13] [Train] Epoch: 58/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1403/5.1234/0.9651/0.1501/0.8647/7.2436\n",
            "[2025/03/08 20:34:13] [Eval]  Epoch: 58/300 F-score: 0.5427/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:15] [Train] Epoch: 59/300 Iter: 5/10 Time: 0.212 Data: 0.054 Loss: 0.1380/5.4195/0.9245/0.1553/0.8569/7.4942\n",
            "[2025/03/08 20:34:15] [Train] Epoch: 59/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1403/5.1807/0.9623/0.1568/0.8375/7.2777\n",
            "[2025/03/08 20:34:16] [Eval]  Epoch: 59/300 F-score: 0.5238/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:17] [Train] Epoch: 60/300 Iter: 5/10 Time: 0.212 Data: 0.054 Loss: 0.1398/5.7562/0.9434/0.1422/0.9608/7.9425\n",
            "[2025/03/08 20:34:18] [Train] Epoch: 60/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1417/5.1400/0.9804/0.1451/0.8431/7.2502\n",
            "[2025/03/08 20:34:19] [Eval]  Epoch: 60/300 F-score: 0.5556/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:21] [Train] Epoch: 61/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1403/4.7518/0.9625/0.1429/0.7352/6.7327\n",
            "[2025/03/08 20:34:22] [Train] Epoch: 61/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1396/5.1433/0.9602/0.1395/0.7699/7.1525\n",
            "[2025/03/08 20:34:23] [Eval]  Epoch: 61/300 F-score: 0.5070/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:24] [Train] Epoch: 62/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1382/5.4003/0.9579/0.1469/0.8947/7.5380\n",
            "[2025/03/08 20:34:24] [Train] Epoch: 62/300 Iter: 10/10 Time: 0.212 Data: 0.054 Loss: 0.1390/5.1143/0.9547/0.1453/0.7981/7.1513\n",
            "[2025/03/08 20:34:25] [Eval]  Epoch: 62/300 F-score: 0.5141/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:27] [Train] Epoch: 63/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1384/5.1205/0.9122/0.1475/0.7534/7.0720\n",
            "[2025/03/08 20:34:27] [Train] Epoch: 63/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1395/5.1284/0.9436/0.1420/0.6746/7.0281\n",
            "[2025/03/08 20:34:28] [Eval]  Epoch: 63/300 F-score: 0.5159/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:29] [Train] Epoch: 64/300 Iter: 5/10 Time: 0.212 Data: 0.054 Loss: 0.1387/5.1065/0.9478/0.1459/0.6109/6.9498\n",
            "[2025/03/08 20:34:30] [Train] Epoch: 64/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1393/5.1425/0.9581/0.1472/0.7059/7.0930\n",
            "[2025/03/08 20:34:30] [Eval]  Epoch: 64/300 F-score: 0.5365/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:32] [Train] Epoch: 65/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1386/5.0890/0.9928/0.1429/0.8673/7.2306\n",
            "[2025/03/08 20:34:33] [Train] Epoch: 65/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1397/5.1086/1.0052/0.1479/0.7838/7.1852\n",
            "[2025/03/08 20:34:34] [Eval]  Epoch: 65/300 F-score: 0.5574/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:36] [Train] Epoch: 66/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1391/5.2897/0.9530/0.1479/0.7789/7.3087\n",
            "[2025/03/08 20:34:36] [Train] Epoch: 66/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1396/5.1065/0.9774/0.1449/0.7501/7.1185\n",
            "[2025/03/08 20:34:37] [Eval]  Epoch: 66/300 F-score: 0.5551/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:38] [Train] Epoch: 67/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1384/5.3368/0.9766/0.1579/0.7157/7.3254\n",
            "[2025/03/08 20:34:39] [Train] Epoch: 67/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1396/5.1343/0.9550/0.1537/0.6635/7.0461\n",
            "[2025/03/08 20:34:40] [Eval]  Epoch: 67/300 F-score: 0.5554/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:41] [Train] Epoch: 68/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1378/5.3461/0.9093/0.1607/0.6010/7.1549\n",
            "[2025/03/08 20:34:42] [Train] Epoch: 68/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1381/5.1095/0.9437/0.1560/0.6987/7.0459\n",
            "[2025/03/08 20:34:42] [Eval]  Epoch: 68/300 F-score: 0.5563/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:44] [Train] Epoch: 69/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1383/5.0161/0.9499/0.1537/0.7564/7.0145\n",
            "[2025/03/08 20:34:44] [Train] Epoch: 69/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1383/5.1017/0.9374/0.1522/0.7596/7.0893\n",
            "[2025/03/08 20:34:45] [Eval]  Epoch: 69/300 F-score: 0.5695/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:47] [Train] Epoch: 70/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1383/4.8242/0.9381/0.1549/0.8571/6.9127\n",
            "[2025/03/08 20:34:48] [Train] Epoch: 70/300 Iter: 10/10 Time: 0.213 Data: 0.054 Loss: 0.1389/5.1163/0.9327/0.1490/0.8346/7.1715\n",
            "[2025/03/08 20:34:49] [Eval]  Epoch: 70/300 F-score: 0.5536/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:50] [Train] Epoch: 71/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1381/5.2679/0.9052/0.1457/0.7724/7.2293\n",
            "[2025/03/08 20:34:51] [Train] Epoch: 71/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1388/5.0938/0.9335/0.1497/0.8111/7.1269\n",
            "[2025/03/08 20:34:52] [Eval]  Epoch: 71/300 F-score: 0.5278/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:53] [Train] Epoch: 72/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1385/4.9674/0.9413/0.1479/0.7242/6.9193\n",
            "[2025/03/08 20:34:54] [Train] Epoch: 72/300 Iter: 10/10 Time: 0.213 Data: 0.054 Loss: 0.1391/5.0971/0.9462/0.1457/0.7767/7.1048\n",
            "[2025/03/08 20:34:54] [Eval]  Epoch: 72/300 F-score: 0.5333/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:55] [Train] Epoch: 73/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1396/4.9304/0.9412/0.1554/0.7416/6.9083\n",
            "[2025/03/08 20:34:56] [Train] Epoch: 73/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1387/5.1075/0.9236/0.1530/0.7847/7.1076\n",
            "[2025/03/08 20:34:57] [Eval]  Epoch: 73/300 F-score: 0.5297/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:34:58] [Train] Epoch: 74/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1386/5.0446/0.9289/0.1536/0.8360/7.1016\n",
            "[2025/03/08 20:34:59] [Train] Epoch: 74/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1388/5.0991/0.9187/0.1527/0.8011/7.1104\n",
            "[2025/03/08 20:35:00] [Eval]  Epoch: 74/300 F-score: 0.5682/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:02] [Train] Epoch: 75/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1389/4.9111/0.9531/0.1501/0.8287/6.9820\n",
            "[2025/03/08 20:35:03] [Train] Epoch: 75/300 Iter: 10/10 Time: 0.213 Data: 0.054 Loss: 0.1389/5.0946/0.9197/0.1495/0.7560/7.0586\n",
            "[2025/03/08 20:35:03] [Eval]  Epoch: 75/300 F-score: 0.5395/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:05] [Train] Epoch: 76/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1405/5.2995/0.9019/0.1520/0.6117/7.1057\n",
            "[2025/03/08 20:35:05] [Train] Epoch: 76/300 Iter: 10/10 Time: 0.213 Data: 0.054 Loss: 0.1400/5.1005/0.9355/0.1480/0.7017/7.0257\n",
            "[2025/03/08 20:35:06] [Eval]  Epoch: 76/300 F-score: 0.5378/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:08] [Train] Epoch: 77/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1384/5.2002/1.0234/0.1485/0.7083/7.2189\n",
            "[2025/03/08 20:35:08] [Train] Epoch: 77/300 Iter: 10/10 Time: 0.213 Data: 0.054 Loss: 0.1390/5.1408/0.9579/0.1475/0.6692/7.0545\n",
            "[2025/03/08 20:35:09] [Eval]  Epoch: 77/300 F-score: 0.5279/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:10] [Train] Epoch: 78/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1399/5.2163/0.9469/0.1362/0.7184/7.1578\n",
            "[2025/03/08 20:35:11] [Train] Epoch: 78/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1397/5.1136/0.9235/0.1434/0.6704/6.9906\n",
            "[2025/03/08 20:35:11] [Eval]  Epoch: 78/300 F-score: 0.5430/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:13] [Train] Epoch: 79/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1391/5.2378/0.9141/0.1489/0.6752/7.1151\n",
            "[2025/03/08 20:35:14] [Train] Epoch: 79/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1392/5.1103/0.9023/0.1472/0.6970/6.9959\n",
            "[2025/03/08 20:35:15] [Eval]  Epoch: 79/300 F-score: 0.5563/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:17] [Train] Epoch: 80/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1373/5.3078/0.9030/0.1389/0.9173/7.4043\n",
            "[2025/03/08 20:35:17] [Train] Epoch: 80/300 Iter: 10/10 Time: 0.214 Data: 0.053 Loss: 0.1388/5.0900/0.9025/0.1409/0.9459/7.2181\n",
            "[2025/03/08 20:35:18] [Eval]  Epoch: 80/300 F-score: 0.5460/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:19] [Train] Epoch: 81/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1386/5.4113/0.9116/0.1394/0.9768/7.5778\n",
            "[2025/03/08 20:35:20] [Train] Epoch: 81/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1391/5.0800/0.9302/0.1400/0.9347/7.2240\n",
            "[2025/03/08 20:35:20] [Eval]  Epoch: 81/300 F-score: 0.5636/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:22] [Train] Epoch: 82/300 Iter: 5/10 Time: 0.214 Data: 0.053 Loss: 0.1371/5.3787/0.9160/0.1497/0.8937/7.4751\n",
            "[2025/03/08 20:35:22] [Train] Epoch: 82/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1392/5.0917/0.9391/0.1474/0.7982/7.1155\n",
            "[2025/03/08 20:35:23] [Eval]  Epoch: 82/300 F-score: 0.5416/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:24] [Train] Epoch: 83/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1395/5.1692/0.9092/0.1395/0.6054/6.9627\n",
            "[2025/03/08 20:35:25] [Train] Epoch: 83/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1395/5.0876/0.9247/0.1448/0.6213/6.9178\n",
            "[2025/03/08 20:35:26] [Eval]  Epoch: 83/300 F-score: 0.5253/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:28] [Train] Epoch: 84/300 Iter: 5/10 Time: 0.214 Data: 0.053 Loss: 0.1384/5.0903/0.9443/0.1506/0.5783/6.9019\n",
            "[2025/03/08 20:35:28] [Train] Epoch: 84/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1387/5.0917/0.9453/0.1428/0.6080/6.9265\n",
            "[2025/03/08 20:35:29] [Eval]  Epoch: 84/300 F-score: 0.5656/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:31] [Train] Epoch: 85/300 Iter: 5/10 Time: 0.214 Data: 0.053 Loss: 0.1395/4.8492/0.9475/0.1413/0.6724/6.7499\n",
            "[2025/03/08 20:35:31] [Train] Epoch: 85/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1390/5.0792/0.9160/0.1489/0.6461/6.9293\n",
            "[2025/03/08 20:35:32] [Eval]  Epoch: 85/300 F-score: 0.5454/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:33] [Train] Epoch: 86/300 Iter: 5/10 Time: 0.214 Data: 0.053 Loss: 0.1397/5.5449/0.9102/0.1407/0.7131/7.4486\n",
            "[2025/03/08 20:35:34] [Train] Epoch: 86/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1398/5.0753/0.9004/0.1407/0.6559/6.9122\n",
            "[2025/03/08 20:35:35] [Eval]  Epoch: 86/300 F-score: 0.5163/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:36] [Train] Epoch: 87/300 Iter: 5/10 Time: 0.214 Data: 0.053 Loss: 0.1392/4.9847/0.9282/0.1511/0.7861/6.9893\n",
            "[2025/03/08 20:35:37] [Train] Epoch: 87/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1393/5.0702/0.8979/0.1496/0.7648/7.0218\n",
            "[2025/03/08 20:35:37] [Eval]  Epoch: 87/300 F-score: 0.4961/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:39] [Train] Epoch: 88/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1379/5.2243/0.9017/0.1434/0.8341/7.2415\n",
            "[2025/03/08 20:35:39] [Train] Epoch: 88/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1391/5.0758/0.8851/0.1418/0.7806/7.0223\n",
            "[2025/03/08 20:35:40] [Eval]  Epoch: 88/300 F-score: 0.5513/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:42] [Train] Epoch: 89/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1383/5.3235/0.8611/0.1467/0.7315/7.2010\n",
            "[2025/03/08 20:35:43] [Train] Epoch: 89/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1391/5.0705/0.8891/0.1461/0.7527/6.9975\n",
            "[2025/03/08 20:35:44] [Eval]  Epoch: 89/300 F-score: 0.5165/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:45] [Train] Epoch: 90/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1398/5.1197/0.8570/0.1459/0.6614/6.9237\n",
            "[2025/03/08 20:35:46] [Train] Epoch: 90/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1390/5.0696/0.8938/0.1407/0.7131/6.9562\n",
            "[2025/03/08 20:35:46] [Eval]  Epoch: 90/300 F-score: 0.5253/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:48] [Train] Epoch: 91/300 Iter: 5/10 Time: 0.214 Data: 0.053 Loss: 0.1387/4.6539/0.9196/0.1477/0.7321/6.5920\n",
            "[2025/03/08 20:35:48] [Train] Epoch: 91/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1385/5.0764/0.8764/0.1474/0.7174/6.9561\n",
            "[2025/03/08 20:35:49] [Eval]  Epoch: 91/300 F-score: 0.5550/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:50] [Train] Epoch: 92/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1399/5.1902/0.9196/0.1381/0.7207/7.1085\n",
            "[2025/03/08 20:35:51] [Train] Epoch: 92/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1390/5.0651/0.8917/0.1480/0.6984/6.9422\n",
            "[2025/03/08 20:35:52] [Eval]  Epoch: 92/300 F-score: 0.5511/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:53] [Train] Epoch: 93/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1391/5.2092/0.9232/0.1541/0.6919/7.1175\n",
            "[2025/03/08 20:35:54] [Train] Epoch: 93/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1391/5.0599/0.9016/0.1504/0.6702/6.9211\n",
            "[2025/03/08 20:35:55] [Eval]  Epoch: 93/300 F-score: 0.5288/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:57] [Train] Epoch: 94/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1389/4.8756/0.9525/0.1452/0.6333/6.7455\n",
            "[2025/03/08 20:35:57] [Train] Epoch: 94/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1382/5.0675/0.9192/0.1469/0.7131/6.9849\n",
            "[2025/03/08 20:35:58] [Eval]  Epoch: 94/300 F-score: 0.5542/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:35:59] [Train] Epoch: 95/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1387/4.8926/0.8777/0.1514/0.8154/6.8757\n",
            "[2025/03/08 20:36:00] [Train] Epoch: 95/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1381/5.0567/0.9102/0.1490/0.7566/7.0106\n",
            "[2025/03/08 20:36:01] [Eval]  Epoch: 95/300 F-score: 0.5415/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:02] [Train] Epoch: 96/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1396/4.8619/0.9270/0.1481/0.7638/6.8404\n",
            "[2025/03/08 20:36:03] [Train] Epoch: 96/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1389/5.0608/0.9068/0.1435/0.7183/6.9682\n",
            "[2025/03/08 20:36:03] [Eval]  Epoch: 96/300 F-score: 0.5699/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:05] [Train] Epoch: 97/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1374/5.4920/0.8633/0.1461/0.8000/7.4387\n",
            "[2025/03/08 20:36:05] [Train] Epoch: 97/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1394/5.0609/0.8869/0.1453/0.7687/7.0011\n",
            "[2025/03/08 20:36:06] [Eval]  Epoch: 97/300 F-score: 0.5385/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:08] [Train] Epoch: 98/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1383/4.7835/0.9009/0.1605/0.8460/6.8293\n",
            "[2025/03/08 20:36:08] [Train] Epoch: 98/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1383/5.0555/0.8923/0.1493/0.8247/7.0601\n",
            "[2025/03/08 20:36:09] [Eval]  Epoch: 98/300 F-score: 0.5498/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:11] [Train] Epoch: 99/300 Iter: 5/10 Time: 0.214 Data: 0.054 Loss: 0.1385/5.0680/0.8581/0.1400/0.7737/6.9783\n",
            "[2025/03/08 20:36:11] [Train] Epoch: 99/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1380/5.0426/0.8723/0.1426/0.7800/6.9755\n",
            "[2025/03/08 20:36:12] [Eval]  Epoch: 99/300 F-score: 0.5315/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:14] [Train] Epoch: 100/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1361/5.1194/0.9278/0.1432/0.8519/7.1786\n",
            "[2025/03/08 20:36:14] [Train] Epoch: 100/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1383/5.0160/0.8889/0.1453/0.7508/6.9393\n",
            "[2025/03/08 20:36:15] [Eval]  Epoch: 100/300 F-score: 0.5633/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:16] [Train] Epoch: 101/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1386/4.7324/0.9498/0.1415/0.7216/6.6839\n",
            "[2025/03/08 20:36:17] [Train] Epoch: 101/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1382/5.0345/0.8818/0.1417/0.7087/6.9049\n",
            "[2025/03/08 20:36:17] [Eval]  Epoch: 101/300 F-score: 0.5584/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:19] [Train] Epoch: 102/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1379/4.6021/0.8654/0.1425/0.6219/6.3698\n",
            "[2025/03/08 20:36:19] [Train] Epoch: 102/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1377/5.0432/0.8550/0.1404/0.6916/6.8679\n",
            "[2025/03/08 20:36:20] [Eval]  Epoch: 102/300 F-score: 0.5402/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:22] [Train] Epoch: 103/300 Iter: 5/10 Time: 0.213 Data: 0.054 Loss: 0.1381/4.7501/0.8708/0.1300/0.6032/6.4921\n",
            "[2025/03/08 20:36:23] [Train] Epoch: 103/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1380/5.0153/0.8598/0.1390/0.6322/6.7844\n",
            "[2025/03/08 20:36:24] [Eval]  Epoch: 103/300 F-score: 0.5517/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:25] [Train] Epoch: 104/300 Iter: 5/10 Time: 0.214 Data: 0.053 Loss: 0.1386/5.2701/0.8443/0.1541/0.6592/7.0663\n",
            "[2025/03/08 20:36:26] [Train] Epoch: 104/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1388/5.0301/0.8512/0.1514/0.6056/6.7770\n",
            "[2025/03/08 20:36:26] [Eval]  Epoch: 104/300 F-score: 0.5432/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:28] [Train] Epoch: 105/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1372/5.0263/0.8779/0.1410/0.5556/6.7380\n",
            "[2025/03/08 20:36:28] [Train] Epoch: 105/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1386/5.0094/0.8706/0.1419/0.5311/6.6916\n",
            "[2025/03/08 20:36:29] [Eval]  Epoch: 105/300 F-score: 0.5392/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:30] [Train] Epoch: 106/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1389/5.3210/0.8964/0.1460/0.4701/6.9725\n",
            "[2025/03/08 20:36:31] [Train] Epoch: 106/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1387/5.0458/0.8655/0.1426/0.4967/6.6893\n",
            "[2025/03/08 20:36:31] [Eval]  Epoch: 106/300 F-score: 0.5588/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:33] [Train] Epoch: 107/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1393/5.1930/0.8298/0.1466/0.6241/6.9328\n",
            "[2025/03/08 20:36:33] [Train] Epoch: 107/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1380/5.0225/0.8625/0.1471/0.6558/6.8259\n",
            "[2025/03/08 20:36:34] [Eval]  Epoch: 107/300 F-score: 0.5434/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:36] [Train] Epoch: 108/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1381/4.5748/0.8591/0.1394/0.8027/6.5141\n",
            "[2025/03/08 20:36:37] [Train] Epoch: 108/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1381/5.0374/0.8631/0.1407/0.7492/6.9285\n",
            "[2025/03/08 20:36:38] [Eval]  Epoch: 108/300 F-score: 0.5408/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:39] [Train] Epoch: 109/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1393/4.8175/0.8890/0.1458/0.6426/6.6342\n",
            "[2025/03/08 20:36:40] [Train] Epoch: 109/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1391/5.0362/0.8932/0.1500/0.6697/6.8882\n",
            "[2025/03/08 20:36:40] [Eval]  Epoch: 109/300 F-score: 0.5370/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:42] [Train] Epoch: 110/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1372/5.4363/0.8883/0.1470/0.6638/7.2726\n",
            "[2025/03/08 20:36:42] [Train] Epoch: 110/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1375/5.0256/0.8781/0.1460/0.6595/6.8468\n",
            "[2025/03/08 20:36:43] [Eval]  Epoch: 110/300 F-score: 0.5500/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:44] [Train] Epoch: 111/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1384/5.0878/0.8692/0.1461/0.7179/6.9593\n",
            "[2025/03/08 20:36:45] [Train] Epoch: 111/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1380/5.0254/0.8605/0.1458/0.7115/6.8812\n",
            "[2025/03/08 20:36:45] [Eval]  Epoch: 111/300 F-score: 0.5421/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:47] [Train] Epoch: 112/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1374/5.8206/0.8466/0.1457/0.6752/7.6254\n",
            "[2025/03/08 20:36:47] [Train] Epoch: 112/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1383/5.0359/0.8629/0.1445/0.6525/6.8339\n",
            "[2025/03/08 20:36:48] [Eval]  Epoch: 112/300 F-score: 0.5652/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:50] [Train] Epoch: 113/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1367/5.3572/0.8661/0.1528/0.6366/7.1493\n",
            "[2025/03/08 20:36:51] [Train] Epoch: 113/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1377/4.9888/0.8615/0.1515/0.6785/6.8179\n",
            "[2025/03/08 20:36:52] [Eval]  Epoch: 113/300 F-score: 0.5552/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:53] [Train] Epoch: 114/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1363/4.5543/0.9106/0.1597/0.7703/6.5311\n",
            "[2025/03/08 20:36:53] [Train] Epoch: 114/300 Iter: 10/10 Time: 0.213 Data: 0.053 Loss: 0.1377/5.0213/0.8630/0.1519/0.7444/6.9185\n",
            "[2025/03/08 20:36:54] [Eval]  Epoch: 114/300 F-score: 0.5577/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:55] [Train] Epoch: 115/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1410/5.0940/0.7911/0.1444/0.6854/6.8560\n",
            "[2025/03/08 20:36:56] [Train] Epoch: 115/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1388/5.0214/0.8432/0.1456/0.6719/6.8207\n",
            "[2025/03/08 20:36:57] [Eval]  Epoch: 115/300 F-score: 0.5398/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:36:58] [Train] Epoch: 116/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1375/5.4530/0.8098/0.1411/0.6225/7.1640\n",
            "[2025/03/08 20:36:59] [Train] Epoch: 116/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1377/4.9907/0.8460/0.1397/0.6412/6.7552\n",
            "[2025/03/08 20:36:59] [Eval]  Epoch: 116/300 F-score: 0.5586/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:01] [Train] Epoch: 117/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1370/5.1718/0.8727/0.1403/0.6696/6.9914\n",
            "[2025/03/08 20:37:01] [Train] Epoch: 117/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1374/4.9732/0.8430/0.1423/0.6628/6.7587\n",
            "[2025/03/08 20:37:02] [Eval]  Epoch: 117/300 F-score: 0.5421/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:04] [Train] Epoch: 118/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1372/4.4874/0.8413/0.1492/0.6970/6.3120\n",
            "[2025/03/08 20:37:05] [Train] Epoch: 118/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1373/4.9710/0.8264/0.1463/0.6629/6.7438\n",
            "[2025/03/08 20:37:05] [Eval]  Epoch: 118/300 F-score: 0.5308/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:07] [Train] Epoch: 119/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1384/5.1791/0.8284/0.1473/0.5809/6.8741\n",
            "[2025/03/08 20:37:07] [Train] Epoch: 119/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1381/4.9757/0.8382/0.1453/0.5790/6.6763\n",
            "[2025/03/08 20:37:08] [Eval]  Epoch: 119/300 F-score: 0.5564/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:09] [Train] Epoch: 120/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1367/4.9747/0.8690/0.1430/0.5270/6.6503\n",
            "[2025/03/08 20:37:10] [Train] Epoch: 120/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1370/4.9661/0.8503/0.1428/0.5187/6.6149\n",
            "[2025/03/08 20:37:11] [Eval]  Epoch: 120/300 F-score: 0.5402/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:12] [Train] Epoch: 121/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1391/4.5332/0.8256/0.1422/0.3792/6.0193\n",
            "[2025/03/08 20:37:13] [Train] Epoch: 121/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1379/4.9947/0.8545/0.1430/0.4633/6.5934\n",
            "[2025/03/08 20:37:13] [Eval]  Epoch: 121/300 F-score: 0.5564/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:15] [Train] Epoch: 122/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1377/5.1220/0.8135/0.1530/0.4050/6.6312\n",
            "[2025/03/08 20:37:16] [Train] Epoch: 122/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1376/4.9542/0.8602/0.1517/0.4241/6.5278\n",
            "[2025/03/08 20:37:16] [Eval]  Epoch: 122/300 F-score: 0.5411/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:18] [Train] Epoch: 123/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1368/4.7878/0.8250/0.1438/0.4177/6.3110\n",
            "[2025/03/08 20:37:19] [Train] Epoch: 123/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1369/4.9692/0.8504/0.1401/0.5181/6.6147\n",
            "[2025/03/08 20:37:19] [Eval]  Epoch: 123/300 F-score: 0.5485/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:21] [Train] Epoch: 124/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1388/5.1615/0.8371/0.1425/0.6121/6.8919\n",
            "[2025/03/08 20:37:21] [Train] Epoch: 124/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1388/4.9685/0.8468/0.1430/0.6355/6.7325\n",
            "[2025/03/08 20:37:22] [Eval]  Epoch: 124/300 F-score: 0.5585/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:23] [Train] Epoch: 125/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1416/4.4329/0.8293/0.1439/0.5411/6.0889\n",
            "[2025/03/08 20:37:24] [Train] Epoch: 125/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1389/4.9650/0.8540/0.1447/0.5807/6.6833\n",
            "[2025/03/08 20:37:25] [Eval]  Epoch: 125/300 F-score: 0.5419/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:26] [Train] Epoch: 126/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1369/4.8634/0.8449/0.1408/0.5508/6.5367\n",
            "[2025/03/08 20:37:26] [Train] Epoch: 126/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1368/4.9490/0.8359/0.1391/0.6083/6.6691\n",
            "[2025/03/08 20:37:27] [Eval]  Epoch: 126/300 F-score: 0.5594/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:29] [Train] Epoch: 127/300 Iter: 5/10 Time: 0.213 Data: 0.053 Loss: 0.1352/4.9333/0.8156/0.1410/0.5589/6.5841\n",
            "[2025/03/08 20:37:30] [Train] Epoch: 127/300 Iter: 10/10 Time: 0.212 Data: 0.053 Loss: 0.1371/4.9420/0.8401/0.1389/0.5740/6.6321\n",
            "[2025/03/08 20:37:31] [Eval]  Epoch: 127/300 F-score: 0.5321/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:32] [Train] Epoch: 128/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1378/4.9986/0.8098/0.1447/0.5488/6.6397\n",
            "[2025/03/08 20:37:33] [Train] Epoch: 128/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1373/4.9481/0.8360/0.1461/0.5376/6.6051\n",
            "[2025/03/08 20:37:33] [Eval]  Epoch: 128/300 F-score: 0.5401/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:35] [Train] Epoch: 129/300 Iter: 5/10 Time: 0.212 Data: 0.053 Loss: 0.1365/4.5947/0.8715/0.1399/0.5513/6.2938\n",
            "[2025/03/08 20:37:35] [Train] Epoch: 129/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1373/4.9518/0.8317/0.1422/0.5652/6.6282\n",
            "[2025/03/08 20:37:36] [Eval]  Epoch: 129/300 F-score: 0.5412/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:37] [Train] Epoch: 130/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1379/4.4315/0.8610/0.1413/0.5997/6.1715\n",
            "[2025/03/08 20:37:38] [Train] Epoch: 130/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1372/4.9440/0.8397/0.1375/0.5912/6.6496\n",
            "[2025/03/08 20:37:39] [Eval]  Epoch: 130/300 F-score: 0.5359/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:40] [Train] Epoch: 131/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1374/4.5533/0.8140/0.1505/0.4982/6.1534\n",
            "[2025/03/08 20:37:41] [Train] Epoch: 131/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1371/4.9380/0.8331/0.1456/0.5231/6.5769\n",
            "[2025/03/08 20:37:41] [Eval]  Epoch: 131/300 F-score: 0.5333/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:43] [Train] Epoch: 132/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1368/4.4465/0.8192/0.1418/0.7186/6.2628\n",
            "[2025/03/08 20:37:44] [Train] Epoch: 132/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1366/4.9139/0.8261/0.1405/0.7056/6.7228\n",
            "[2025/03/08 20:37:45] [Eval]  Epoch: 132/300 F-score: 0.5569/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:46] [Train] Epoch: 133/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1378/5.0174/0.8235/0.1356/0.6702/6.7845\n",
            "[2025/03/08 20:37:47] [Train] Epoch: 133/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1369/4.9143/0.8296/0.1414/0.6596/6.6817\n",
            "[2025/03/08 20:37:47] [Eval]  Epoch: 133/300 F-score: 0.5553/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:49] [Train] Epoch: 134/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1366/4.8501/0.8760/0.1389/0.6754/6.6771\n",
            "[2025/03/08 20:37:49] [Train] Epoch: 134/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1365/4.9249/0.8351/0.1410/0.6647/6.7023\n",
            "[2025/03/08 20:37:50] [Eval]  Epoch: 134/300 F-score: 0.5408/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:51] [Train] Epoch: 135/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1362/4.2290/0.8643/0.1454/0.6294/6.0044\n",
            "[2025/03/08 20:37:52] [Train] Epoch: 135/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1368/4.9447/0.8404/0.1440/0.5202/6.5862\n",
            "[2025/03/08 20:37:52] [Eval]  Epoch: 135/300 F-score: 0.5519/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:54] [Train] Epoch: 136/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1369/5.5933/0.8151/0.1471/0.3693/7.0617\n",
            "[2025/03/08 20:37:55] [Train] Epoch: 136/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1373/4.9668/0.8511/0.1458/0.3916/6.4925\n",
            "[2025/03/08 20:37:55] [Eval]  Epoch: 136/300 F-score: 0.5699/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:37:57] [Train] Epoch: 137/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1365/4.6466/0.8610/0.1429/0.3909/6.1780\n",
            "[2025/03/08 20:37:58] [Train] Epoch: 137/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1365/4.9418/0.8466/0.1431/0.3928/6.4609\n",
            "[2025/03/08 20:37:59] [Eval]  Epoch: 137/300 F-score: 0.5366/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:00] [Train] Epoch: 138/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1359/5.4976/0.8024/0.1363/0.4320/7.0041\n",
            "[2025/03/08 20:38:01] [Train] Epoch: 138/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1364/4.9176/0.8376/0.1389/0.4179/6.4485\n",
            "[2025/03/08 20:38:01] [Eval]  Epoch: 138/300 F-score: 0.5607/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:03] [Train] Epoch: 139/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1380/4.8761/0.8275/0.1416/0.3685/6.3518\n",
            "[2025/03/08 20:38:03] [Train] Epoch: 139/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1366/4.9276/0.8228/0.1430/0.3894/6.4193\n",
            "[2025/03/08 20:38:04] [Eval]  Epoch: 139/300 F-score: 0.5497/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:06] [Train] Epoch: 140/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1358/5.3617/0.8349/0.1475/0.4844/6.9642\n",
            "[2025/03/08 20:38:06] [Train] Epoch: 140/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1378/4.9179/0.8310/0.1444/0.4533/6.4845\n",
            "[2025/03/08 20:38:07] [Eval]  Epoch: 140/300 F-score: 0.5494/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:08] [Train] Epoch: 141/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1381/4.6857/0.8158/0.1481/0.3708/6.1585\n",
            "[2025/03/08 20:38:09] [Train] Epoch: 141/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1373/4.9300/0.8491/0.1475/0.4056/6.4694\n",
            "[2025/03/08 20:38:10] [Eval]  Epoch: 141/300 F-score: 0.5398/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:12] [Train] Epoch: 142/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1377/5.3893/0.8368/0.1451/0.5329/7.0418\n",
            "[2025/03/08 20:38:12] [Train] Epoch: 142/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1373/4.9260/0.8529/0.1418/0.5895/6.6475\n",
            "[2025/03/08 20:38:13] [Eval]  Epoch: 142/300 F-score: 0.5432/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:15] [Train] Epoch: 143/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1373/5.4494/0.8189/0.1468/0.9276/7.4800\n",
            "[2025/03/08 20:38:15] [Train] Epoch: 143/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1369/4.9056/0.8396/0.1432/0.9879/7.0133\n",
            "[2025/03/08 20:38:16] [Eval]  Epoch: 143/300 F-score: 0.5496/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:17] [Train] Epoch: 144/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1371/5.0432/0.8297/0.1311/0.9004/7.0415\n",
            "[2025/03/08 20:38:18] [Train] Epoch: 144/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1378/4.9030/0.8352/0.1365/0.8755/6.8880\n",
            "[2025/03/08 20:38:18] [Eval]  Epoch: 144/300 F-score: 0.5336/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:20] [Train] Epoch: 145/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1377/4.2832/0.8640/0.1452/0.7507/6.1807\n",
            "[2025/03/08 20:38:20] [Train] Epoch: 145/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1377/4.9114/0.8467/0.1429/0.7002/6.7389\n",
            "[2025/03/08 20:38:21] [Eval]  Epoch: 145/300 F-score: 0.5273/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:22] [Train] Epoch: 146/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1365/4.9484/0.8257/0.1382/0.5857/6.6347\n",
            "[2025/03/08 20:38:23] [Train] Epoch: 146/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1370/4.9454/0.8345/0.1424/0.6447/6.7041\n",
            "[2025/03/08 20:38:24] [Eval]  Epoch: 146/300 F-score: 0.5501/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:26] [Train] Epoch: 147/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1372/4.6941/0.8425/0.1426/0.7091/6.5256\n",
            "[2025/03/08 20:38:26] [Train] Epoch: 147/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1370/4.9236/0.8346/0.1423/0.6790/6.7164\n",
            "[2025/03/08 20:38:27] [Eval]  Epoch: 147/300 F-score: 0.5331/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:28] [Train] Epoch: 148/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1382/5.0191/0.8496/0.1359/0.6996/6.8424\n",
            "[2025/03/08 20:38:29] [Train] Epoch: 148/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1386/4.9107/0.8543/0.1428/0.6164/6.6628\n",
            "[2025/03/08 20:38:29] [Eval]  Epoch: 148/300 F-score: 0.5416/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:31] [Train] Epoch: 149/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1373/4.7758/0.8494/0.1449/0.5251/6.4326\n",
            "[2025/03/08 20:38:31] [Train] Epoch: 149/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1374/4.9388/0.8418/0.1459/0.5484/6.6123\n",
            "[2025/03/08 20:38:32] [Eval]  Epoch: 149/300 F-score: 0.5474/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:33] [Train] Epoch: 150/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1339/5.1182/0.8399/0.1401/0.5227/6.7547\n",
            "[2025/03/08 20:38:34] [Train] Epoch: 150/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1359/4.9216/0.8489/0.1378/0.5341/6.5782\n",
            "[2025/03/08 20:38:34] [Eval]  Epoch: 150/300 F-score: 0.5520/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:36] [Train] Epoch: 151/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1370/4.6445/0.8404/0.1418/0.5430/6.3068\n",
            "[2025/03/08 20:38:37] [Train] Epoch: 151/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1367/4.8809/0.8290/0.1366/0.5811/6.5642\n",
            "[2025/03/08 20:38:38] [Eval]  Epoch: 151/300 F-score: 0.5623/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:39] [Train] Epoch: 152/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1369/4.7566/0.8668/0.1478/0.5928/6.5009\n",
            "[2025/03/08 20:38:40] [Train] Epoch: 152/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1360/4.8773/0.8246/0.1433/0.5838/6.5650\n",
            "[2025/03/08 20:38:41] [Eval]  Epoch: 152/300 F-score: 0.5582/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:42] [Train] Epoch: 153/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1365/4.8885/0.7936/0.1434/0.5413/6.5033\n",
            "[2025/03/08 20:38:43] [Train] Epoch: 153/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1351/4.8864/0.8350/0.1417/0.5804/6.5787\n",
            "[2025/03/08 20:38:43] [Eval]  Epoch: 153/300 F-score: 0.5573/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:45] [Train] Epoch: 154/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1363/4.0325/0.8581/0.1391/0.5026/5.6686\n",
            "[2025/03/08 20:38:45] [Train] Epoch: 154/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1365/4.8916/0.8205/0.1392/0.4957/6.4836\n",
            "[2025/03/08 20:38:46] [Eval]  Epoch: 154/300 F-score: 0.5539/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:47] [Train] Epoch: 155/300 Iter: 5/10 Time: 0.211 Data: 0.052 Loss: 0.1384/4.4807/0.8193/0.1457/0.4865/6.0705\n",
            "[2025/03/08 20:38:48] [Train] Epoch: 155/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1365/4.8871/0.8119/0.1433/0.4736/6.4523\n",
            "[2025/03/08 20:38:49] [Eval]  Epoch: 155/300 F-score: 0.5547/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:51] [Train] Epoch: 156/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1360/4.6829/0.8886/0.1475/0.4634/6.3185\n",
            "[2025/03/08 20:38:51] [Train] Epoch: 156/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1355/4.8673/0.8253/0.1476/0.4407/6.4163\n",
            "[2025/03/08 20:38:52] [Eval]  Epoch: 156/300 F-score: 0.5552/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:54] [Train] Epoch: 157/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1364/4.7113/0.8135/0.1373/0.3794/6.1779\n",
            "[2025/03/08 20:38:54] [Train] Epoch: 157/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1362/4.8709/0.8214/0.1409/0.3935/6.3628\n",
            "[2025/03/08 20:38:55] [Eval]  Epoch: 157/300 F-score: 0.5578/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:56] [Train] Epoch: 158/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1341/4.6376/0.8051/0.1418/0.4502/6.1688\n",
            "[2025/03/08 20:38:57] [Train] Epoch: 158/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1347/4.8535/0.8095/0.1417/0.4357/6.3751\n",
            "[2025/03/08 20:38:58] [Eval]  Epoch: 158/300 F-score: 0.5596/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:38:59] [Train] Epoch: 159/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1361/5.0066/0.8010/0.1373/0.3913/6.4723\n",
            "[2025/03/08 20:38:59] [Train] Epoch: 159/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1367/4.8614/0.8200/0.1378/0.4206/6.3765\n",
            "[2025/03/08 20:39:00] [Eval]  Epoch: 159/300 F-score: 0.5642/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:02] [Train] Epoch: 160/300 Iter: 5/10 Time: 0.211 Data: 0.052 Loss: 0.1365/4.9950/0.8348/0.1438/0.4267/6.5369\n",
            "[2025/03/08 20:39:02] [Train] Epoch: 160/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1357/4.8534/0.8234/0.1426/0.4337/6.3889\n",
            "[2025/03/08 20:39:03] [Eval]  Epoch: 160/300 F-score: 0.5302/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:05] [Train] Epoch: 161/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1366/4.7812/0.7820/0.1348/0.3721/6.2067\n",
            "[2025/03/08 20:39:06] [Train] Epoch: 161/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1349/4.8231/0.8197/0.1390/0.4267/6.3435\n",
            "[2025/03/08 20:39:07] [Eval]  Epoch: 161/300 F-score: 0.5365/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:08] [Train] Epoch: 162/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1352/4.7691/0.8687/0.1444/0.4525/6.3699\n",
            "[2025/03/08 20:39:09] [Train] Epoch: 162/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1342/4.8422/0.8275/0.1412/0.4605/6.4057\n",
            "[2025/03/08 20:39:09] [Eval]  Epoch: 162/300 F-score: 0.5358/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:11] [Train] Epoch: 163/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1355/5.1583/0.8054/0.1353/0.3942/6.6288\n",
            "[2025/03/08 20:39:11] [Train] Epoch: 163/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1352/4.8285/0.8177/0.1387/0.4518/6.3719\n",
            "[2025/03/08 20:39:12] [Eval]  Epoch: 163/300 F-score: 0.5214/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:13] [Train] Epoch: 164/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1360/4.9472/0.8324/0.1402/0.4624/6.5182\n",
            "[2025/03/08 20:39:14] [Train] Epoch: 164/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1356/4.8500/0.8260/0.1408/0.5483/6.5007\n",
            "[2025/03/08 20:39:15] [Eval]  Epoch: 164/300 F-score: 0.5303/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:16] [Train] Epoch: 165/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1356/4.5138/0.8117/0.1463/0.5399/6.1473\n",
            "[2025/03/08 20:39:17] [Train] Epoch: 165/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1354/4.8124/0.8152/0.1447/0.6251/6.5328\n",
            "[2025/03/08 20:39:18] [Eval]  Epoch: 165/300 F-score: 0.5333/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:20] [Train] Epoch: 166/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1367/4.2659/0.7964/0.1398/0.4475/5.7864\n",
            "[2025/03/08 20:39:20] [Train] Epoch: 166/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1355/4.8264/0.8193/0.1396/0.5397/6.4605\n",
            "[2025/03/08 20:39:21] [Eval]  Epoch: 166/300 F-score: 0.5438/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:22] [Train] Epoch: 167/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1361/4.6301/0.8039/0.1356/0.5255/6.2313\n",
            "[2025/03/08 20:39:23] [Train] Epoch: 167/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1357/4.8311/0.8209/0.1342/0.5370/6.4590\n",
            "[2025/03/08 20:39:24] [Eval]  Epoch: 167/300 F-score: 0.5438/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:25] [Train] Epoch: 168/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1365/4.7349/0.8171/0.1374/0.5444/6.3702\n",
            "[2025/03/08 20:39:26] [Train] Epoch: 168/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1359/4.8245/0.8166/0.1399/0.5103/6.4271\n",
            "[2025/03/08 20:39:26] [Eval]  Epoch: 168/300 F-score: 0.5471/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:28] [Train] Epoch: 169/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1357/5.0553/0.8631/0.1452/0.4819/6.6811\n",
            "[2025/03/08 20:39:28] [Train] Epoch: 169/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1359/4.8375/0.8219/0.1450/0.4653/6.4055\n",
            "[2025/03/08 20:39:29] [Eval]  Epoch: 169/300 F-score: 0.5426/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:31] [Train] Epoch: 170/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1354/4.9046/0.8073/0.1437/0.4719/6.4629\n",
            "[2025/03/08 20:39:32] [Train] Epoch: 170/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1355/4.8325/0.8232/0.1437/0.4664/6.4013\n",
            "[2025/03/08 20:39:32] [Eval]  Epoch: 170/300 F-score: 0.5506/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:34] [Train] Epoch: 171/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1369/4.4696/0.7868/0.1377/0.4611/5.9920\n",
            "[2025/03/08 20:39:34] [Train] Epoch: 171/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1358/4.8370/0.8171/0.1423/0.4796/6.4117\n",
            "[2025/03/08 20:39:35] [Eval]  Epoch: 171/300 F-score: 0.5469/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:36] [Train] Epoch: 172/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1371/4.5441/0.8072/0.1442/0.4558/6.0883\n",
            "[2025/03/08 20:39:37] [Train] Epoch: 172/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1361/4.8329/0.8174/0.1441/0.4785/6.4089\n",
            "[2025/03/08 20:39:38] [Eval]  Epoch: 172/300 F-score: 0.5721/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:39] [Train] Epoch: 173/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1372/5.2866/0.8181/0.1364/0.4239/6.8022\n",
            "[2025/03/08 20:39:40] [Train] Epoch: 173/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1355/4.8377/0.8079/0.1413/0.4296/6.3519\n",
            "[2025/03/08 20:39:40] [Eval]  Epoch: 173/300 F-score: 0.5424/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:42] [Train] Epoch: 174/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1374/4.6990/0.7887/0.1470/0.4044/6.1764\n",
            "[2025/03/08 20:39:42] [Train] Epoch: 174/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1351/4.7951/0.8170/0.1484/0.4345/6.3302\n",
            "[2025/03/08 20:39:43] [Eval]  Epoch: 174/300 F-score: 0.5517/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:45] [Train] Epoch: 175/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1340/4.8893/0.8671/0.1453/0.3921/6.4278\n",
            "[2025/03/08 20:39:46] [Train] Epoch: 175/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1357/4.8112/0.8183/0.1419/0.3900/6.2972\n",
            "[2025/03/08 20:39:47] [Eval]  Epoch: 175/300 F-score: 0.5465/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:48] [Train] Epoch: 176/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1363/5.2009/0.7844/0.1366/0.4368/6.6951\n",
            "[2025/03/08 20:39:49] [Train] Epoch: 176/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1342/4.7996/0.8118/0.1370/0.5327/6.4153\n",
            "[2025/03/08 20:39:49] [Eval]  Epoch: 176/300 F-score: 0.5321/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:51] [Train] Epoch: 177/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1366/5.0293/0.8275/0.1524/0.6402/6.7861\n",
            "[2025/03/08 20:39:51] [Train] Epoch: 177/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1342/4.7932/0.8100/0.1447/0.6227/6.5050\n",
            "[2025/03/08 20:39:52] [Eval]  Epoch: 177/300 F-score: 0.5403/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:53] [Train] Epoch: 178/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1346/4.4040/0.8312/0.1407/0.5402/6.0507\n",
            "[2025/03/08 20:39:54] [Train] Epoch: 178/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1351/4.8070/0.8160/0.1439/0.5528/6.4548\n",
            "[2025/03/08 20:39:55] [Eval]  Epoch: 178/300 F-score: 0.5597/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:39:56] [Train] Epoch: 179/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1354/4.7066/0.7988/0.1320/0.5835/6.3562\n",
            "[2025/03/08 20:39:57] [Train] Epoch: 179/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1343/4.8138/0.8059/0.1370/0.5738/6.4648\n",
            "[2025/03/08 20:39:58] [Eval]  Epoch: 179/300 F-score: 0.5322/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:00] [Train] Epoch: 180/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1348/4.6239/0.8334/0.1420/0.5089/6.2429\n",
            "[2025/03/08 20:40:00] [Train] Epoch: 180/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1343/4.8095/0.8137/0.1369/0.5465/6.4409\n",
            "[2025/03/08 20:40:01] [Eval]  Epoch: 180/300 F-score: 0.5374/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:02] [Train] Epoch: 181/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1350/4.6566/0.8077/0.1422/0.5994/6.3408\n",
            "[2025/03/08 20:40:03] [Train] Epoch: 181/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1362/4.8043/0.8127/0.1424/0.5840/6.4796\n",
            "[2025/03/08 20:40:04] [Eval]  Epoch: 181/300 F-score: 0.5338/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:05] [Train] Epoch: 182/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1358/5.0438/0.8249/0.1401/0.5969/6.7414\n",
            "[2025/03/08 20:40:05] [Train] Epoch: 182/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1372/4.7804/0.8229/0.1378/0.5749/6.4533\n",
            "[2025/03/08 20:40:06] [Eval]  Epoch: 182/300 F-score: 0.5270/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:07] [Train] Epoch: 183/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1367/4.7132/0.8572/0.1436/0.5544/6.4052\n",
            "[2025/03/08 20:40:08] [Train] Epoch: 183/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1357/4.7892/0.8279/0.1414/0.5604/6.4547\n",
            "[2025/03/08 20:40:09] [Eval]  Epoch: 183/300 F-score: 0.5535/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:11] [Train] Epoch: 184/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1335/4.9998/0.7883/0.1474/0.6118/6.6808\n",
            "[2025/03/08 20:40:11] [Train] Epoch: 184/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1340/4.7905/0.8087/0.1411/0.5582/6.4325\n",
            "[2025/03/08 20:40:12] [Eval]  Epoch: 184/300 F-score: 0.5473/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:14] [Train] Epoch: 185/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1362/4.8150/0.8110/0.1458/0.4758/6.3838\n",
            "[2025/03/08 20:40:15] [Train] Epoch: 185/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1352/4.7841/0.8109/0.1423/0.4977/6.3702\n",
            "[2025/03/08 20:40:15] [Eval]  Epoch: 185/300 F-score: 0.5370/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:17] [Train] Epoch: 186/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1337/3.8455/0.8664/0.1449/0.4873/5.4778\n",
            "[2025/03/08 20:40:17] [Train] Epoch: 186/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1349/4.7680/0.8066/0.1421/0.4758/6.3273\n",
            "[2025/03/08 20:40:18] [Eval]  Epoch: 186/300 F-score: 0.5421/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:19] [Train] Epoch: 187/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1352/5.3987/0.8005/0.1318/0.4700/6.9362\n",
            "[2025/03/08 20:40:20] [Train] Epoch: 187/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1349/4.7750/0.8204/0.1368/0.4621/6.3292\n",
            "[2025/03/08 20:40:21] [Eval]  Epoch: 187/300 F-score: 0.5322/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:22] [Train] Epoch: 188/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1340/4.7191/0.8216/0.1325/0.4479/6.2551\n",
            "[2025/03/08 20:40:22] [Train] Epoch: 188/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1339/4.7845/0.8218/0.1374/0.4558/6.3334\n",
            "[2025/03/08 20:40:23] [Eval]  Epoch: 188/300 F-score: 0.5227/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:25] [Train] Epoch: 189/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1344/4.3161/0.7749/0.1455/0.4355/5.8065\n",
            "[2025/03/08 20:40:26] [Train] Epoch: 189/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1341/4.7535/0.8062/0.1452/0.4239/6.2629\n",
            "[2025/03/08 20:40:27] [Eval]  Epoch: 189/300 F-score: 0.5266/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:28] [Train] Epoch: 190/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1359/5.3979/0.7911/0.1383/0.3765/6.8397\n",
            "[2025/03/08 20:40:29] [Train] Epoch: 190/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1354/4.7742/0.8129/0.1366/0.3958/6.2549\n",
            "[2025/03/08 20:40:30] [Eval]  Epoch: 190/300 F-score: 0.5336/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:31] [Train] Epoch: 191/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1326/4.5190/0.7819/0.1476/0.4338/6.0150\n",
            "[2025/03/08 20:40:32] [Train] Epoch: 191/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1340/4.7425/0.8047/0.1460/0.4352/6.2624\n",
            "[2025/03/08 20:40:32] [Eval]  Epoch: 191/300 F-score: 0.5414/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:34] [Train] Epoch: 192/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1364/4.2123/0.8564/0.1438/0.4452/5.7940\n",
            "[2025/03/08 20:40:34] [Train] Epoch: 192/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1342/4.7789/0.8074/0.1450/0.4512/6.3168\n",
            "[2025/03/08 20:40:35] [Eval]  Epoch: 192/300 F-score: 0.5250/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:36] [Train] Epoch: 193/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1353/4.4494/0.8131/0.1354/0.5608/6.0940\n",
            "[2025/03/08 20:40:37] [Train] Epoch: 193/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1332/4.7463/0.8054/0.1399/0.5632/6.3880\n",
            "[2025/03/08 20:40:38] [Eval]  Epoch: 193/300 F-score: 0.5422/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:40] [Train] Epoch: 194/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1356/5.2814/0.7313/0.1447/0.5477/6.8407\n",
            "[2025/03/08 20:40:41] [Train] Epoch: 194/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1332/4.7503/0.8001/0.1455/0.5586/6.3876\n",
            "[2025/03/08 20:40:41] [Eval]  Epoch: 194/300 F-score: 0.5403/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:43] [Train] Epoch: 195/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1337/4.5269/0.8094/0.1398/0.5729/6.1826\n",
            "[2025/03/08 20:40:43] [Train] Epoch: 195/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1330/4.7142/0.8070/0.1368/0.5359/6.3268\n",
            "[2025/03/08 20:40:44] [Eval]  Epoch: 195/300 F-score: 0.5375/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:46] [Train] Epoch: 196/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1304/5.2903/0.8112/0.1379/0.5632/6.9329\n",
            "[2025/03/08 20:40:46] [Train] Epoch: 196/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1334/4.7097/0.8029/0.1364/0.5129/6.2952\n",
            "[2025/03/08 20:40:47] [Eval]  Epoch: 196/300 F-score: 0.5528/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:48] [Train] Epoch: 197/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1307/4.6456/0.8081/0.1484/0.5613/6.2940\n",
            "[2025/03/08 20:40:49] [Train] Epoch: 197/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1333/4.7087/0.7925/0.1442/0.5151/6.2938\n",
            "[2025/03/08 20:40:49] [Eval]  Epoch: 197/300 F-score: 0.5551/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:51] [Train] Epoch: 198/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1318/5.1067/0.7824/0.1360/0.5021/6.6589\n",
            "[2025/03/08 20:40:52] [Train] Epoch: 198/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1321/4.7023/0.8054/0.1401/0.5082/6.2881\n",
            "[2025/03/08 20:40:53] [Eval]  Epoch: 198/300 F-score: 0.5482/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:54] [Train] Epoch: 199/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1323/4.3362/0.8055/0.1211/0.5479/5.9430\n",
            "[2025/03/08 20:40:55] [Train] Epoch: 199/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1336/4.7116/0.7944/0.1292/0.5032/6.2719\n",
            "[2025/03/08 20:40:55] [Eval]  Epoch: 199/300 F-score: 0.5533/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:57] [Train] Epoch: 200/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1327/4.6260/0.7928/0.1298/0.4927/6.1739\n",
            "[2025/03/08 20:40:57] [Train] Epoch: 200/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1330/4.7221/0.7984/0.1336/0.4975/6.2846\n",
            "[2025/03/08 20:40:58] [Eval]  Epoch: 200/300 F-score: 0.5549/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:40:59] [Train] Epoch: 201/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1344/5.0065/0.7814/0.1427/0.4896/6.5547\n",
            "[2025/03/08 20:41:00] [Train] Epoch: 201/300 Iter: 10/10 Time: 0.212 Data: 0.052 Loss: 0.1328/4.7070/0.7971/0.1389/0.4770/6.2528\n",
            "[2025/03/08 20:41:01] [Eval]  Epoch: 201/300 F-score: 0.5393/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:41:02] [Train] Epoch: 202/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1305/4.4485/0.8409/0.1341/0.4994/6.0535\n",
            "[2025/03/08 20:41:02] [Train] Epoch: 202/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1326/4.7042/0.7955/0.1364/0.4713/6.2401\n",
            "[2025/03/08 20:41:03] [Eval]  Epoch: 202/300 F-score: 0.5555/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:41:05] [Train] Epoch: 203/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1318/4.6594/0.7603/0.1331/0.4666/6.1512\n",
            "[2025/03/08 20:41:05] [Train] Epoch: 203/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1329/4.7125/0.7996/0.1395/0.4581/6.2426\n",
            "[2025/03/08 20:41:06] [Eval]  Epoch: 203/300 F-score: 0.5339/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:41:08] [Train] Epoch: 204/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1303/4.8115/0.8025/0.1454/0.4373/6.3270\n",
            "[2025/03/08 20:41:09] [Train] Epoch: 204/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1307/4.6974/0.7992/0.1347/0.4122/6.1742\n",
            "[2025/03/08 20:41:09] [Eval]  Epoch: 204/300 F-score: 0.5505/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:41:10] [Train] Epoch: 205/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1327/4.7927/0.8196/0.1296/0.3896/6.2641\n",
            "[2025/03/08 20:41:11] [Train] Epoch: 205/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1321/4.6818/0.8077/0.1349/0.4019/6.1584\n",
            "[2025/03/08 20:41:12] [Eval]  Epoch: 205/300 F-score: 0.5512/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:41:13] [Train] Epoch: 206/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1316/4.7135/0.7723/0.1387/0.4054/6.1616\n",
            "[2025/03/08 20:41:14] [Train] Epoch: 206/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1313/4.6594/0.7964/0.1360/0.3845/6.1076\n",
            "[2025/03/08 20:41:14] [Eval]  Epoch: 206/300 F-score: 0.5685/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:41:16] [Train] Epoch: 207/300 Iter: 5/10 Time: 0.211 Data: 0.052 Loss: 0.1338/5.0246/0.7561/0.1442/0.3698/6.4286\n",
            "[2025/03/08 20:41:16] [Train] Epoch: 207/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1305/4.6668/0.7985/0.1347/0.3911/6.1217\n",
            "[2025/03/08 20:41:17] [Eval]  Epoch: 207/300 F-score: 0.5668/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:41:19] [Train] Epoch: 208/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1324/4.6928/0.8155/0.1326/0.3509/6.1241\n",
            "[2025/03/08 20:41:20] [Train] Epoch: 208/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1315/4.6481/0.8057/0.1287/0.3908/6.1048\n",
            "[2025/03/08 20:41:21] [Eval]  Epoch: 208/300 F-score: 0.5256/0.5797\n",
            "\n",
            "\n",
            "[2025/03/08 20:41:22] [Train] Epoch: 209/300 Iter: 5/10 Time: 0.212 Data: 0.052 Loss: 0.1293/4.4632/0.8290/0.1287/0.4599/6.0100\n",
            "[2025/03/08 20:41:23] [Train] Epoch: 209/300 Iter: 10/10 Time: 0.211 Data: 0.052 Loss: 0.1314/4.6423/0.7979/0.1369/0.4374/6.1459\n",
            "[2025/03/08 20:41:23] [Eval]  Epoch: 209/300 F-score: 0.5663/0.5797\n",
            "\n",
            "\n",
            "Exception in thread Thread-1020 (_pin_memory_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 59, in _pin_memory_loop\n",
            "    do_one_step()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 35, in do_one_step\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "         ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 519, in Client\n",
            "    c = SocketClient(address)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 647, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "Process Process-4075:\n",
            "Process Process-4076:\n",
            "Process Process-4074:\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ae8c42a4cc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1568, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
            "    ready = selector.select(timeout)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/selectors.py\", line 415, in select\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1LuXWjW3BcAXCOals4o2UUVYMx-FYnJ3T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EPr408WfkKH",
        "outputId": "26644a3d-022b-451a-e7f6-9969669fdb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1LuXWjW3BcAXCOals4o2UUVYMx-FYnJ3T\n",
            "From (redirected): https://drive.google.com/uc?id=1LuXWjW3BcAXCOals4o2UUVYMx-FYnJ3T&confirm=t&uuid=dbfc8ab9-eb76-432a-bbd9-4afdc0e7750c\n",
            "To: /content/drive/MyDrive/A2Summ/saved_model.tar\n",
            "100% 191M/191M [00:08<00:00, 22.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf saved_model.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t84djLGcfqhr",
        "outputId": "73a85ab9-3779-4548-8421-fde92b1ea665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved_model/\n",
            "saved_model/BLiSS/\n",
            "saved_model/BLiSS/model_best_video.pt\n",
            "saved_model/BLiSS/model_best_text.pt\n",
            "saved_model/Daily_Mail/\n",
            "saved_model/Daily_Mail/model_best_video.pt\n",
            "saved_model/Daily_Mail/model_best_text.pt\n",
            "saved_model/SumMe/\n",
            "saved_model/SumMe/model_best_split3.pt\n",
            "saved_model/SumMe/model_best_split0.pt\n",
            "saved_model/SumMe/model_best_split1.pt\n",
            "saved_model/SumMe/model_best_split2.pt\n",
            "saved_model/SumMe/model_best_split4.pt\n",
            "saved_model/CNN/\n",
            "saved_model/CNN/model_best_video.pt\n",
            "saved_model/CNN/model_best_text.pt\n",
            "saved_model/TVSum/\n",
            "saved_model/TVSum/model_best_split3.pt\n",
            "saved_model/TVSum/model_best_split0.pt\n",
            "saved_model/TVSum/model_best_split1.pt\n",
            "saved_model/TVSum/model_best_split2.pt\n",
            "saved_model/TVSum/model_best_split4.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset TVSum \\--test --checkpoint saved_model/TVSum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW2I96WlgNuE",
        "outputId": "1de28d2f-ebc8-4abe-b7c6-0ddbc3cece91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-11 10:09:54.026092: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741687794.046468    5626 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741687794.053363    5626 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-11 10:09:54.074133: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025/03/11 10:09:58] {'dataset': 'TVSum', 'data_root': 'data', 'device': 'cuda', 'seed': 666, 'max_epoch': 300, 'start_epoch': 0, 'batch_size': 4, 'num_workers': 4, 'model_dir': 'logs/TVSum', 'log_file': 'log.txt', 'lr': 0.001, 'weight_decay': 1e-05, 'nms_thresh': 0.4, 'print_freq': 5, 'eval_freq': 1, 'suffix': '', 'checkpoint': 'saved_model/TVSum', 'test': True, 'num_input_video': 1024, 'num_input_text': 768, 'num_feature': 512, 'num_hidden': 128, 'dropout_video': 0.1, 'dropout_text': 0.1, 'dropout_attn': 0.5, 'dropout_fc': 0.5, 'num_layers': 2, 'lambda_contrastive_inter': 0.1, 'lambda_contrastive_intra': 1.0, 'ratio': 16}\n",
            "logs/TVSum\n",
            "[2025/03/11 10:09:58] Start training on data/TVSum/splits.yml: split 0\n",
            "/content/drive/MyDrive/A2Summ/train_videosumm.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
            "load checkpoint from saved_model/TVSum/model_best_split0.pt\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[2025/03/11 10:10:01] Saved frame data for video_35: 667 key frames identified, 641 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_43: 736 key frames identified, 730 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_21: 2911 key frames identified, 2903 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_16: 1424 key frames identified, 1430 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_38: 436 key frames identified, 441 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_31: 808 key frames identified, 808 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_33: 2000 key frames identified, 1994 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_34: 546 key frames identified, 539 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_38: 1586 key frames identified, 1585 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_31: 642 key frames identified, 622 ground truth frames\n",
            "[2025/03/11 10:10:01] Completed saving frame data to TVSum_frames folder\n",
            "[2025/03/11 10:10:01] F-score: 0.6383\n",
            "[2025/03/11 10:10:01] Start training on data/TVSum/splits.yml: split 1\n",
            "load checkpoint from saved_model/TVSum/model_best_split1.pt\n",
            "[2025/03/11 10:10:01] Saved frame data for video_34: 540 key frames identified, 539 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_50: 1036 key frames identified, 1024 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_11: 674 key frames identified, 703 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_19: 832 key frames identified, 860 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_10: 599 key frames identified, 552 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_27: 1635 key frames identified, 1629 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_16: 1428 key frames identified, 1430 ground truth frames\n",
            "[2025/03/11 10:10:01] Saved frame data for video_1: 1586 key frames identified, 1585 ground truth frames\n",
            "[2025/03/11 10:10:02] Saved frame data for video_10: 582 key frames identified, 572 ground truth frames\n",
            "[2025/03/11 10:10:02] Saved frame data for video_27: 640 key frames identified, 622 ground truth frames\n",
            "[2025/03/11 10:10:02] Completed saving frame data to TVSum_frames folder\n",
            "[2025/03/11 10:10:02] F-score: 0.5973\n",
            "[2025/03/11 10:10:02] Start training on data/TVSum/splits.yml: split 2\n",
            "load checkpoint from saved_model/TVSum/model_best_split2.pt\n",
            "[2025/03/11 10:10:02] Saved frame data for video_26: 496 key frames identified, 495 ground truth frames\n",
            "[2025/03/11 10:10:02] Saved frame data for video_24: 648 key frames identified, 637 ground truth frames\n",
            "[2025/03/11 10:10:02] Saved frame data for video_23: 840 key frames identified, 832 ground truth frames\n",
            "[2025/03/11 10:10:02] Saved frame data for video_41: 1209 key frames identified, 1202 ground truth frames\n",
            "[2025/03/11 10:10:02] Saved frame data for video_16: 1426 key frames identified, 1430 ground truth frames\n",
            "[2025/03/11 10:10:02] Saved frame data for video_43: 736 key frames identified, 730 ground truth frames\n",
            "[2025/03/11 10:10:02] Saved frame data for video_1: 1586 key frames identified, 1585 ground truth frames\n",
            "[2025/03/11 10:10:02] Saved frame data for video_36: 1194 key frames identified, 1163 ground truth frames\n",
            "[2025/03/11 10:10:02] Saved frame data for video_16: 1029 key frames identified, 1024 ground truth frames\n",
            "[2025/03/11 10:10:02] Saved frame data for video_43: 1458 key frames identified, 1449 ground truth frames\n",
            "[2025/03/11 10:10:02] Completed saving frame data to TVSum_frames folder\n",
            "[2025/03/11 10:10:02] F-score: 0.6512\n",
            "[2025/03/11 10:10:02] Start training on data/TVSum/splits.yml: split 3\n",
            "load checkpoint from saved_model/TVSum/model_best_split3.pt\n",
            "[2025/03/11 10:10:03] Saved frame data for video_19: 853 key frames identified, 860 ground truth frames\n",
            "[2025/03/11 10:10:03] Saved frame data for video_26: 460 key frames identified, 495 ground truth frames\n",
            "[2025/03/11 10:10:03] Saved frame data for video_42: 889 key frames identified, 880 ground truth frames\n",
            "[2025/03/11 10:10:03] Saved frame data for video_11: 704 key frames identified, 703 ground truth frames\n",
            "[2025/03/11 10:10:03] Saved frame data for video_40: 1712 key frames identified, 1711 ground truth frames\n",
            "[2025/03/11 10:10:03] Saved frame data for video_46: 2296 key frames identified, 2293 ground truth frames\n",
            "[2025/03/11 10:10:03] Saved frame data for video_29: 2628 key frames identified, 2624 ground truth frames\n",
            "[2025/03/11 10:10:03] Saved frame data for video_18: 1458 key frames identified, 1449 ground truth frames\n",
            "[2025/03/11 10:10:03] Saved frame data for video_40: 930 key frames identified, 931 ground truth frames\n",
            "[2025/03/11 10:10:03] Saved frame data for video_46: 636 key frames identified, 645 ground truth frames\n",
            "[2025/03/11 10:10:03] Completed saving frame data to TVSum_frames folder\n",
            "[2025/03/11 10:10:03] F-score: 0.6341\n",
            "[2025/03/11 10:10:03] Start training on data/TVSum/splits.yml: split 4\n",
            "load checkpoint from saved_model/TVSum/model_best_split4.pt\n",
            "[2025/03/11 10:10:04] Saved frame data for video_35: 664 key frames identified, 641 ground truth frames\n",
            "[2025/03/11 10:10:04] Saved frame data for video_41: 1209 key frames identified, 1202 ground truth frames\n",
            "[2025/03/11 10:10:04] Saved frame data for video_50: 1033 key frames identified, 1024 ground truth frames\n",
            "[2025/03/11 10:10:04] Saved frame data for video_44: 636 key frames identified, 645 ground truth frames\n",
            "[2025/03/11 10:10:04] Saved frame data for video_15: 642 key frames identified, 622 ground truth frames\n",
            "[2025/03/11 10:10:04] Saved frame data for video_22: 843 key frames identified, 837 ground truth frames\n",
            "[2025/03/11 10:10:04] Saved frame data for video_16: 1428 key frames identified, 1430 ground truth frames\n",
            "[2025/03/11 10:10:04] Saved frame data for video_28: 1240 key frames identified, 1242 ground truth frames\n",
            "[2025/03/11 10:10:04] Saved frame data for video_15: 565 key frames identified, 564 ground truth frames\n",
            "[2025/03/11 10:10:04] Saved frame data for video_22: 871 key frames identified, 874 ground truth frames\n",
            "[2025/03/11 10:10:04] Completed saving frame data to TVSum_frames folder\n",
            "[2025/03/11 10:10:04] F-score: 0.6426\n",
            "[2025/03/11 10:10:04] Training done on data/TVSum/splits.yml.\n",
            "[2025/03/11 10:10:04] F1_results: {'split0': 0.6383229756288314, 'split1': 0.5972982603735566, 'split2': 0.651177353382769, 'split3': 0.6340906055934667, 'split4': 0.6426364793973789}\n",
            "[2025/03/11 10:10:04] F1-score: 0.6327\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "POBux7uPgU71"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}